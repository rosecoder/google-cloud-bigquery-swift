// DO NOT EDIT.
// swift-format-ignore-file
// swiftlint:disable all
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/bigquery/storage/v1/arrow.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Arrow schema as specified in
/// https://arrow.apache.org/docs/python/api/datatypes.html
/// and serialized to bytes using IPC:
/// https://arrow.apache.org/docs/format/Columnar.html#serialization-and-interprocess-communication-ipc
///
/// See code samples on how this message can be deserialized.
package struct Google_Cloud_Bigquery_Storage_V1_ArrowSchema: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// IPC serialized Arrow schema.
  package var serializedSchema: Data = Data()

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

/// Arrow RecordBatch.
package struct Google_Cloud_Bigquery_Storage_V1_ArrowRecordBatch: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// IPC-serialized Arrow RecordBatch.
  package var serializedRecordBatch: Data = Data()

  /// [Deprecated] The count of rows in `serialized_record_batch`.
  /// Please use the format-independent ReadRowsResponse.row_count instead.
  ///
  /// NOTE: This field was marked as deprecated in the .proto file.
  package var rowCount: Int64 = 0

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

/// Contains options specific to Arrow Serialization.
package struct Google_Cloud_Bigquery_Storage_V1_ArrowSerializationOptions: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The compression codec to use for Arrow buffers in serialized record
  /// batches.
  package var bufferCompression: Google_Cloud_Bigquery_Storage_V1_ArrowSerializationOptions.CompressionCodec = .compressionUnspecified

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Compression codec's supported by Arrow.
  package enum CompressionCodec: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// If unspecified no compression will be used.
    case compressionUnspecified // = 0

    /// LZ4 Frame (https://github.com/lz4/lz4/blob/dev/doc/lz4_Frame_format.md)
    case lz4Frame // = 1

    /// Zstandard compression.
    case zstd // = 2
    case UNRECOGNIZED(Int)

    package init() {
      self = .compressionUnspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .compressionUnspecified
      case 1: self = .lz4Frame
      case 2: self = .zstd
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .compressionUnspecified: return 0
      case .lz4Frame: return 1
      case .zstd: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_Storage_V1_ArrowSerializationOptions.CompressionCodec] = [
      .compressionUnspecified,
      .lz4Frame,
      .zstd,
    ]

  }

  package init() {}
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.bigquery.storage.v1"

extension Google_Cloud_Bigquery_Storage_V1_ArrowSchema: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".ArrowSchema"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "serialized_schema"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBytesField(value: &self.serializedSchema) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.serializedSchema.isEmpty {
      try visitor.visitSingularBytesField(value: self.serializedSchema, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_Storage_V1_ArrowSchema, rhs: Google_Cloud_Bigquery_Storage_V1_ArrowSchema) -> Bool {
    if lhs.serializedSchema != rhs.serializedSchema {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1_ArrowRecordBatch: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".ArrowRecordBatch"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "serialized_record_batch"),
    2: .standard(proto: "row_count"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBytesField(value: &self.serializedRecordBatch) }()
      case 2: try { try decoder.decodeSingularInt64Field(value: &self.rowCount) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.serializedRecordBatch.isEmpty {
      try visitor.visitSingularBytesField(value: self.serializedRecordBatch, fieldNumber: 1)
    }
    if self.rowCount != 0 {
      try visitor.visitSingularInt64Field(value: self.rowCount, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_Storage_V1_ArrowRecordBatch, rhs: Google_Cloud_Bigquery_Storage_V1_ArrowRecordBatch) -> Bool {
    if lhs.serializedRecordBatch != rhs.serializedRecordBatch {return false}
    if lhs.rowCount != rhs.rowCount {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1_ArrowSerializationOptions: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".ArrowSerializationOptions"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    2: .standard(proto: "buffer_compression"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 2: try { try decoder.decodeSingularEnumField(value: &self.bufferCompression) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.bufferCompression != .compressionUnspecified {
      try visitor.visitSingularEnumField(value: self.bufferCompression, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_Storage_V1_ArrowSerializationOptions, rhs: Google_Cloud_Bigquery_Storage_V1_ArrowSerializationOptions) -> Bool {
    if lhs.bufferCompression != rhs.bufferCompression {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1_ArrowSerializationOptions.CompressionCodec: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "COMPRESSION_UNSPECIFIED"),
    1: .same(proto: "LZ4_FRAME"),
    2: .same(proto: "ZSTD"),
  ]
}
