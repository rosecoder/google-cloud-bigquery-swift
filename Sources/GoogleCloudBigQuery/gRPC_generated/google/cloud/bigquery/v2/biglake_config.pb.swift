// DO NOT EDIT.
// swift-format-ignore-file
// swiftlint:disable all
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/bigquery/v2/biglake_config.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Configuration for BigLake managed tables.
package struct Google_Cloud_Bigquery_V2_BigLakeConfiguration: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Optional. The connection specifying the credentials to be used to read and
  /// write to external storage, such as Cloud Storage. The connection_id can
  /// have the form `{project}.{location}.{connection_id}` or
  /// `projects/{project}/locations/{location}/connections/{connection_id}".
  package var connectionID: String = String()

  /// Optional. The fully qualified location prefix of the external folder where
  /// table data is stored. The '*' wildcard character is not allowed. The URI
  /// should be in the format `gs://bucket/path_to_table/`
  package var storageUri: String = String()

  /// Optional. The file format the table data is stored in.
  package var fileFormat: Google_Cloud_Bigquery_V2_BigLakeConfiguration.FileFormat = .unspecified

  /// Optional. The table format the metadata only snapshots are stored in.
  package var tableFormat: Google_Cloud_Bigquery_V2_BigLakeConfiguration.TableFormat = .unspecified

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Supported file formats for BigLake tables.
  package enum FileFormat: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Default Value.
    case unspecified // = 0

    /// Apache Parquet format.
    case parquet // = 1
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .parquet
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .parquet: return 1
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_BigLakeConfiguration.FileFormat] = [
      .unspecified,
      .parquet,
    ]

  }

  /// Supported table formats for BigLake tables.
  package enum TableFormat: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Default Value.
    case unspecified // = 0

    /// Apache Iceberg format.
    case iceberg // = 1
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .iceberg
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .iceberg: return 1
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_BigLakeConfiguration.TableFormat] = [
      .unspecified,
      .iceberg,
    ]

  }

  package init() {}
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.bigquery.v2"

extension Google_Cloud_Bigquery_V2_BigLakeConfiguration: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".BigLakeConfiguration"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "connection_id"),
    2: .standard(proto: "storage_uri"),
    3: .standard(proto: "file_format"),
    4: .standard(proto: "table_format"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.connectionID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.storageUri) }()
      case 3: try { try decoder.decodeSingularEnumField(value: &self.fileFormat) }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self.tableFormat) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.connectionID.isEmpty {
      try visitor.visitSingularStringField(value: self.connectionID, fieldNumber: 1)
    }
    if !self.storageUri.isEmpty {
      try visitor.visitSingularStringField(value: self.storageUri, fieldNumber: 2)
    }
    if self.fileFormat != .unspecified {
      try visitor.visitSingularEnumField(value: self.fileFormat, fieldNumber: 3)
    }
    if self.tableFormat != .unspecified {
      try visitor.visitSingularEnumField(value: self.tableFormat, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_BigLakeConfiguration, rhs: Google_Cloud_Bigquery_V2_BigLakeConfiguration) -> Bool {
    if lhs.connectionID != rhs.connectionID {return false}
    if lhs.storageUri != rhs.storageUri {return false}
    if lhs.fileFormat != rhs.fileFormat {return false}
    if lhs.tableFormat != rhs.tableFormat {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_BigLakeConfiguration.FileFormat: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "FILE_FORMAT_UNSPECIFIED"),
    1: .same(proto: "PARQUET"),
  ]
}

extension Google_Cloud_Bigquery_V2_BigLakeConfiguration.TableFormat: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "TABLE_FORMAT_UNSPECIFIED"),
    1: .same(proto: "ICEBERG"),
  ]
}
