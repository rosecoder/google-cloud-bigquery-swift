// DO NOT EDIT.
// swift-format-ignore-file
// swiftlint:disable all
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/bigquery/v2/model.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Remote Model Info
package struct Google_Cloud_Bigquery_V2_RemoteModelInfo: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Remote services are services outside of BigQuery used by remote models for
  /// predictions. A remote service is backed by either an arbitrary endpoint or
  /// a selected remote service type, but not both.
  package var remoteService: Google_Cloud_Bigquery_V2_RemoteModelInfo.OneOf_RemoteService? = nil

  /// Output only. The endpoint for remote model.
  package var endpoint: String {
    get {
      if case .endpoint(let v)? = remoteService {return v}
      return String()
    }
    set {remoteService = .endpoint(newValue)}
  }

  /// Output only. The remote service type for remote model.
  package var remoteServiceType: Google_Cloud_Bigquery_V2_RemoteModelInfo.RemoteServiceType {
    get {
      if case .remoteServiceType(let v)? = remoteService {return v}
      return .unspecified
    }
    set {remoteService = .remoteServiceType(newValue)}
  }

  /// Output only. Fully qualified name of the user-provided connection object of
  /// the remote model. Format:
  /// ```"projects/{project_id}/locations/{location_id}/connections/{connection_id}"```
  package var connection: String = String()

  /// Output only. Max number of rows in each batch sent to the remote service.
  /// If unset, the number of rows in each batch is set dynamically.
  package var maxBatchingRows: Int64 = 0

  /// Output only. The model version for LLM.
  package var remoteModelVersion: String = String()

  /// Output only. The name of the speech recognizer to use for speech
  /// recognition. The expected format is
  /// `projects/{project}/locations/{location}/recognizers/{recognizer}`.
  /// Customers can specify this field at model creation. If not specified, a
  /// default recognizer `projects/{model
  /// project}/locations/global/recognizers/_` will be used. See more details at
  /// [recognizers](https://cloud.google.com/speech-to-text/v2/docs/reference/rest/v2/projects.locations.recognizers)
  package var speechRecognizer: String = String()

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Remote services are services outside of BigQuery used by remote models for
  /// predictions. A remote service is backed by either an arbitrary endpoint or
  /// a selected remote service type, but not both.
  package enum OneOf_RemoteService: Equatable, Sendable {
    /// Output only. The endpoint for remote model.
    case endpoint(String)
    /// Output only. The remote service type for remote model.
    case remoteServiceType(Google_Cloud_Bigquery_V2_RemoteModelInfo.RemoteServiceType)

  }

  /// Supported service type for remote model.
  package enum RemoteServiceType: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Unspecified remote service type.
    case unspecified // = 0

    /// V3 Cloud AI Translation API. See more details at [Cloud Translation API]
    /// (https://cloud.google.com/translate/docs/reference/rest).
    case cloudAiTranslateV3 // = 1

    /// V1 Cloud AI Vision API See more details at [Cloud Vision API]
    /// (https://cloud.google.com/vision/docs/reference/rest).
    case cloudAiVisionV1 // = 2

    /// V1 Cloud AI Natural Language API. See more details at [REST Resource:
    /// documents](https://cloud.google.com/natural-language/docs/reference/rest/v1/documents).
    case cloudAiNaturalLanguageV1 // = 3

    /// V2 Speech-to-Text API. See more details at [Google Cloud Speech-to-Text
    /// V2 API](https://cloud.google.com/speech-to-text/v2/docs)
    case cloudAiSpeechToTextV2 // = 7
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .cloudAiTranslateV3
      case 2: self = .cloudAiVisionV1
      case 3: self = .cloudAiNaturalLanguageV1
      case 7: self = .cloudAiSpeechToTextV2
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .cloudAiTranslateV3: return 1
      case .cloudAiVisionV1: return 2
      case .cloudAiNaturalLanguageV1: return 3
      case .cloudAiSpeechToTextV2: return 7
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_RemoteModelInfo.RemoteServiceType] = [
      .unspecified,
      .cloudAiTranslateV3,
      .cloudAiVisionV1,
      .cloudAiNaturalLanguageV1,
      .cloudAiSpeechToTextV2,
    ]

  }

  package init() {}
}

/// Information about a single transform column.
package struct Google_Cloud_Bigquery_V2_TransformColumn: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Name of the column.
  package var name: String = String()

  /// Output only. Data type of the column after the transform.
  package var type: Google_Cloud_Bigquery_V2_StandardSqlDataType {
    get {return _type ?? Google_Cloud_Bigquery_V2_StandardSqlDataType()}
    set {_type = newValue}
  }
  /// Returns true if `type` has been explicitly set.
  package var hasType: Bool {return self._type != nil}
  /// Clears the value of `type`. Subsequent reads from it will return its default value.
  package mutating func clearType() {self._type = nil}

  /// Output only. The SQL expression used in the column transform.
  package var transformSql: String = String()

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _type: Google_Cloud_Bigquery_V2_StandardSqlDataType? = nil
}

package struct Google_Cloud_Bigquery_V2_Model: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. A hash of this resource.
  package var etag: String {
    get {return _storage._etag}
    set {_uniqueStorage()._etag = newValue}
  }

  /// Required. Unique identifier for this model.
  package var modelReference: Google_Cloud_Bigquery_V2_ModelReference {
    get {return _storage._modelReference ?? Google_Cloud_Bigquery_V2_ModelReference()}
    set {_uniqueStorage()._modelReference = newValue}
  }
  /// Returns true if `modelReference` has been explicitly set.
  package var hasModelReference: Bool {return _storage._modelReference != nil}
  /// Clears the value of `modelReference`. Subsequent reads from it will return its default value.
  package mutating func clearModelReference() {_uniqueStorage()._modelReference = nil}

  /// Output only. The time when this model was created, in millisecs since the
  /// epoch.
  package var creationTime: Int64 {
    get {return _storage._creationTime}
    set {_uniqueStorage()._creationTime = newValue}
  }

  /// Output only. The time when this model was last modified, in millisecs since
  /// the epoch.
  package var lastModifiedTime: Int64 {
    get {return _storage._lastModifiedTime}
    set {_uniqueStorage()._lastModifiedTime = newValue}
  }

  /// Optional. A user-friendly description of this model.
  package var description_p: String {
    get {return _storage._description_p}
    set {_uniqueStorage()._description_p = newValue}
  }

  /// Optional. A descriptive name for this model.
  package var friendlyName: String {
    get {return _storage._friendlyName}
    set {_uniqueStorage()._friendlyName = newValue}
  }

  /// The labels associated with this model. You can use these to organize
  /// and group your models. Label keys and values can be no longer
  /// than 63 characters, can only contain lowercase letters, numeric
  /// characters, underscores and dashes. International characters are allowed.
  /// Label values are optional. Label keys must start with a letter and each
  /// label in the list must have a different key.
  package var labels: Dictionary<String,String> {
    get {return _storage._labels}
    set {_uniqueStorage()._labels = newValue}
  }

  /// Optional. The time when this model expires, in milliseconds since the
  /// epoch. If not present, the model will persist indefinitely. Expired models
  /// will be deleted and their storage reclaimed.  The defaultTableExpirationMs
  /// property of the encapsulating dataset can be used to set a default
  /// expirationTime on newly created models.
  package var expirationTime: Int64 {
    get {return _storage._expirationTime}
    set {_uniqueStorage()._expirationTime = newValue}
  }

  /// Output only. The geographic location where the model resides. This value
  /// is inherited from the dataset.
  package var location: String {
    get {return _storage._location}
    set {_uniqueStorage()._location = newValue}
  }

  /// Custom encryption configuration (e.g., Cloud KMS keys). This shows the
  /// encryption configuration of the model data while stored in BigQuery
  /// storage. This field can be used with PatchModel to update encryption key
  /// for an already encrypted model.
  package var encryptionConfiguration: Google_Cloud_Bigquery_V2_EncryptionConfiguration {
    get {return _storage._encryptionConfiguration ?? Google_Cloud_Bigquery_V2_EncryptionConfiguration()}
    set {_uniqueStorage()._encryptionConfiguration = newValue}
  }
  /// Returns true if `encryptionConfiguration` has been explicitly set.
  package var hasEncryptionConfiguration: Bool {return _storage._encryptionConfiguration != nil}
  /// Clears the value of `encryptionConfiguration`. Subsequent reads from it will return its default value.
  package mutating func clearEncryptionConfiguration() {_uniqueStorage()._encryptionConfiguration = nil}

  /// Output only. Type of the model resource.
  package var modelType: Google_Cloud_Bigquery_V2_Model.ModelType {
    get {return _storage._modelType}
    set {_uniqueStorage()._modelType = newValue}
  }

  /// Information for all training runs in increasing order of start_time.
  package var trainingRuns: [Google_Cloud_Bigquery_V2_Model.TrainingRun] {
    get {return _storage._trainingRuns}
    set {_uniqueStorage()._trainingRuns = newValue}
  }

  /// Output only. Input feature columns for the model inference. If the model is
  /// trained with TRANSFORM clause, these are the input of the TRANSFORM clause.
  package var featureColumns: [Google_Cloud_Bigquery_V2_StandardSqlField] {
    get {return _storage._featureColumns}
    set {_uniqueStorage()._featureColumns = newValue}
  }

  /// Output only. Label columns that were used to train this model.
  /// The output of the model will have a "predicted_" prefix to these columns.
  package var labelColumns: [Google_Cloud_Bigquery_V2_StandardSqlField] {
    get {return _storage._labelColumns}
    set {_uniqueStorage()._labelColumns = newValue}
  }

  /// Output only. This field will be populated if a TRANSFORM clause was used to
  /// train a model. TRANSFORM clause (if used) takes feature_columns as input
  /// and outputs transform_columns. transform_columns then are used to train the
  /// model.
  package var transformColumns: [Google_Cloud_Bigquery_V2_TransformColumn] {
    get {return _storage._transformColumns}
    set {_uniqueStorage()._transformColumns = newValue}
  }

  /// Output only. All hyperparameter search spaces in this model.
  package var hparamSearchSpaces: Google_Cloud_Bigquery_V2_Model.HparamSearchSpaces {
    get {return _storage._hparamSearchSpaces ?? Google_Cloud_Bigquery_V2_Model.HparamSearchSpaces()}
    set {_uniqueStorage()._hparamSearchSpaces = newValue}
  }
  /// Returns true if `hparamSearchSpaces` has been explicitly set.
  package var hasHparamSearchSpaces: Bool {return _storage._hparamSearchSpaces != nil}
  /// Clears the value of `hparamSearchSpaces`. Subsequent reads from it will return its default value.
  package mutating func clearHparamSearchSpaces() {_uniqueStorage()._hparamSearchSpaces = nil}

  /// Output only. The default trial_id to use in TVFs when the trial_id is not
  /// passed in. For single-objective [hyperparameter
  /// tuning](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview)
  /// models, this is the best trial ID. For multi-objective [hyperparameter
  /// tuning](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview)
  /// models, this is the smallest trial ID among all Pareto optimal trials.
  package var defaultTrialID: Int64 {
    get {return _storage._defaultTrialID}
    set {_uniqueStorage()._defaultTrialID = newValue}
  }

  /// Output only. Trials of a [hyperparameter
  /// tuning](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview)
  /// model sorted by trial_id.
  package var hparamTrials: [Google_Cloud_Bigquery_V2_Model.HparamTuningTrial] {
    get {return _storage._hparamTrials}
    set {_uniqueStorage()._hparamTrials = newValue}
  }

  /// Output only. For single-objective [hyperparameter
  /// tuning](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview)
  /// models, it only contains the best trial. For multi-objective
  /// [hyperparameter
  /// tuning](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview)
  /// models, it contains all Pareto optimal trials sorted by trial_id.
  package var optimalTrialIds: [Int64] {
    get {return _storage._optimalTrialIds}
    set {_uniqueStorage()._optimalTrialIds = newValue}
  }

  /// Output only. Remote model info
  package var remoteModelInfo: Google_Cloud_Bigquery_V2_RemoteModelInfo {
    get {return _storage._remoteModelInfo ?? Google_Cloud_Bigquery_V2_RemoteModelInfo()}
    set {_uniqueStorage()._remoteModelInfo = newValue}
  }
  /// Returns true if `remoteModelInfo` has been explicitly set.
  package var hasRemoteModelInfo: Bool {return _storage._remoteModelInfo != nil}
  /// Clears the value of `remoteModelInfo`. Subsequent reads from it will return its default value.
  package mutating func clearRemoteModelInfo() {_uniqueStorage()._remoteModelInfo = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Indicates the type of the Model.
  package enum ModelType: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Default value.
    case unspecified // = 0

    /// Linear regression model.
    case linearRegression // = 1

    /// Logistic regression based classification model.
    case logisticRegression // = 2

    /// K-means clustering model.
    case kmeans // = 3

    /// Matrix factorization model.
    case matrixFactorization // = 4

    /// DNN classifier model.
    case dnnClassifier // = 5

    /// An imported TensorFlow model.
    case tensorflow // = 6

    /// DNN regressor model.
    case dnnRegressor // = 7

    /// An imported XGBoost model.
    case xgboost // = 8

    /// Boosted tree regressor model.
    case boostedTreeRegressor // = 9

    /// Boosted tree classifier model.
    case boostedTreeClassifier // = 10

    /// ARIMA model.
    case arima // = 11

    /// AutoML Tables regression model.
    case automlRegressor // = 12

    /// AutoML Tables classification model.
    case automlClassifier // = 13

    /// Prinpical Component Analysis model.
    case pca // = 14

    /// Wide-and-deep classifier model.
    case dnnLinearCombinedClassifier // = 16

    /// Wide-and-deep regressor model.
    case dnnLinearCombinedRegressor // = 17

    /// Autoencoder model.
    case autoencoder // = 18

    /// New name for the ARIMA model.
    case arimaPlus // = 19

    /// ARIMA with external regressors.
    case arimaPlusXreg // = 23

    /// Random forest regressor model.
    case randomForestRegressor // = 24

    /// Random forest classifier model.
    case randomForestClassifier // = 25

    /// An imported TensorFlow Lite model.
    case tensorflowLite // = 26

    /// An imported ONNX model.
    case onnx // = 28

    /// Model to capture the columns and logic in the TRANSFORM clause along with
    /// statistics useful for ML analytic functions.
    case transformOnly // = 29

    /// The contribution analysis model.
    case contributionAnalysis // = 37
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .linearRegression
      case 2: self = .logisticRegression
      case 3: self = .kmeans
      case 4: self = .matrixFactorization
      case 5: self = .dnnClassifier
      case 6: self = .tensorflow
      case 7: self = .dnnRegressor
      case 8: self = .xgboost
      case 9: self = .boostedTreeRegressor
      case 10: self = .boostedTreeClassifier
      case 11: self = .arima
      case 12: self = .automlRegressor
      case 13: self = .automlClassifier
      case 14: self = .pca
      case 16: self = .dnnLinearCombinedClassifier
      case 17: self = .dnnLinearCombinedRegressor
      case 18: self = .autoencoder
      case 19: self = .arimaPlus
      case 23: self = .arimaPlusXreg
      case 24: self = .randomForestRegressor
      case 25: self = .randomForestClassifier
      case 26: self = .tensorflowLite
      case 28: self = .onnx
      case 29: self = .transformOnly
      case 37: self = .contributionAnalysis
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .linearRegression: return 1
      case .logisticRegression: return 2
      case .kmeans: return 3
      case .matrixFactorization: return 4
      case .dnnClassifier: return 5
      case .tensorflow: return 6
      case .dnnRegressor: return 7
      case .xgboost: return 8
      case .boostedTreeRegressor: return 9
      case .boostedTreeClassifier: return 10
      case .arima: return 11
      case .automlRegressor: return 12
      case .automlClassifier: return 13
      case .pca: return 14
      case .dnnLinearCombinedClassifier: return 16
      case .dnnLinearCombinedRegressor: return 17
      case .autoencoder: return 18
      case .arimaPlus: return 19
      case .arimaPlusXreg: return 23
      case .randomForestRegressor: return 24
      case .randomForestClassifier: return 25
      case .tensorflowLite: return 26
      case .onnx: return 28
      case .transformOnly: return 29
      case .contributionAnalysis: return 37
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_Model.ModelType] = [
      .unspecified,
      .linearRegression,
      .logisticRegression,
      .kmeans,
      .matrixFactorization,
      .dnnClassifier,
      .tensorflow,
      .dnnRegressor,
      .xgboost,
      .boostedTreeRegressor,
      .boostedTreeClassifier,
      .arima,
      .automlRegressor,
      .automlClassifier,
      .pca,
      .dnnLinearCombinedClassifier,
      .dnnLinearCombinedRegressor,
      .autoencoder,
      .arimaPlus,
      .arimaPlusXreg,
      .randomForestRegressor,
      .randomForestClassifier,
      .tensorflowLite,
      .onnx,
      .transformOnly,
      .contributionAnalysis,
    ]

  }

  /// Loss metric to evaluate model training performance.
  package enum LossType: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Default value.
    case unspecified // = 0

    /// Mean squared loss, used for linear regression.
    case meanSquaredLoss // = 1

    /// Mean log loss, used for logistic regression.
    case meanLogLoss // = 2
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .meanSquaredLoss
      case 2: self = .meanLogLoss
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .meanSquaredLoss: return 1
      case .meanLogLoss: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_Model.LossType] = [
      .unspecified,
      .meanSquaredLoss,
      .meanLogLoss,
    ]

  }

  /// Distance metric used to compute the distance between two points.
  package enum DistanceType: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Default value.
    case unspecified // = 0

    /// Eculidean distance.
    case euclidean // = 1

    /// Cosine distance.
    case cosine // = 2
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .euclidean
      case 2: self = .cosine
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .euclidean: return 1
      case .cosine: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_Model.DistanceType] = [
      .unspecified,
      .euclidean,
      .cosine,
    ]

  }

  /// Indicates the method to split input data into multiple tables.
  package enum DataSplitMethod: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Default value.
    case unspecified // = 0

    /// Splits data randomly.
    case random // = 1

    /// Splits data with the user provided tags.
    case custom // = 2

    /// Splits data sequentially.
    case sequential // = 3

    /// Data split will be skipped.
    case noSplit // = 4

    /// Splits data automatically: Uses NO_SPLIT if the data size is small.
    /// Otherwise uses RANDOM.
    case autoSplit // = 5
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .random
      case 2: self = .custom
      case 3: self = .sequential
      case 4: self = .noSplit
      case 5: self = .autoSplit
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .random: return 1
      case .custom: return 2
      case .sequential: return 3
      case .noSplit: return 4
      case .autoSplit: return 5
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_Model.DataSplitMethod] = [
      .unspecified,
      .random,
      .custom,
      .sequential,
      .noSplit,
      .autoSplit,
    ]

  }

  /// Type of supported data frequency for time series forecasting models.
  package enum DataFrequency: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Default value.
    case unspecified // = 0

    /// Automatically inferred from timestamps.
    case autoFrequency // = 1

    /// Yearly data.
    case yearly // = 2

    /// Quarterly data.
    case quarterly // = 3

    /// Monthly data.
    case monthly // = 4

    /// Weekly data.
    case weekly // = 5

    /// Daily data.
    case daily // = 6

    /// Hourly data.
    case hourly // = 7

    /// Per-minute data.
    case perMinute // = 8
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .autoFrequency
      case 2: self = .yearly
      case 3: self = .quarterly
      case 4: self = .monthly
      case 5: self = .weekly
      case 6: self = .daily
      case 7: self = .hourly
      case 8: self = .perMinute
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .autoFrequency: return 1
      case .yearly: return 2
      case .quarterly: return 3
      case .monthly: return 4
      case .weekly: return 5
      case .daily: return 6
      case .hourly: return 7
      case .perMinute: return 8
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_Model.DataFrequency] = [
      .unspecified,
      .autoFrequency,
      .yearly,
      .quarterly,
      .monthly,
      .weekly,
      .daily,
      .hourly,
      .perMinute,
    ]

  }

  /// Type of supported holiday regions for time series forecasting models.
  package enum HolidayRegion: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Holiday region unspecified.
    case unspecified // = 0

    /// Global.
    case global // = 1

    /// North America.
    case na // = 2

    /// Japan and Asia Pacific: Korea, Greater China, India, Australia, and New
    /// Zealand.
    case japac // = 3

    /// Europe, the Middle East and Africa.
    case emea // = 4

    /// Latin America and the Caribbean.
    case lac // = 5

    /// United Arab Emirates
    case ae // = 6

    /// Argentina
    case ar // = 7

    /// Austria
    case at // = 8

    /// Australia
    case au // = 9

    /// Belgium
    case be // = 10

    /// Brazil
    case br // = 11

    /// Canada
    case ca // = 12

    /// Switzerland
    case ch // = 13

    /// Chile
    case cl // = 14

    /// China
    case cn // = 15

    /// Colombia
    case co // = 16

    /// Czechoslovakia
    case cs // = 17

    /// Czech Republic
    case cz // = 18

    /// Germany
    case de // = 19

    /// Denmark
    case dk // = 20

    /// Algeria
    case dz // = 21

    /// Ecuador
    case ec // = 22

    /// Estonia
    case ee // = 23

    /// Egypt
    case eg // = 24

    /// Spain
    case es // = 25

    /// Finland
    case fi // = 26

    /// France
    case fr // = 27

    /// Great Britain (United Kingdom)
    case gb // = 28

    /// Greece
    case gr // = 29

    /// Hong Kong
    case hk // = 30

    /// Hungary
    case hu // = 31

    /// Indonesia
    case id // = 32

    /// Ireland
    case ie // = 33

    /// Israel
    case il // = 34

    /// India
    case `in` // = 35

    /// Iran
    case ir // = 36

    /// Italy
    case it // = 37

    /// Japan
    case jp // = 38

    /// Korea (South)
    case kr // = 39

    /// Latvia
    case lv // = 40

    /// Morocco
    case ma // = 41

    /// Mexico
    case mx // = 42

    /// Malaysia
    case my // = 43

    /// Nigeria
    case ng // = 44

    /// Netherlands
    case nl // = 45

    /// Norway
    case no // = 46

    /// New Zealand
    case nz // = 47

    /// Peru
    case pe // = 48

    /// Philippines
    case ph // = 49

    /// Pakistan
    case pk // = 50

    /// Poland
    case pl // = 51

    /// Portugal
    case pt // = 52

    /// Romania
    case ro // = 53

    /// Serbia
    case rs // = 54

    /// Russian Federation
    case ru // = 55

    /// Saudi Arabia
    case sa // = 56

    /// Sweden
    case se // = 57

    /// Singapore
    case sg // = 58

    /// Slovenia
    case si // = 59

    /// Slovakia
    case sk // = 60

    /// Thailand
    case th // = 61

    /// Turkey
    case tr // = 62

    /// Taiwan
    case tw // = 63

    /// Ukraine
    case ua // = 64

    /// United States
    case us // = 65

    /// Venezuela
    case ve // = 66

    /// Viet Nam
    case vn // = 67

    /// South Africa
    case za // = 68
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .global
      case 2: self = .na
      case 3: self = .japac
      case 4: self = .emea
      case 5: self = .lac
      case 6: self = .ae
      case 7: self = .ar
      case 8: self = .at
      case 9: self = .au
      case 10: self = .be
      case 11: self = .br
      case 12: self = .ca
      case 13: self = .ch
      case 14: self = .cl
      case 15: self = .cn
      case 16: self = .co
      case 17: self = .cs
      case 18: self = .cz
      case 19: self = .de
      case 20: self = .dk
      case 21: self = .dz
      case 22: self = .ec
      case 23: self = .ee
      case 24: self = .eg
      case 25: self = .es
      case 26: self = .fi
      case 27: self = .fr
      case 28: self = .gb
      case 29: self = .gr
      case 30: self = .hk
      case 31: self = .hu
      case 32: self = .id
      case 33: self = .ie
      case 34: self = .il
      case 35: self = .in
      case 36: self = .ir
      case 37: self = .it
      case 38: self = .jp
      case 39: self = .kr
      case 40: self = .lv
      case 41: self = .ma
      case 42: self = .mx
      case 43: self = .my
      case 44: self = .ng
      case 45: self = .nl
      case 46: self = .no
      case 47: self = .nz
      case 48: self = .pe
      case 49: self = .ph
      case 50: self = .pk
      case 51: self = .pl
      case 52: self = .pt
      case 53: self = .ro
      case 54: self = .rs
      case 55: self = .ru
      case 56: self = .sa
      case 57: self = .se
      case 58: self = .sg
      case 59: self = .si
      case 60: self = .sk
      case 61: self = .th
      case 62: self = .tr
      case 63: self = .tw
      case 64: self = .ua
      case 65: self = .us
      case 66: self = .ve
      case 67: self = .vn
      case 68: self = .za
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .global: return 1
      case .na: return 2
      case .japac: return 3
      case .emea: return 4
      case .lac: return 5
      case .ae: return 6
      case .ar: return 7
      case .at: return 8
      case .au: return 9
      case .be: return 10
      case .br: return 11
      case .ca: return 12
      case .ch: return 13
      case .cl: return 14
      case .cn: return 15
      case .co: return 16
      case .cs: return 17
      case .cz: return 18
      case .de: return 19
      case .dk: return 20
      case .dz: return 21
      case .ec: return 22
      case .ee: return 23
      case .eg: return 24
      case .es: return 25
      case .fi: return 26
      case .fr: return 27
      case .gb: return 28
      case .gr: return 29
      case .hk: return 30
      case .hu: return 31
      case .id: return 32
      case .ie: return 33
      case .il: return 34
      case .in: return 35
      case .ir: return 36
      case .it: return 37
      case .jp: return 38
      case .kr: return 39
      case .lv: return 40
      case .ma: return 41
      case .mx: return 42
      case .my: return 43
      case .ng: return 44
      case .nl: return 45
      case .no: return 46
      case .nz: return 47
      case .pe: return 48
      case .ph: return 49
      case .pk: return 50
      case .pl: return 51
      case .pt: return 52
      case .ro: return 53
      case .rs: return 54
      case .ru: return 55
      case .sa: return 56
      case .se: return 57
      case .sg: return 58
      case .si: return 59
      case .sk: return 60
      case .th: return 61
      case .tr: return 62
      case .tw: return 63
      case .ua: return 64
      case .us: return 65
      case .ve: return 66
      case .vn: return 67
      case .za: return 68
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_Model.HolidayRegion] = [
      .unspecified,
      .global,
      .na,
      .japac,
      .emea,
      .lac,
      .ae,
      .ar,
      .at,
      .au,
      .be,
      .br,
      .ca,
      .ch,
      .cl,
      .cn,
      .co,
      .cs,
      .cz,
      .de,
      .dk,
      .dz,
      .ec,
      .ee,
      .eg,
      .es,
      .fi,
      .fr,
      .gb,
      .gr,
      .hk,
      .hu,
      .id,
      .ie,
      .il,
      .in,
      .ir,
      .it,
      .jp,
      .kr,
      .lv,
      .ma,
      .mx,
      .my,
      .ng,
      .nl,
      .no,
      .nz,
      .pe,
      .ph,
      .pk,
      .pl,
      .pt,
      .ro,
      .rs,
      .ru,
      .sa,
      .se,
      .sg,
      .si,
      .sk,
      .th,
      .tr,
      .tw,
      .ua,
      .us,
      .ve,
      .vn,
      .za,
    ]

  }

  /// Enums for color space, used for processing images in Object Table.
  /// See more details at
  /// https://www.tensorflow.org/io/tutorials/colorspace.
  package enum ColorSpace: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Unspecified color space
    case unspecified // = 0

    /// RGB
    case rgb // = 1

    /// HSV
    case hsv // = 2

    /// YIQ
    case yiq // = 3

    /// YUV
    case yuv // = 4

    /// GRAYSCALE
    case grayscale // = 5
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .rgb
      case 2: self = .hsv
      case 3: self = .yiq
      case 4: self = .yuv
      case 5: self = .grayscale
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .rgb: return 1
      case .hsv: return 2
      case .yiq: return 3
      case .yuv: return 4
      case .grayscale: return 5
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_Model.ColorSpace] = [
      .unspecified,
      .rgb,
      .hsv,
      .yiq,
      .yuv,
      .grayscale,
    ]

  }

  /// Indicates the learning rate optimization strategy to use.
  package enum LearnRateStrategy: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Default value.
    case unspecified // = 0

    /// Use line search to determine learning rate.
    case lineSearch // = 1

    /// Use a constant learning rate.
    case constant // = 2
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .lineSearch
      case 2: self = .constant
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .lineSearch: return 1
      case .constant: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_Model.LearnRateStrategy] = [
      .unspecified,
      .lineSearch,
      .constant,
    ]

  }

  /// Indicates the optimization strategy used for training.
  package enum OptimizationStrategy: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Default value.
    case unspecified // = 0

    /// Uses an iterative batch gradient descent algorithm.
    case batchGradientDescent // = 1

    /// Uses a normal equation to solve linear regression problem.
    case normalEquation // = 2
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .batchGradientDescent
      case 2: self = .normalEquation
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .batchGradientDescent: return 1
      case .normalEquation: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_Model.OptimizationStrategy] = [
      .unspecified,
      .batchGradientDescent,
      .normalEquation,
    ]

  }

  /// Indicates the training algorithm to use for matrix factorization models.
  package enum FeedbackType: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Default value.
    case unspecified // = 0

    /// Use weighted-als for implicit feedback problems.
    case implicit // = 1

    /// Use nonweighted-als for explicit feedback problems.
    case explicit // = 2
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .implicit
      case 2: self = .explicit
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .implicit: return 1
      case .explicit: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_Model.FeedbackType] = [
      .unspecified,
      .implicit,
      .explicit,
    ]

  }

  /// Enums for seasonal period.
  package struct SeasonalPeriod: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    /// Seasonal period type.
    package enum SeasonalPeriodType: SwiftProtobuf.Enum, Swift.CaseIterable {
      package typealias RawValue = Int

      /// Unspecified seasonal period.
      case unspecified // = 0

      /// No seasonality
      case noSeasonality // = 1

      /// Daily period, 24 hours.
      case daily // = 2

      /// Weekly period, 7 days.
      case weekly // = 3

      /// Monthly period, 30 days or irregular.
      case monthly // = 4

      /// Quarterly period, 90 days or irregular.
      case quarterly // = 5

      /// Yearly period, 365 days or irregular.
      case yearly // = 6
      case UNRECOGNIZED(Int)

      package init() {
        self = .unspecified
      }

      package init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .unspecified
        case 1: self = .noSeasonality
        case 2: self = .daily
        case 3: self = .weekly
        case 4: self = .monthly
        case 5: self = .quarterly
        case 6: self = .yearly
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      package var rawValue: Int {
        switch self {
        case .unspecified: return 0
        case .noSeasonality: return 1
        case .daily: return 2
        case .weekly: return 3
        case .monthly: return 4
        case .quarterly: return 5
        case .yearly: return 6
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      package static let allCases: [Google_Cloud_Bigquery_V2_Model.SeasonalPeriod.SeasonalPeriodType] = [
        .unspecified,
        .noSeasonality,
        .daily,
        .weekly,
        .monthly,
        .quarterly,
        .yearly,
      ]

    }

    package init() {}
  }

  /// Enums for kmeans model type.
  package struct KmeansEnums: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    /// Indicates the method used to initialize the centroids for KMeans
    /// clustering algorithm.
    package enum KmeansInitializationMethod: SwiftProtobuf.Enum, Swift.CaseIterable {
      package typealias RawValue = Int

      /// Unspecified initialization method.
      case unspecified // = 0

      /// Initializes the centroids randomly.
      case random // = 1

      /// Initializes the centroids using data specified in
      /// kmeans_initialization_column.
      case custom // = 2

      /// Initializes with kmeans++.
      case kmeansPlusPlus // = 3
      case UNRECOGNIZED(Int)

      package init() {
        self = .unspecified
      }

      package init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .unspecified
        case 1: self = .random
        case 2: self = .custom
        case 3: self = .kmeansPlusPlus
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      package var rawValue: Int {
        switch self {
        case .unspecified: return 0
        case .random: return 1
        case .custom: return 2
        case .kmeansPlusPlus: return 3
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      package static let allCases: [Google_Cloud_Bigquery_V2_Model.KmeansEnums.KmeansInitializationMethod] = [
        .unspecified,
        .random,
        .custom,
        .kmeansPlusPlus,
      ]

    }

    package init() {}
  }

  /// Enums for XGBoost model type.
  package struct BoostedTreeOptionEnums: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    /// Booster types supported. Refer to booster parameter in XGBoost.
    package enum BoosterType: SwiftProtobuf.Enum, Swift.CaseIterable {
      package typealias RawValue = Int

      /// Unspecified booster type.
      case unspecified // = 0

      /// Gbtree booster.
      case gbtree // = 1

      /// Dart booster.
      case dart // = 2
      case UNRECOGNIZED(Int)

      package init() {
        self = .unspecified
      }

      package init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .unspecified
        case 1: self = .gbtree
        case 2: self = .dart
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      package var rawValue: Int {
        switch self {
        case .unspecified: return 0
        case .gbtree: return 1
        case .dart: return 2
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      package static let allCases: [Google_Cloud_Bigquery_V2_Model.BoostedTreeOptionEnums.BoosterType] = [
        .unspecified,
        .gbtree,
        .dart,
      ]

    }

    /// Type of normalization algorithm for boosted tree models using dart
    /// booster. Refer to normalize_type in XGBoost.
    package enum DartNormalizeType: SwiftProtobuf.Enum, Swift.CaseIterable {
      package typealias RawValue = Int

      /// Unspecified dart normalize type.
      case unspecified // = 0

      /// New trees have the same weight of each of dropped trees.
      case tree // = 1

      /// New trees have the same weight of sum of dropped trees.
      case forest // = 2
      case UNRECOGNIZED(Int)

      package init() {
        self = .unspecified
      }

      package init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .unspecified
        case 1: self = .tree
        case 2: self = .forest
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      package var rawValue: Int {
        switch self {
        case .unspecified: return 0
        case .tree: return 1
        case .forest: return 2
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      package static let allCases: [Google_Cloud_Bigquery_V2_Model.BoostedTreeOptionEnums.DartNormalizeType] = [
        .unspecified,
        .tree,
        .forest,
      ]

    }

    /// Tree construction algorithm used in boosted tree models.
    /// Refer to tree_method in XGBoost.
    package enum TreeMethod: SwiftProtobuf.Enum, Swift.CaseIterable {
      package typealias RawValue = Int

      /// Unspecified tree method.
      case unspecified // = 0

      /// Use heuristic to choose the fastest method.
      case auto // = 1

      /// Exact greedy algorithm.
      case exact // = 2

      /// Approximate greedy algorithm using quantile sketch and gradient
      /// histogram.
      case approx // = 3

      /// Fast histogram optimized approximate greedy algorithm.
      case hist // = 4
      case UNRECOGNIZED(Int)

      package init() {
        self = .unspecified
      }

      package init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .unspecified
        case 1: self = .auto
        case 2: self = .exact
        case 3: self = .approx
        case 4: self = .hist
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      package var rawValue: Int {
        switch self {
        case .unspecified: return 0
        case .auto: return 1
        case .exact: return 2
        case .approx: return 3
        case .hist: return 4
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      package static let allCases: [Google_Cloud_Bigquery_V2_Model.BoostedTreeOptionEnums.TreeMethod] = [
        .unspecified,
        .auto,
        .exact,
        .approx,
        .hist,
      ]

    }

    package init() {}
  }

  /// Enums for hyperparameter tuning.
  package struct HparamTuningEnums: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    /// Available evaluation metrics used as hyperparameter tuning objectives.
    package enum HparamTuningObjective: SwiftProtobuf.Enum, Swift.CaseIterable {
      package typealias RawValue = Int

      /// Unspecified evaluation metric.
      case unspecified // = 0

      /// Mean absolute error.
      /// mean_absolute_error = AVG(ABS(label - predicted))
      case meanAbsoluteError // = 1

      /// Mean squared error.
      /// mean_squared_error = AVG(POW(label - predicted, 2))
      case meanSquaredError // = 2

      /// Mean squared log error.
      /// mean_squared_log_error = AVG(POW(LN(1 + label) - LN(1 + predicted), 2))
      case meanSquaredLogError // = 3

      /// Mean absolute error.
      /// median_absolute_error = APPROX_QUANTILES(absolute_error, 2)[OFFSET(1)]
      case medianAbsoluteError // = 4

      /// R^2 score. This corresponds to r2_score in ML.EVALUATE.
      /// r_squared = 1 - SUM(squared_error)/(COUNT(label)*VAR_POP(label))
      case rSquared // = 5

      /// Explained variance.
      /// explained_variance = 1 - VAR_POP(label_error)/VAR_POP(label)
      case explainedVariance // = 6

      /// Precision is the fraction of actual positive predictions that had
      /// positive actual labels. For multiclass this is a macro-averaged metric
      /// treating each class as a binary classifier.
      case precision // = 7

      /// Recall is the fraction of actual positive labels that were given a
      /// positive prediction. For multiclass this is a macro-averaged metric.
      case recall // = 8

      /// Accuracy is the fraction of predictions given the correct label. For
      /// multiclass this is a globally micro-averaged metric.
      case accuracy // = 9

      /// The F1 score is an average of recall and precision. For multiclass this
      /// is a macro-averaged metric.
      case f1Score // = 10

      /// Logorithmic Loss. For multiclass this is a macro-averaged metric.
      case logLoss // = 11

      /// Area Under an ROC Curve. For multiclass this is a macro-averaged
      /// metric.
      case rocAuc // = 12

      /// Davies-Bouldin Index.
      case daviesBouldinIndex // = 13

      /// Mean Average Precision.
      case meanAveragePrecision // = 14

      /// Normalized Discounted Cumulative Gain.
      case normalizedDiscountedCumulativeGain // = 15

      /// Average Rank.
      case averageRank // = 16
      case UNRECOGNIZED(Int)

      package init() {
        self = .unspecified
      }

      package init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .unspecified
        case 1: self = .meanAbsoluteError
        case 2: self = .meanSquaredError
        case 3: self = .meanSquaredLogError
        case 4: self = .medianAbsoluteError
        case 5: self = .rSquared
        case 6: self = .explainedVariance
        case 7: self = .precision
        case 8: self = .recall
        case 9: self = .accuracy
        case 10: self = .f1Score
        case 11: self = .logLoss
        case 12: self = .rocAuc
        case 13: self = .daviesBouldinIndex
        case 14: self = .meanAveragePrecision
        case 15: self = .normalizedDiscountedCumulativeGain
        case 16: self = .averageRank
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      package var rawValue: Int {
        switch self {
        case .unspecified: return 0
        case .meanAbsoluteError: return 1
        case .meanSquaredError: return 2
        case .meanSquaredLogError: return 3
        case .medianAbsoluteError: return 4
        case .rSquared: return 5
        case .explainedVariance: return 6
        case .precision: return 7
        case .recall: return 8
        case .accuracy: return 9
        case .f1Score: return 10
        case .logLoss: return 11
        case .rocAuc: return 12
        case .daviesBouldinIndex: return 13
        case .meanAveragePrecision: return 14
        case .normalizedDiscountedCumulativeGain: return 15
        case .averageRank: return 16
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      package static let allCases: [Google_Cloud_Bigquery_V2_Model.HparamTuningEnums.HparamTuningObjective] = [
        .unspecified,
        .meanAbsoluteError,
        .meanSquaredError,
        .meanSquaredLogError,
        .medianAbsoluteError,
        .rSquared,
        .explainedVariance,
        .precision,
        .recall,
        .accuracy,
        .f1Score,
        .logLoss,
        .rocAuc,
        .daviesBouldinIndex,
        .meanAveragePrecision,
        .normalizedDiscountedCumulativeGain,
        .averageRank,
      ]

    }

    package init() {}
  }

  /// Evaluation metrics for regression and explicit feedback type matrix
  /// factorization models.
  package struct RegressionMetrics: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Mean absolute error.
    package var meanAbsoluteError: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _meanAbsoluteError ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_meanAbsoluteError = newValue}
    }
    /// Returns true if `meanAbsoluteError` has been explicitly set.
    package var hasMeanAbsoluteError: Bool {return self._meanAbsoluteError != nil}
    /// Clears the value of `meanAbsoluteError`. Subsequent reads from it will return its default value.
    package mutating func clearMeanAbsoluteError() {self._meanAbsoluteError = nil}

    /// Mean squared error.
    package var meanSquaredError: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _meanSquaredError ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_meanSquaredError = newValue}
    }
    /// Returns true if `meanSquaredError` has been explicitly set.
    package var hasMeanSquaredError: Bool {return self._meanSquaredError != nil}
    /// Clears the value of `meanSquaredError`. Subsequent reads from it will return its default value.
    package mutating func clearMeanSquaredError() {self._meanSquaredError = nil}

    /// Mean squared log error.
    package var meanSquaredLogError: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _meanSquaredLogError ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_meanSquaredLogError = newValue}
    }
    /// Returns true if `meanSquaredLogError` has been explicitly set.
    package var hasMeanSquaredLogError: Bool {return self._meanSquaredLogError != nil}
    /// Clears the value of `meanSquaredLogError`. Subsequent reads from it will return its default value.
    package mutating func clearMeanSquaredLogError() {self._meanSquaredLogError = nil}

    /// Median absolute error.
    package var medianAbsoluteError: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _medianAbsoluteError ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_medianAbsoluteError = newValue}
    }
    /// Returns true if `medianAbsoluteError` has been explicitly set.
    package var hasMedianAbsoluteError: Bool {return self._medianAbsoluteError != nil}
    /// Clears the value of `medianAbsoluteError`. Subsequent reads from it will return its default value.
    package mutating func clearMedianAbsoluteError() {self._medianAbsoluteError = nil}

    /// R^2 score. This corresponds to r2_score in ML.EVALUATE.
    package var rSquared: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _rSquared ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_rSquared = newValue}
    }
    /// Returns true if `rSquared` has been explicitly set.
    package var hasRSquared: Bool {return self._rSquared != nil}
    /// Clears the value of `rSquared`. Subsequent reads from it will return its default value.
    package mutating func clearRSquared() {self._rSquared = nil}

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    package init() {}

    fileprivate var _meanAbsoluteError: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    fileprivate var _meanSquaredError: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    fileprivate var _meanSquaredLogError: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    fileprivate var _medianAbsoluteError: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    fileprivate var _rSquared: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
  }

  /// Aggregate metrics for classification/classifier models. For multi-class
  /// models, the metrics are either macro-averaged or micro-averaged. When
  /// macro-averaged, the metrics are calculated for each label and then an
  /// unweighted average is taken of those values. When micro-averaged, the
  /// metric is calculated globally by counting the total number of correctly
  /// predicted rows.
  package struct AggregateClassificationMetrics: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Precision is the fraction of actual positive predictions that had
    /// positive actual labels. For multiclass this is a macro-averaged
    /// metric treating each class as a binary classifier.
    package var precision: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _precision ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_precision = newValue}
    }
    /// Returns true if `precision` has been explicitly set.
    package var hasPrecision: Bool {return self._precision != nil}
    /// Clears the value of `precision`. Subsequent reads from it will return its default value.
    package mutating func clearPrecision() {self._precision = nil}

    /// Recall is the fraction of actual positive labels that were given a
    /// positive prediction. For multiclass this is a macro-averaged metric.
    package var recall: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _recall ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_recall = newValue}
    }
    /// Returns true if `recall` has been explicitly set.
    package var hasRecall: Bool {return self._recall != nil}
    /// Clears the value of `recall`. Subsequent reads from it will return its default value.
    package mutating func clearRecall() {self._recall = nil}

    /// Accuracy is the fraction of predictions given the correct label. For
    /// multiclass this is a micro-averaged metric.
    package var accuracy: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _accuracy ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_accuracy = newValue}
    }
    /// Returns true if `accuracy` has been explicitly set.
    package var hasAccuracy: Bool {return self._accuracy != nil}
    /// Clears the value of `accuracy`. Subsequent reads from it will return its default value.
    package mutating func clearAccuracy() {self._accuracy = nil}

    /// Threshold at which the metrics are computed. For binary
    /// classification models this is the positive class threshold.
    /// For multi-class classfication models this is the confidence
    /// threshold.
    package var threshold: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _threshold ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_threshold = newValue}
    }
    /// Returns true if `threshold` has been explicitly set.
    package var hasThreshold: Bool {return self._threshold != nil}
    /// Clears the value of `threshold`. Subsequent reads from it will return its default value.
    package mutating func clearThreshold() {self._threshold = nil}

    /// The F1 score is an average of recall and precision. For multiclass
    /// this is a macro-averaged metric.
    package var f1Score: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _f1Score ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_f1Score = newValue}
    }
    /// Returns true if `f1Score` has been explicitly set.
    package var hasF1Score: Bool {return self._f1Score != nil}
    /// Clears the value of `f1Score`. Subsequent reads from it will return its default value.
    package mutating func clearF1Score() {self._f1Score = nil}

    /// Logarithmic Loss. For multiclass this is a macro-averaged metric.
    package var logLoss: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _logLoss ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_logLoss = newValue}
    }
    /// Returns true if `logLoss` has been explicitly set.
    package var hasLogLoss: Bool {return self._logLoss != nil}
    /// Clears the value of `logLoss`. Subsequent reads from it will return its default value.
    package mutating func clearLogLoss() {self._logLoss = nil}

    /// Area Under a ROC Curve. For multiclass this is a macro-averaged
    /// metric.
    package var rocAuc: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _rocAuc ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_rocAuc = newValue}
    }
    /// Returns true if `rocAuc` has been explicitly set.
    package var hasRocAuc: Bool {return self._rocAuc != nil}
    /// Clears the value of `rocAuc`. Subsequent reads from it will return its default value.
    package mutating func clearRocAuc() {self._rocAuc = nil}

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    package init() {}

    fileprivate var _precision: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    fileprivate var _recall: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    fileprivate var _accuracy: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    fileprivate var _threshold: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    fileprivate var _f1Score: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    fileprivate var _logLoss: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    fileprivate var _rocAuc: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
  }

  /// Evaluation metrics for binary classification/classifier models.
  package struct BinaryClassificationMetrics: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Aggregate classification metrics.
    package var aggregateClassificationMetrics: Google_Cloud_Bigquery_V2_Model.AggregateClassificationMetrics {
      get {return _aggregateClassificationMetrics ?? Google_Cloud_Bigquery_V2_Model.AggregateClassificationMetrics()}
      set {_aggregateClassificationMetrics = newValue}
    }
    /// Returns true if `aggregateClassificationMetrics` has been explicitly set.
    package var hasAggregateClassificationMetrics: Bool {return self._aggregateClassificationMetrics != nil}
    /// Clears the value of `aggregateClassificationMetrics`. Subsequent reads from it will return its default value.
    package mutating func clearAggregateClassificationMetrics() {self._aggregateClassificationMetrics = nil}

    /// Binary confusion matrix at multiple thresholds.
    package var binaryConfusionMatrixList: [Google_Cloud_Bigquery_V2_Model.BinaryClassificationMetrics.BinaryConfusionMatrix] = []

    /// Label representing the positive class.
    package var positiveLabel: String = String()

    /// Label representing the negative class.
    package var negativeLabel: String = String()

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    /// Confusion matrix for binary classification models.
    package struct BinaryConfusionMatrix: Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      /// Threshold value used when computing each of the following metric.
      package var positiveClassThreshold: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _positiveClassThreshold ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_positiveClassThreshold = newValue}
      }
      /// Returns true if `positiveClassThreshold` has been explicitly set.
      package var hasPositiveClassThreshold: Bool {return self._positiveClassThreshold != nil}
      /// Clears the value of `positiveClassThreshold`. Subsequent reads from it will return its default value.
      package mutating func clearPositiveClassThreshold() {self._positiveClassThreshold = nil}

      /// Number of true samples predicted as true.
      package var truePositives: SwiftProtobuf.Google_Protobuf_Int64Value {
        get {return _truePositives ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
        set {_truePositives = newValue}
      }
      /// Returns true if `truePositives` has been explicitly set.
      package var hasTruePositives: Bool {return self._truePositives != nil}
      /// Clears the value of `truePositives`. Subsequent reads from it will return its default value.
      package mutating func clearTruePositives() {self._truePositives = nil}

      /// Number of false samples predicted as true.
      package var falsePositives: SwiftProtobuf.Google_Protobuf_Int64Value {
        get {return _falsePositives ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
        set {_falsePositives = newValue}
      }
      /// Returns true if `falsePositives` has been explicitly set.
      package var hasFalsePositives: Bool {return self._falsePositives != nil}
      /// Clears the value of `falsePositives`. Subsequent reads from it will return its default value.
      package mutating func clearFalsePositives() {self._falsePositives = nil}

      /// Number of true samples predicted as false.
      package var trueNegatives: SwiftProtobuf.Google_Protobuf_Int64Value {
        get {return _trueNegatives ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
        set {_trueNegatives = newValue}
      }
      /// Returns true if `trueNegatives` has been explicitly set.
      package var hasTrueNegatives: Bool {return self._trueNegatives != nil}
      /// Clears the value of `trueNegatives`. Subsequent reads from it will return its default value.
      package mutating func clearTrueNegatives() {self._trueNegatives = nil}

      /// Number of false samples predicted as false.
      package var falseNegatives: SwiftProtobuf.Google_Protobuf_Int64Value {
        get {return _falseNegatives ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
        set {_falseNegatives = newValue}
      }
      /// Returns true if `falseNegatives` has been explicitly set.
      package var hasFalseNegatives: Bool {return self._falseNegatives != nil}
      /// Clears the value of `falseNegatives`. Subsequent reads from it will return its default value.
      package mutating func clearFalseNegatives() {self._falseNegatives = nil}

      /// The fraction of actual positive predictions that had positive actual
      /// labels.
      package var precision: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _precision ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_precision = newValue}
      }
      /// Returns true if `precision` has been explicitly set.
      package var hasPrecision: Bool {return self._precision != nil}
      /// Clears the value of `precision`. Subsequent reads from it will return its default value.
      package mutating func clearPrecision() {self._precision = nil}

      /// The fraction of actual positive labels that were given a positive
      /// prediction.
      package var recall: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _recall ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_recall = newValue}
      }
      /// Returns true if `recall` has been explicitly set.
      package var hasRecall: Bool {return self._recall != nil}
      /// Clears the value of `recall`. Subsequent reads from it will return its default value.
      package mutating func clearRecall() {self._recall = nil}

      /// The equally weighted average of recall and precision.
      package var f1Score: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _f1Score ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_f1Score = newValue}
      }
      /// Returns true if `f1Score` has been explicitly set.
      package var hasF1Score: Bool {return self._f1Score != nil}
      /// Clears the value of `f1Score`. Subsequent reads from it will return its default value.
      package mutating func clearF1Score() {self._f1Score = nil}

      /// The fraction of predictions given the correct label.
      package var accuracy: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _accuracy ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_accuracy = newValue}
      }
      /// Returns true if `accuracy` has been explicitly set.
      package var hasAccuracy: Bool {return self._accuracy != nil}
      /// Clears the value of `accuracy`. Subsequent reads from it will return its default value.
      package mutating func clearAccuracy() {self._accuracy = nil}

      package var unknownFields = SwiftProtobuf.UnknownStorage()

      package init() {}

      fileprivate var _positiveClassThreshold: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
      fileprivate var _truePositives: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
      fileprivate var _falsePositives: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
      fileprivate var _trueNegatives: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
      fileprivate var _falseNegatives: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
      fileprivate var _precision: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
      fileprivate var _recall: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
      fileprivate var _f1Score: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
      fileprivate var _accuracy: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    }

    package init() {}

    fileprivate var _aggregateClassificationMetrics: Google_Cloud_Bigquery_V2_Model.AggregateClassificationMetrics? = nil
  }

  /// Evaluation metrics for multi-class classification/classifier models.
  package struct MultiClassClassificationMetrics: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Aggregate classification metrics.
    package var aggregateClassificationMetrics: Google_Cloud_Bigquery_V2_Model.AggregateClassificationMetrics {
      get {return _aggregateClassificationMetrics ?? Google_Cloud_Bigquery_V2_Model.AggregateClassificationMetrics()}
      set {_aggregateClassificationMetrics = newValue}
    }
    /// Returns true if `aggregateClassificationMetrics` has been explicitly set.
    package var hasAggregateClassificationMetrics: Bool {return self._aggregateClassificationMetrics != nil}
    /// Clears the value of `aggregateClassificationMetrics`. Subsequent reads from it will return its default value.
    package mutating func clearAggregateClassificationMetrics() {self._aggregateClassificationMetrics = nil}

    /// Confusion matrix at different thresholds.
    package var confusionMatrixList: [Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics.ConfusionMatrix] = []

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    /// Confusion matrix for multi-class classification models.
    package struct ConfusionMatrix: Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      /// Confidence threshold used when computing the entries of the
      /// confusion matrix.
      package var confidenceThreshold: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _confidenceThreshold ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_confidenceThreshold = newValue}
      }
      /// Returns true if `confidenceThreshold` has been explicitly set.
      package var hasConfidenceThreshold: Bool {return self._confidenceThreshold != nil}
      /// Clears the value of `confidenceThreshold`. Subsequent reads from it will return its default value.
      package mutating func clearConfidenceThreshold() {self._confidenceThreshold = nil}

      /// One row per actual label.
      package var rows: [Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics.ConfusionMatrix.Row] = []

      package var unknownFields = SwiftProtobuf.UnknownStorage()

      /// A single entry in the confusion matrix.
      package struct Entry: Sendable {
        // SwiftProtobuf.Message conformance is added in an extension below. See the
        // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
        // methods supported on all messages.

        /// The predicted label. For confidence_threshold > 0, we will
        /// also add an entry indicating the number of items under the
        /// confidence threshold.
        package var predictedLabel: String = String()

        /// Number of items being predicted as this label.
        package var itemCount: SwiftProtobuf.Google_Protobuf_Int64Value {
          get {return _itemCount ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
          set {_itemCount = newValue}
        }
        /// Returns true if `itemCount` has been explicitly set.
        package var hasItemCount: Bool {return self._itemCount != nil}
        /// Clears the value of `itemCount`. Subsequent reads from it will return its default value.
        package mutating func clearItemCount() {self._itemCount = nil}

        package var unknownFields = SwiftProtobuf.UnknownStorage()

        package init() {}

        fileprivate var _itemCount: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
      }

      /// A single row in the confusion matrix.
      package struct Row: Sendable {
        // SwiftProtobuf.Message conformance is added in an extension below. See the
        // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
        // methods supported on all messages.

        /// The original label of this row.
        package var actualLabel: String = String()

        /// Info describing predicted label distribution.
        package var entries: [Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics.ConfusionMatrix.Entry] = []

        package var unknownFields = SwiftProtobuf.UnknownStorage()

        package init() {}
      }

      package init() {}

      fileprivate var _confidenceThreshold: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    }

    package init() {}

    fileprivate var _aggregateClassificationMetrics: Google_Cloud_Bigquery_V2_Model.AggregateClassificationMetrics? = nil
  }

  /// Evaluation metrics for clustering models.
  package struct ClusteringMetrics: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Davies-Bouldin index.
    package var daviesBouldinIndex: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _daviesBouldinIndex ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_daviesBouldinIndex = newValue}
    }
    /// Returns true if `daviesBouldinIndex` has been explicitly set.
    package var hasDaviesBouldinIndex: Bool {return self._daviesBouldinIndex != nil}
    /// Clears the value of `daviesBouldinIndex`. Subsequent reads from it will return its default value.
    package mutating func clearDaviesBouldinIndex() {self._daviesBouldinIndex = nil}

    /// Mean of squared distances between each sample to its cluster centroid.
    package var meanSquaredDistance: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _meanSquaredDistance ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_meanSquaredDistance = newValue}
    }
    /// Returns true if `meanSquaredDistance` has been explicitly set.
    package var hasMeanSquaredDistance: Bool {return self._meanSquaredDistance != nil}
    /// Clears the value of `meanSquaredDistance`. Subsequent reads from it will return its default value.
    package mutating func clearMeanSquaredDistance() {self._meanSquaredDistance = nil}

    /// Information for all clusters.
    package var clusters: [Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster] = []

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    /// Message containing the information about one cluster.
    package struct Cluster: Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      /// Centroid id.
      package var centroidID: Int64 = 0

      /// Values of highly variant features for this cluster.
      package var featureValues: [Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster.FeatureValue] = []

      /// Count of training data rows that were assigned to this cluster.
      package var count: SwiftProtobuf.Google_Protobuf_Int64Value {
        get {return _count ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
        set {_count = newValue}
      }
      /// Returns true if `count` has been explicitly set.
      package var hasCount: Bool {return self._count != nil}
      /// Clears the value of `count`. Subsequent reads from it will return its default value.
      package mutating func clearCount() {self._count = nil}

      package var unknownFields = SwiftProtobuf.UnknownStorage()

      /// Representative value of a single feature within the cluster.
      package struct FeatureValue: Sendable {
        // SwiftProtobuf.Message conformance is added in an extension below. See the
        // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
        // methods supported on all messages.

        /// The feature column name.
        package var featureColumn: String = String()

        /// Value.
        package var value: Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster.FeatureValue.OneOf_Value? = nil

        /// The numerical feature value. This is the centroid value for this
        /// feature.
        package var numericalValue: SwiftProtobuf.Google_Protobuf_DoubleValue {
          get {
            if case .numericalValue(let v)? = value {return v}
            return SwiftProtobuf.Google_Protobuf_DoubleValue()
          }
          set {value = .numericalValue(newValue)}
        }

        /// The categorical feature value.
        package var categoricalValue: Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster.FeatureValue.CategoricalValue {
          get {
            if case .categoricalValue(let v)? = value {return v}
            return Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster.FeatureValue.CategoricalValue()
          }
          set {value = .categoricalValue(newValue)}
        }

        package var unknownFields = SwiftProtobuf.UnknownStorage()

        /// Value.
        package enum OneOf_Value: Equatable, Sendable {
          /// The numerical feature value. This is the centroid value for this
          /// feature.
          case numericalValue(SwiftProtobuf.Google_Protobuf_DoubleValue)
          /// The categorical feature value.
          case categoricalValue(Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster.FeatureValue.CategoricalValue)

        }

        /// Representative value of a categorical feature.
        package struct CategoricalValue: Sendable {
          // SwiftProtobuf.Message conformance is added in an extension below. See the
          // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
          // methods supported on all messages.

          /// Counts of all categories for the categorical feature. If there are
          /// more than ten categories, we return top ten (by count) and return
          /// one more CategoryCount with category "_OTHER_" and count as
          /// aggregate counts of remaining categories.
          package var categoryCounts: [Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster.FeatureValue.CategoricalValue.CategoryCount] = []

          package var unknownFields = SwiftProtobuf.UnknownStorage()

          /// Represents the count of a single category within the cluster.
          package struct CategoryCount: Sendable {
            // SwiftProtobuf.Message conformance is added in an extension below. See the
            // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
            // methods supported on all messages.

            /// The name of category.
            package var category: String = String()

            /// The count of training samples matching the category within the
            /// cluster.
            package var count: SwiftProtobuf.Google_Protobuf_Int64Value {
              get {return _count ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
              set {_count = newValue}
            }
            /// Returns true if `count` has been explicitly set.
            package var hasCount: Bool {return self._count != nil}
            /// Clears the value of `count`. Subsequent reads from it will return its default value.
            package mutating func clearCount() {self._count = nil}

            package var unknownFields = SwiftProtobuf.UnknownStorage()

            package init() {}

            fileprivate var _count: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
          }

          package init() {}
        }

        package init() {}
      }

      package init() {}

      fileprivate var _count: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    }

    package init() {}

    fileprivate var _daviesBouldinIndex: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    fileprivate var _meanSquaredDistance: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
  }

  /// Evaluation metrics used by weighted-ALS models specified by
  /// feedback_type=implicit.
  package struct RankingMetrics: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Calculates a precision per user for all the items by ranking them and
    /// then averages all the precisions across all the users.
    package var meanAveragePrecision: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _meanAveragePrecision ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_meanAveragePrecision = newValue}
    }
    /// Returns true if `meanAveragePrecision` has been explicitly set.
    package var hasMeanAveragePrecision: Bool {return self._meanAveragePrecision != nil}
    /// Clears the value of `meanAveragePrecision`. Subsequent reads from it will return its default value.
    package mutating func clearMeanAveragePrecision() {self._meanAveragePrecision = nil}

    /// Similar to the mean squared error computed in regression and explicit
    /// recommendation models except instead of computing the rating directly,
    /// the output from evaluate is computed against a preference which is 1 or 0
    /// depending on if the rating exists or not.
    package var meanSquaredError: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _meanSquaredError ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_meanSquaredError = newValue}
    }
    /// Returns true if `meanSquaredError` has been explicitly set.
    package var hasMeanSquaredError: Bool {return self._meanSquaredError != nil}
    /// Clears the value of `meanSquaredError`. Subsequent reads from it will return its default value.
    package mutating func clearMeanSquaredError() {self._meanSquaredError = nil}

    /// A metric to determine the goodness of a ranking calculated from the
    /// predicted confidence by comparing it to an ideal rank measured by the
    /// original ratings.
    package var normalizedDiscountedCumulativeGain: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _normalizedDiscountedCumulativeGain ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_normalizedDiscountedCumulativeGain = newValue}
    }
    /// Returns true if `normalizedDiscountedCumulativeGain` has been explicitly set.
    package var hasNormalizedDiscountedCumulativeGain: Bool {return self._normalizedDiscountedCumulativeGain != nil}
    /// Clears the value of `normalizedDiscountedCumulativeGain`. Subsequent reads from it will return its default value.
    package mutating func clearNormalizedDiscountedCumulativeGain() {self._normalizedDiscountedCumulativeGain = nil}

    /// Determines the goodness of a ranking by computing the percentile rank
    /// from the predicted confidence and dividing it by the original rank.
    package var averageRank: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _averageRank ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_averageRank = newValue}
    }
    /// Returns true if `averageRank` has been explicitly set.
    package var hasAverageRank: Bool {return self._averageRank != nil}
    /// Clears the value of `averageRank`. Subsequent reads from it will return its default value.
    package mutating func clearAverageRank() {self._averageRank = nil}

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    package init() {}

    fileprivate var _meanAveragePrecision: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    fileprivate var _meanSquaredError: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    fileprivate var _normalizedDiscountedCumulativeGain: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    fileprivate var _averageRank: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
  }

  /// Model evaluation metrics for ARIMA forecasting models.
  package struct ArimaForecastingMetrics: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Repeated as there can be many metric sets (one for each model) in
    /// auto-arima and the large-scale case.
    package var arimaSingleModelForecastingMetrics: [Google_Cloud_Bigquery_V2_Model.ArimaForecastingMetrics.ArimaSingleModelForecastingMetrics] = []

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    /// Model evaluation metrics for a single ARIMA forecasting model.
    package struct ArimaSingleModelForecastingMetrics: Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      /// Non-seasonal order.
      package var nonSeasonalOrder: Google_Cloud_Bigquery_V2_Model.ArimaOrder {
        get {return _nonSeasonalOrder ?? Google_Cloud_Bigquery_V2_Model.ArimaOrder()}
        set {_nonSeasonalOrder = newValue}
      }
      /// Returns true if `nonSeasonalOrder` has been explicitly set.
      package var hasNonSeasonalOrder: Bool {return self._nonSeasonalOrder != nil}
      /// Clears the value of `nonSeasonalOrder`. Subsequent reads from it will return its default value.
      package mutating func clearNonSeasonalOrder() {self._nonSeasonalOrder = nil}

      /// Arima fitting metrics.
      package var arimaFittingMetrics: Google_Cloud_Bigquery_V2_Model.ArimaFittingMetrics {
        get {return _arimaFittingMetrics ?? Google_Cloud_Bigquery_V2_Model.ArimaFittingMetrics()}
        set {_arimaFittingMetrics = newValue}
      }
      /// Returns true if `arimaFittingMetrics` has been explicitly set.
      package var hasArimaFittingMetrics: Bool {return self._arimaFittingMetrics != nil}
      /// Clears the value of `arimaFittingMetrics`. Subsequent reads from it will return its default value.
      package mutating func clearArimaFittingMetrics() {self._arimaFittingMetrics = nil}

      /// Is arima model fitted with drift or not. It is always false when d
      /// is not 1.
      package var hasDrift_p: SwiftProtobuf.Google_Protobuf_BoolValue {
        get {return _hasDrift_p ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
        set {_hasDrift_p = newValue}
      }
      /// Returns true if `hasDrift_p` has been explicitly set.
      package var hasHasDrift_p: Bool {return self._hasDrift_p != nil}
      /// Clears the value of `hasDrift_p`. Subsequent reads from it will return its default value.
      package mutating func clearHasDrift_p() {self._hasDrift_p = nil}

      /// The time_series_id value for this time series. It will be one of
      /// the unique values from the time_series_id_column specified during
      /// ARIMA model training. Only present when time_series_id_column
      /// training option was used.
      package var timeSeriesID: String = String()

      /// The tuple of time_series_ids identifying this time series. It will
      /// be one of the unique tuples of values present in the
      /// time_series_id_columns specified during ARIMA model training. Only
      /// present when time_series_id_columns training option was used and
      /// the order of values here are same as the order of
      /// time_series_id_columns.
      package var timeSeriesIds: [String] = []

      /// Seasonal periods. Repeated because multiple periods are supported
      /// for one time series.
      package var seasonalPeriods: [Google_Cloud_Bigquery_V2_Model.SeasonalPeriod.SeasonalPeriodType] = []

      /// If true, holiday_effect is a part of time series decomposition result.
      package var hasHolidayEffect_p: SwiftProtobuf.Google_Protobuf_BoolValue {
        get {return _hasHolidayEffect_p ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
        set {_hasHolidayEffect_p = newValue}
      }
      /// Returns true if `hasHolidayEffect_p` has been explicitly set.
      package var hasHasHolidayEffect_p: Bool {return self._hasHolidayEffect_p != nil}
      /// Clears the value of `hasHolidayEffect_p`. Subsequent reads from it will return its default value.
      package mutating func clearHasHolidayEffect_p() {self._hasHolidayEffect_p = nil}

      /// If true, spikes_and_dips is a part of time series decomposition result.
      package var hasSpikesAndDips_p: SwiftProtobuf.Google_Protobuf_BoolValue {
        get {return _hasSpikesAndDips_p ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
        set {_hasSpikesAndDips_p = newValue}
      }
      /// Returns true if `hasSpikesAndDips_p` has been explicitly set.
      package var hasHasSpikesAndDips_p: Bool {return self._hasSpikesAndDips_p != nil}
      /// Clears the value of `hasSpikesAndDips_p`. Subsequent reads from it will return its default value.
      package mutating func clearHasSpikesAndDips_p() {self._hasSpikesAndDips_p = nil}

      /// If true, step_changes is a part of time series decomposition result.
      package var hasStepChanges_p: SwiftProtobuf.Google_Protobuf_BoolValue {
        get {return _hasStepChanges_p ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
        set {_hasStepChanges_p = newValue}
      }
      /// Returns true if `hasStepChanges_p` has been explicitly set.
      package var hasHasStepChanges_p: Bool {return self._hasStepChanges_p != nil}
      /// Clears the value of `hasStepChanges_p`. Subsequent reads from it will return its default value.
      package mutating func clearHasStepChanges_p() {self._hasStepChanges_p = nil}

      package var unknownFields = SwiftProtobuf.UnknownStorage()

      package init() {}

      fileprivate var _nonSeasonalOrder: Google_Cloud_Bigquery_V2_Model.ArimaOrder? = nil
      fileprivate var _arimaFittingMetrics: Google_Cloud_Bigquery_V2_Model.ArimaFittingMetrics? = nil
      fileprivate var _hasDrift_p: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
      fileprivate var _hasHolidayEffect_p: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
      fileprivate var _hasSpikesAndDips_p: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
      fileprivate var _hasStepChanges_p: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    }

    package init() {}
  }

  /// Model evaluation metrics for dimensionality reduction models.
  package struct DimensionalityReductionMetrics: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Total percentage of variance explained by the selected principal
    /// components.
    package var totalExplainedVarianceRatio: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _totalExplainedVarianceRatio ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_totalExplainedVarianceRatio = newValue}
    }
    /// Returns true if `totalExplainedVarianceRatio` has been explicitly set.
    package var hasTotalExplainedVarianceRatio: Bool {return self._totalExplainedVarianceRatio != nil}
    /// Clears the value of `totalExplainedVarianceRatio`. Subsequent reads from it will return its default value.
    package mutating func clearTotalExplainedVarianceRatio() {self._totalExplainedVarianceRatio = nil}

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    package init() {}

    fileprivate var _totalExplainedVarianceRatio: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
  }

  /// Evaluation metrics of a model. These are either computed on all training
  /// data or just the eval data based on whether eval data was used during
  /// training. These are not present for imported models.
  package struct EvaluationMetrics: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Metrics.
    package var metrics: Google_Cloud_Bigquery_V2_Model.EvaluationMetrics.OneOf_Metrics? = nil

    /// Populated for regression models and explicit feedback type matrix
    /// factorization models.
    package var regressionMetrics: Google_Cloud_Bigquery_V2_Model.RegressionMetrics {
      get {
        if case .regressionMetrics(let v)? = metrics {return v}
        return Google_Cloud_Bigquery_V2_Model.RegressionMetrics()
      }
      set {metrics = .regressionMetrics(newValue)}
    }

    /// Populated for binary classification/classifier models.
    package var binaryClassificationMetrics: Google_Cloud_Bigquery_V2_Model.BinaryClassificationMetrics {
      get {
        if case .binaryClassificationMetrics(let v)? = metrics {return v}
        return Google_Cloud_Bigquery_V2_Model.BinaryClassificationMetrics()
      }
      set {metrics = .binaryClassificationMetrics(newValue)}
    }

    /// Populated for multi-class classification/classifier models.
    package var multiClassClassificationMetrics: Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics {
      get {
        if case .multiClassClassificationMetrics(let v)? = metrics {return v}
        return Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics()
      }
      set {metrics = .multiClassClassificationMetrics(newValue)}
    }

    /// Populated for clustering models.
    package var clusteringMetrics: Google_Cloud_Bigquery_V2_Model.ClusteringMetrics {
      get {
        if case .clusteringMetrics(let v)? = metrics {return v}
        return Google_Cloud_Bigquery_V2_Model.ClusteringMetrics()
      }
      set {metrics = .clusteringMetrics(newValue)}
    }

    /// Populated for implicit feedback type matrix factorization models.
    package var rankingMetrics: Google_Cloud_Bigquery_V2_Model.RankingMetrics {
      get {
        if case .rankingMetrics(let v)? = metrics {return v}
        return Google_Cloud_Bigquery_V2_Model.RankingMetrics()
      }
      set {metrics = .rankingMetrics(newValue)}
    }

    /// Populated for ARIMA models.
    package var arimaForecastingMetrics: Google_Cloud_Bigquery_V2_Model.ArimaForecastingMetrics {
      get {
        if case .arimaForecastingMetrics(let v)? = metrics {return v}
        return Google_Cloud_Bigquery_V2_Model.ArimaForecastingMetrics()
      }
      set {metrics = .arimaForecastingMetrics(newValue)}
    }

    /// Evaluation metrics when the model is a dimensionality reduction model,
    /// which currently includes PCA.
    package var dimensionalityReductionMetrics: Google_Cloud_Bigquery_V2_Model.DimensionalityReductionMetrics {
      get {
        if case .dimensionalityReductionMetrics(let v)? = metrics {return v}
        return Google_Cloud_Bigquery_V2_Model.DimensionalityReductionMetrics()
      }
      set {metrics = .dimensionalityReductionMetrics(newValue)}
    }

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    /// Metrics.
    package enum OneOf_Metrics: Equatable, Sendable {
      /// Populated for regression models and explicit feedback type matrix
      /// factorization models.
      case regressionMetrics(Google_Cloud_Bigquery_V2_Model.RegressionMetrics)
      /// Populated for binary classification/classifier models.
      case binaryClassificationMetrics(Google_Cloud_Bigquery_V2_Model.BinaryClassificationMetrics)
      /// Populated for multi-class classification/classifier models.
      case multiClassClassificationMetrics(Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics)
      /// Populated for clustering models.
      case clusteringMetrics(Google_Cloud_Bigquery_V2_Model.ClusteringMetrics)
      /// Populated for implicit feedback type matrix factorization models.
      case rankingMetrics(Google_Cloud_Bigquery_V2_Model.RankingMetrics)
      /// Populated for ARIMA models.
      case arimaForecastingMetrics(Google_Cloud_Bigquery_V2_Model.ArimaForecastingMetrics)
      /// Evaluation metrics when the model is a dimensionality reduction model,
      /// which currently includes PCA.
      case dimensionalityReductionMetrics(Google_Cloud_Bigquery_V2_Model.DimensionalityReductionMetrics)

    }

    package init() {}
  }

  /// Data split result. This contains references to the training and evaluation
  /// data tables that were used to train the model.
  package struct DataSplitResult: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Table reference of the training data after split.
    package var trainingTable: Google_Cloud_Bigquery_V2_TableReference {
      get {return _trainingTable ?? Google_Cloud_Bigquery_V2_TableReference()}
      set {_trainingTable = newValue}
    }
    /// Returns true if `trainingTable` has been explicitly set.
    package var hasTrainingTable: Bool {return self._trainingTable != nil}
    /// Clears the value of `trainingTable`. Subsequent reads from it will return its default value.
    package mutating func clearTrainingTable() {self._trainingTable = nil}

    /// Table reference of the evaluation data after split.
    package var evaluationTable: Google_Cloud_Bigquery_V2_TableReference {
      get {return _evaluationTable ?? Google_Cloud_Bigquery_V2_TableReference()}
      set {_evaluationTable = newValue}
    }
    /// Returns true if `evaluationTable` has been explicitly set.
    package var hasEvaluationTable: Bool {return self._evaluationTable != nil}
    /// Clears the value of `evaluationTable`. Subsequent reads from it will return its default value.
    package mutating func clearEvaluationTable() {self._evaluationTable = nil}

    /// Table reference of the test data after split.
    package var testTable: Google_Cloud_Bigquery_V2_TableReference {
      get {return _testTable ?? Google_Cloud_Bigquery_V2_TableReference()}
      set {_testTable = newValue}
    }
    /// Returns true if `testTable` has been explicitly set.
    package var hasTestTable: Bool {return self._testTable != nil}
    /// Clears the value of `testTable`. Subsequent reads from it will return its default value.
    package mutating func clearTestTable() {self._testTable = nil}

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    package init() {}

    fileprivate var _trainingTable: Google_Cloud_Bigquery_V2_TableReference? = nil
    fileprivate var _evaluationTable: Google_Cloud_Bigquery_V2_TableReference? = nil
    fileprivate var _testTable: Google_Cloud_Bigquery_V2_TableReference? = nil
  }

  /// Arima order, can be used for both non-seasonal and seasonal parts.
  package struct ArimaOrder: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Order of the autoregressive part.
    package var p: SwiftProtobuf.Google_Protobuf_Int64Value {
      get {return _p ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
      set {_p = newValue}
    }
    /// Returns true if `p` has been explicitly set.
    package var hasP: Bool {return self._p != nil}
    /// Clears the value of `p`. Subsequent reads from it will return its default value.
    package mutating func clearP() {self._p = nil}

    /// Order of the differencing part.
    package var d: SwiftProtobuf.Google_Protobuf_Int64Value {
      get {return _d ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
      set {_d = newValue}
    }
    /// Returns true if `d` has been explicitly set.
    package var hasD: Bool {return self._d != nil}
    /// Clears the value of `d`. Subsequent reads from it will return its default value.
    package mutating func clearD() {self._d = nil}

    /// Order of the moving-average part.
    package var q: SwiftProtobuf.Google_Protobuf_Int64Value {
      get {return _q ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
      set {_q = newValue}
    }
    /// Returns true if `q` has been explicitly set.
    package var hasQ: Bool {return self._q != nil}
    /// Clears the value of `q`. Subsequent reads from it will return its default value.
    package mutating func clearQ() {self._q = nil}

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    package init() {}

    fileprivate var _p: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    fileprivate var _d: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    fileprivate var _q: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  }

  /// ARIMA model fitting metrics.
  package struct ArimaFittingMetrics: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Log-likelihood.
    package var logLikelihood: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _logLikelihood ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_logLikelihood = newValue}
    }
    /// Returns true if `logLikelihood` has been explicitly set.
    package var hasLogLikelihood: Bool {return self._logLikelihood != nil}
    /// Clears the value of `logLikelihood`. Subsequent reads from it will return its default value.
    package mutating func clearLogLikelihood() {self._logLikelihood = nil}

    /// AIC.
    package var aic: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _aic ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_aic = newValue}
    }
    /// Returns true if `aic` has been explicitly set.
    package var hasAic: Bool {return self._aic != nil}
    /// Clears the value of `aic`. Subsequent reads from it will return its default value.
    package mutating func clearAic() {self._aic = nil}

    /// Variance.
    package var variance: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _variance ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_variance = newValue}
    }
    /// Returns true if `variance` has been explicitly set.
    package var hasVariance: Bool {return self._variance != nil}
    /// Clears the value of `variance`. Subsequent reads from it will return its default value.
    package mutating func clearVariance() {self._variance = nil}

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    package init() {}

    fileprivate var _logLikelihood: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    fileprivate var _aic: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    fileprivate var _variance: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
  }

  /// Global explanations containing the top most important features
  /// after training.
  package struct GlobalExplanation: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// A list of the top global explanations. Sorted by absolute value of
    /// attribution in descending order.
    package var explanations: [Google_Cloud_Bigquery_V2_Model.GlobalExplanation.Explanation] = []

    /// Class label for this set of global explanations. Will be empty/null for
    /// binary logistic and linear regression models. Sorted alphabetically in
    /// descending order.
    package var classLabel: String = String()

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    /// Explanation for a single feature.
    package struct Explanation: Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      /// The full feature name. For non-numerical features, will be formatted
      /// like `<column_name>.<encoded_feature_name>`. Overall size of feature
      /// name will always be truncated to first 120 characters.
      package var featureName: String = String()

      /// Attribution of feature.
      package var attribution: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _attribution ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_attribution = newValue}
      }
      /// Returns true if `attribution` has been explicitly set.
      package var hasAttribution: Bool {return self._attribution != nil}
      /// Clears the value of `attribution`. Subsequent reads from it will return its default value.
      package mutating func clearAttribution() {self._attribution = nil}

      package var unknownFields = SwiftProtobuf.UnknownStorage()

      package init() {}

      fileprivate var _attribution: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    }

    package init() {}
  }

  /// Encoding methods for categorical features.
  package struct CategoryEncodingMethod: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    /// Supported encoding methods for categorical features.
    package enum EncodingMethod: SwiftProtobuf.Enum, Swift.CaseIterable {
      package typealias RawValue = Int

      /// Unspecified encoding method.
      case unspecified // = 0

      /// Applies one-hot encoding.
      case oneHotEncoding // = 1

      /// Applies label encoding.
      case labelEncoding // = 2

      /// Applies dummy encoding.
      case dummyEncoding // = 3
      case UNRECOGNIZED(Int)

      package init() {
        self = .unspecified
      }

      package init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .unspecified
        case 1: self = .oneHotEncoding
        case 2: self = .labelEncoding
        case 3: self = .dummyEncoding
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      package var rawValue: Int {
        switch self {
        case .unspecified: return 0
        case .oneHotEncoding: return 1
        case .labelEncoding: return 2
        case .dummyEncoding: return 3
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      package static let allCases: [Google_Cloud_Bigquery_V2_Model.CategoryEncodingMethod.EncodingMethod] = [
        .unspecified,
        .oneHotEncoding,
        .labelEncoding,
        .dummyEncoding,
      ]

    }

    package init() {}
  }

  /// PCA solver options.
  package struct PcaSolverOptionEnums: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    /// Enums for supported PCA solvers.
    package enum PcaSolver: SwiftProtobuf.Enum, Swift.CaseIterable {
      package typealias RawValue = Int

      /// Default value.
      case unspecified // = 0

      /// Full eigen-decoposition.
      case full // = 1

      /// Randomized SVD.
      case randomized // = 2

      /// Auto.
      case auto // = 3
      case UNRECOGNIZED(Int)

      package init() {
        self = .unspecified
      }

      package init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .unspecified
        case 1: self = .full
        case 2: self = .randomized
        case 3: self = .auto
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      package var rawValue: Int {
        switch self {
        case .unspecified: return 0
        case .full: return 1
        case .randomized: return 2
        case .auto: return 3
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      package static let allCases: [Google_Cloud_Bigquery_V2_Model.PcaSolverOptionEnums.PcaSolver] = [
        .unspecified,
        .full,
        .randomized,
        .auto,
      ]

    }

    package init() {}
  }

  /// Model registry options.
  package struct ModelRegistryOptionEnums: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    /// Enums for supported model registries.
    package enum ModelRegistry: SwiftProtobuf.Enum, Swift.CaseIterable {
      package typealias RawValue = Int

      /// Default value.
      case unspecified // = 0

      /// Vertex AI.
      case vertexAi // = 1
      case UNRECOGNIZED(Int)

      package init() {
        self = .unspecified
      }

      package init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .unspecified
        case 1: self = .vertexAi
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      package var rawValue: Int {
        switch self {
        case .unspecified: return 0
        case .vertexAi: return 1
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      package static let allCases: [Google_Cloud_Bigquery_V2_Model.ModelRegistryOptionEnums.ModelRegistry] = [
        .unspecified,
        .vertexAi,
      ]

    }

    package init() {}
  }

  /// Information about a single training query run for the model.
  package struct TrainingRun: @unchecked Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Output only. Options that were used for this training run, includes
    /// user specified and default options that were used.
    package var trainingOptions: Google_Cloud_Bigquery_V2_Model.TrainingRun.TrainingOptions {
      get {return _storage._trainingOptions ?? Google_Cloud_Bigquery_V2_Model.TrainingRun.TrainingOptions()}
      set {_uniqueStorage()._trainingOptions = newValue}
    }
    /// Returns true if `trainingOptions` has been explicitly set.
    package var hasTrainingOptions: Bool {return _storage._trainingOptions != nil}
    /// Clears the value of `trainingOptions`. Subsequent reads from it will return its default value.
    package mutating func clearTrainingOptions() {_uniqueStorage()._trainingOptions = nil}

    /// Output only. The start time of this training run.
    package var startTime: SwiftProtobuf.Google_Protobuf_Timestamp {
      get {return _storage._startTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
      set {_uniqueStorage()._startTime = newValue}
    }
    /// Returns true if `startTime` has been explicitly set.
    package var hasStartTime: Bool {return _storage._startTime != nil}
    /// Clears the value of `startTime`. Subsequent reads from it will return its default value.
    package mutating func clearStartTime() {_uniqueStorage()._startTime = nil}

    /// Output only. Output of each iteration run, results.size() <=
    /// max_iterations.
    package var results: [Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult] {
      get {return _storage._results}
      set {_uniqueStorage()._results = newValue}
    }

    /// Output only. The evaluation metrics over training/eval data that were
    /// computed at the end of training.
    package var evaluationMetrics: Google_Cloud_Bigquery_V2_Model.EvaluationMetrics {
      get {return _storage._evaluationMetrics ?? Google_Cloud_Bigquery_V2_Model.EvaluationMetrics()}
      set {_uniqueStorage()._evaluationMetrics = newValue}
    }
    /// Returns true if `evaluationMetrics` has been explicitly set.
    package var hasEvaluationMetrics: Bool {return _storage._evaluationMetrics != nil}
    /// Clears the value of `evaluationMetrics`. Subsequent reads from it will return its default value.
    package mutating func clearEvaluationMetrics() {_uniqueStorage()._evaluationMetrics = nil}

    /// Output only. Data split result of the training run. Only set when the
    /// input data is actually split.
    package var dataSplitResult: Google_Cloud_Bigquery_V2_Model.DataSplitResult {
      get {return _storage._dataSplitResult ?? Google_Cloud_Bigquery_V2_Model.DataSplitResult()}
      set {_uniqueStorage()._dataSplitResult = newValue}
    }
    /// Returns true if `dataSplitResult` has been explicitly set.
    package var hasDataSplitResult: Bool {return _storage._dataSplitResult != nil}
    /// Clears the value of `dataSplitResult`. Subsequent reads from it will return its default value.
    package mutating func clearDataSplitResult() {_uniqueStorage()._dataSplitResult = nil}

    /// Output only. Global explanation contains the explanation of top features
    /// on the model level. Applies to both regression and classification models.
    package var modelLevelGlobalExplanation: Google_Cloud_Bigquery_V2_Model.GlobalExplanation {
      get {return _storage._modelLevelGlobalExplanation ?? Google_Cloud_Bigquery_V2_Model.GlobalExplanation()}
      set {_uniqueStorage()._modelLevelGlobalExplanation = newValue}
    }
    /// Returns true if `modelLevelGlobalExplanation` has been explicitly set.
    package var hasModelLevelGlobalExplanation: Bool {return _storage._modelLevelGlobalExplanation != nil}
    /// Clears the value of `modelLevelGlobalExplanation`. Subsequent reads from it will return its default value.
    package mutating func clearModelLevelGlobalExplanation() {_uniqueStorage()._modelLevelGlobalExplanation = nil}

    /// Output only. Global explanation contains the explanation of top features
    /// on the class level. Applies to classification models only.
    package var classLevelGlobalExplanations: [Google_Cloud_Bigquery_V2_Model.GlobalExplanation] {
      get {return _storage._classLevelGlobalExplanations}
      set {_uniqueStorage()._classLevelGlobalExplanations = newValue}
    }

    /// The model id in the [Vertex AI Model
    /// Registry](https://cloud.google.com/vertex-ai/docs/model-registry/introduction)
    /// for this training run.
    package var vertexAiModelID: String {
      get {return _storage._vertexAiModelID}
      set {_uniqueStorage()._vertexAiModelID = newValue}
    }

    /// Output only. The model version in the [Vertex AI Model
    /// Registry](https://cloud.google.com/vertex-ai/docs/model-registry/introduction)
    /// for this training run.
    package var vertexAiModelVersion: String {
      get {return _storage._vertexAiModelVersion}
      set {_uniqueStorage()._vertexAiModelVersion = newValue}
    }

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    /// Options used in model training.
    package struct TrainingOptions: @unchecked Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      /// The maximum number of iterations in training. Used only for iterative
      /// training algorithms.
      package var maxIterations: Int64 {
        get {return _storage._maxIterations}
        set {_uniqueStorage()._maxIterations = newValue}
      }

      /// Type of loss function used during training run.
      package var lossType: Google_Cloud_Bigquery_V2_Model.LossType {
        get {return _storage._lossType}
        set {_uniqueStorage()._lossType = newValue}
      }

      /// Learning rate in training. Used only for iterative training algorithms.
      package var learnRate: Double {
        get {return _storage._learnRate}
        set {_uniqueStorage()._learnRate = newValue}
      }

      /// L1 regularization coefficient.
      package var l1Regularization: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _storage._l1Regularization ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_uniqueStorage()._l1Regularization = newValue}
      }
      /// Returns true if `l1Regularization` has been explicitly set.
      package var hasL1Regularization: Bool {return _storage._l1Regularization != nil}
      /// Clears the value of `l1Regularization`. Subsequent reads from it will return its default value.
      package mutating func clearL1Regularization() {_uniqueStorage()._l1Regularization = nil}

      /// L2 regularization coefficient.
      package var l2Regularization: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _storage._l2Regularization ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_uniqueStorage()._l2Regularization = newValue}
      }
      /// Returns true if `l2Regularization` has been explicitly set.
      package var hasL2Regularization: Bool {return _storage._l2Regularization != nil}
      /// Clears the value of `l2Regularization`. Subsequent reads from it will return its default value.
      package mutating func clearL2Regularization() {_uniqueStorage()._l2Regularization = nil}

      /// When early_stop is true, stops training when accuracy improvement is
      /// less than 'min_relative_progress'. Used only for iterative training
      /// algorithms.
      package var minRelativeProgress: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _storage._minRelativeProgress ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_uniqueStorage()._minRelativeProgress = newValue}
      }
      /// Returns true if `minRelativeProgress` has been explicitly set.
      package var hasMinRelativeProgress: Bool {return _storage._minRelativeProgress != nil}
      /// Clears the value of `minRelativeProgress`. Subsequent reads from it will return its default value.
      package mutating func clearMinRelativeProgress() {_uniqueStorage()._minRelativeProgress = nil}

      /// Whether to train a model from the last checkpoint.
      package var warmStart: SwiftProtobuf.Google_Protobuf_BoolValue {
        get {return _storage._warmStart ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
        set {_uniqueStorage()._warmStart = newValue}
      }
      /// Returns true if `warmStart` has been explicitly set.
      package var hasWarmStart: Bool {return _storage._warmStart != nil}
      /// Clears the value of `warmStart`. Subsequent reads from it will return its default value.
      package mutating func clearWarmStart() {_uniqueStorage()._warmStart = nil}

      /// Whether to stop early when the loss doesn't improve significantly
      /// any more (compared to min_relative_progress). Used only for iterative
      /// training algorithms.
      package var earlyStop: SwiftProtobuf.Google_Protobuf_BoolValue {
        get {return _storage._earlyStop ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
        set {_uniqueStorage()._earlyStop = newValue}
      }
      /// Returns true if `earlyStop` has been explicitly set.
      package var hasEarlyStop: Bool {return _storage._earlyStop != nil}
      /// Clears the value of `earlyStop`. Subsequent reads from it will return its default value.
      package mutating func clearEarlyStop() {_uniqueStorage()._earlyStop = nil}

      /// Name of input label columns in training data.
      package var inputLabelColumns: [String] {
        get {return _storage._inputLabelColumns}
        set {_uniqueStorage()._inputLabelColumns = newValue}
      }

      /// The data split type for training and evaluation, e.g. RANDOM.
      package var dataSplitMethod: Google_Cloud_Bigquery_V2_Model.DataSplitMethod {
        get {return _storage._dataSplitMethod}
        set {_uniqueStorage()._dataSplitMethod = newValue}
      }

      /// The fraction of evaluation data over the whole input data. The rest
      /// of data will be used as training data. The format should be double.
      /// Accurate to two decimal places.
      /// Default value is 0.2.
      package var dataSplitEvalFraction: Double {
        get {return _storage._dataSplitEvalFraction}
        set {_uniqueStorage()._dataSplitEvalFraction = newValue}
      }

      /// The column to split data with. This column won't be used as a
      /// feature.
      /// 1. When data_split_method is CUSTOM, the corresponding column should
      /// be boolean. The rows with true value tag are eval data, and the false
      /// are training data.
      /// 2. When data_split_method is SEQ, the first DATA_SPLIT_EVAL_FRACTION
      /// rows (from smallest to largest) in the corresponding column are used
      /// as training data, and the rest are eval data. It respects the order
      /// in Orderable data types:
      /// https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#data-type-properties
      package var dataSplitColumn: String {
        get {return _storage._dataSplitColumn}
        set {_uniqueStorage()._dataSplitColumn = newValue}
      }

      /// The strategy to determine learn rate for the current iteration.
      package var learnRateStrategy: Google_Cloud_Bigquery_V2_Model.LearnRateStrategy {
        get {return _storage._learnRateStrategy}
        set {_uniqueStorage()._learnRateStrategy = newValue}
      }

      /// Specifies the initial learning rate for the line search learn rate
      /// strategy.
      package var initialLearnRate: Double {
        get {return _storage._initialLearnRate}
        set {_uniqueStorage()._initialLearnRate = newValue}
      }

      /// Weights associated with each label class, for rebalancing the
      /// training data. Only applicable for classification models.
      package var labelClassWeights: Dictionary<String,Double> {
        get {return _storage._labelClassWeights}
        set {_uniqueStorage()._labelClassWeights = newValue}
      }

      /// User column specified for matrix factorization models.
      package var userColumn: String {
        get {return _storage._userColumn}
        set {_uniqueStorage()._userColumn = newValue}
      }

      /// Item column specified for matrix factorization models.
      package var itemColumn: String {
        get {return _storage._itemColumn}
        set {_uniqueStorage()._itemColumn = newValue}
      }

      /// Distance type for clustering models.
      package var distanceType: Google_Cloud_Bigquery_V2_Model.DistanceType {
        get {return _storage._distanceType}
        set {_uniqueStorage()._distanceType = newValue}
      }

      /// Number of clusters for clustering models.
      package var numClusters: Int64 {
        get {return _storage._numClusters}
        set {_uniqueStorage()._numClusters = newValue}
      }

      /// Google Cloud Storage URI from which the model was imported. Only
      /// applicable for imported models.
      package var modelUri: String {
        get {return _storage._modelUri}
        set {_uniqueStorage()._modelUri = newValue}
      }

      /// Optimization strategy for training linear regression models.
      package var optimizationStrategy: Google_Cloud_Bigquery_V2_Model.OptimizationStrategy {
        get {return _storage._optimizationStrategy}
        set {_uniqueStorage()._optimizationStrategy = newValue}
      }

      /// Hidden units for dnn models.
      package var hiddenUnits: [Int64] {
        get {return _storage._hiddenUnits}
        set {_uniqueStorage()._hiddenUnits = newValue}
      }

      /// Batch size for dnn models.
      package var batchSize: Int64 {
        get {return _storage._batchSize}
        set {_uniqueStorage()._batchSize = newValue}
      }

      /// Dropout probability for dnn models.
      package var dropout: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _storage._dropout ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_uniqueStorage()._dropout = newValue}
      }
      /// Returns true if `dropout` has been explicitly set.
      package var hasDropout: Bool {return _storage._dropout != nil}
      /// Clears the value of `dropout`. Subsequent reads from it will return its default value.
      package mutating func clearDropout() {_uniqueStorage()._dropout = nil}

      /// Maximum depth of a tree for boosted tree models.
      package var maxTreeDepth: Int64 {
        get {return _storage._maxTreeDepth}
        set {_uniqueStorage()._maxTreeDepth = newValue}
      }

      /// Subsample fraction of the training data to grow tree to prevent
      /// overfitting for boosted tree models.
      package var subsample: Double {
        get {return _storage._subsample}
        set {_uniqueStorage()._subsample = newValue}
      }

      /// Minimum split loss for boosted tree models.
      package var minSplitLoss: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _storage._minSplitLoss ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_uniqueStorage()._minSplitLoss = newValue}
      }
      /// Returns true if `minSplitLoss` has been explicitly set.
      package var hasMinSplitLoss: Bool {return _storage._minSplitLoss != nil}
      /// Clears the value of `minSplitLoss`. Subsequent reads from it will return its default value.
      package mutating func clearMinSplitLoss() {_uniqueStorage()._minSplitLoss = nil}

      /// Booster type for boosted tree models.
      package var boosterType: Google_Cloud_Bigquery_V2_Model.BoostedTreeOptionEnums.BoosterType {
        get {return _storage._boosterType}
        set {_uniqueStorage()._boosterType = newValue}
      }

      /// Number of parallel trees constructed during each iteration for boosted
      /// tree models.
      package var numParallelTree: SwiftProtobuf.Google_Protobuf_Int64Value {
        get {return _storage._numParallelTree ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
        set {_uniqueStorage()._numParallelTree = newValue}
      }
      /// Returns true if `numParallelTree` has been explicitly set.
      package var hasNumParallelTree: Bool {return _storage._numParallelTree != nil}
      /// Clears the value of `numParallelTree`. Subsequent reads from it will return its default value.
      package mutating func clearNumParallelTree() {_uniqueStorage()._numParallelTree = nil}

      /// Type of normalization algorithm for boosted tree models using
      /// dart booster.
      package var dartNormalizeType: Google_Cloud_Bigquery_V2_Model.BoostedTreeOptionEnums.DartNormalizeType {
        get {return _storage._dartNormalizeType}
        set {_uniqueStorage()._dartNormalizeType = newValue}
      }

      /// Tree construction algorithm for boosted tree models.
      package var treeMethod: Google_Cloud_Bigquery_V2_Model.BoostedTreeOptionEnums.TreeMethod {
        get {return _storage._treeMethod}
        set {_uniqueStorage()._treeMethod = newValue}
      }

      /// Minimum sum of instance weight needed in a child for boosted tree
      /// models.
      package var minTreeChildWeight: SwiftProtobuf.Google_Protobuf_Int64Value {
        get {return _storage._minTreeChildWeight ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
        set {_uniqueStorage()._minTreeChildWeight = newValue}
      }
      /// Returns true if `minTreeChildWeight` has been explicitly set.
      package var hasMinTreeChildWeight: Bool {return _storage._minTreeChildWeight != nil}
      /// Clears the value of `minTreeChildWeight`. Subsequent reads from it will return its default value.
      package mutating func clearMinTreeChildWeight() {_uniqueStorage()._minTreeChildWeight = nil}

      /// Subsample ratio of columns when constructing each tree for boosted tree
      /// models.
      package var colsampleBytree: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _storage._colsampleBytree ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_uniqueStorage()._colsampleBytree = newValue}
      }
      /// Returns true if `colsampleBytree` has been explicitly set.
      package var hasColsampleBytree: Bool {return _storage._colsampleBytree != nil}
      /// Clears the value of `colsampleBytree`. Subsequent reads from it will return its default value.
      package mutating func clearColsampleBytree() {_uniqueStorage()._colsampleBytree = nil}

      /// Subsample ratio of columns for each level for boosted tree models.
      package var colsampleBylevel: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _storage._colsampleBylevel ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_uniqueStorage()._colsampleBylevel = newValue}
      }
      /// Returns true if `colsampleBylevel` has been explicitly set.
      package var hasColsampleBylevel: Bool {return _storage._colsampleBylevel != nil}
      /// Clears the value of `colsampleBylevel`. Subsequent reads from it will return its default value.
      package mutating func clearColsampleBylevel() {_uniqueStorage()._colsampleBylevel = nil}

      /// Subsample ratio of columns for each node(split) for boosted tree
      /// models.
      package var colsampleBynode: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _storage._colsampleBynode ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_uniqueStorage()._colsampleBynode = newValue}
      }
      /// Returns true if `colsampleBynode` has been explicitly set.
      package var hasColsampleBynode: Bool {return _storage._colsampleBynode != nil}
      /// Clears the value of `colsampleBynode`. Subsequent reads from it will return its default value.
      package mutating func clearColsampleBynode() {_uniqueStorage()._colsampleBynode = nil}

      /// Num factors specified for matrix factorization models.
      package var numFactors: Int64 {
        get {return _storage._numFactors}
        set {_uniqueStorage()._numFactors = newValue}
      }

      /// Feedback type that specifies which algorithm to run for matrix
      /// factorization.
      package var feedbackType: Google_Cloud_Bigquery_V2_Model.FeedbackType {
        get {return _storage._feedbackType}
        set {_uniqueStorage()._feedbackType = newValue}
      }

      /// Hyperparameter for matrix factoration when implicit feedback type is
      /// specified.
      package var walsAlpha: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _storage._walsAlpha ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_uniqueStorage()._walsAlpha = newValue}
      }
      /// Returns true if `walsAlpha` has been explicitly set.
      package var hasWalsAlpha: Bool {return _storage._walsAlpha != nil}
      /// Clears the value of `walsAlpha`. Subsequent reads from it will return its default value.
      package mutating func clearWalsAlpha() {_uniqueStorage()._walsAlpha = nil}

      /// The method used to initialize the centroids for kmeans algorithm.
      package var kmeansInitializationMethod: Google_Cloud_Bigquery_V2_Model.KmeansEnums.KmeansInitializationMethod {
        get {return _storage._kmeansInitializationMethod}
        set {_uniqueStorage()._kmeansInitializationMethod = newValue}
      }

      /// The column used to provide the initial centroids for kmeans algorithm
      /// when kmeans_initialization_method is CUSTOM.
      package var kmeansInitializationColumn: String {
        get {return _storage._kmeansInitializationColumn}
        set {_uniqueStorage()._kmeansInitializationColumn = newValue}
      }

      /// Column to be designated as time series timestamp for ARIMA model.
      package var timeSeriesTimestampColumn: String {
        get {return _storage._timeSeriesTimestampColumn}
        set {_uniqueStorage()._timeSeriesTimestampColumn = newValue}
      }

      /// Column to be designated as time series data for ARIMA model.
      package var timeSeriesDataColumn: String {
        get {return _storage._timeSeriesDataColumn}
        set {_uniqueStorage()._timeSeriesDataColumn = newValue}
      }

      /// Whether to enable auto ARIMA or not.
      package var autoArima: SwiftProtobuf.Google_Protobuf_BoolValue {
        get {return _storage._autoArima ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
        set {_uniqueStorage()._autoArima = newValue}
      }
      /// Returns true if `autoArima` has been explicitly set.
      package var hasAutoArima: Bool {return _storage._autoArima != nil}
      /// Clears the value of `autoArima`. Subsequent reads from it will return its default value.
      package mutating func clearAutoArima() {_uniqueStorage()._autoArima = nil}

      /// A specification of the non-seasonal part of the ARIMA model: the three
      /// components (p, d, q) are the AR order, the degree of differencing, and
      /// the MA order.
      package var nonSeasonalOrder: Google_Cloud_Bigquery_V2_Model.ArimaOrder {
        get {return _storage._nonSeasonalOrder ?? Google_Cloud_Bigquery_V2_Model.ArimaOrder()}
        set {_uniqueStorage()._nonSeasonalOrder = newValue}
      }
      /// Returns true if `nonSeasonalOrder` has been explicitly set.
      package var hasNonSeasonalOrder: Bool {return _storage._nonSeasonalOrder != nil}
      /// Clears the value of `nonSeasonalOrder`. Subsequent reads from it will return its default value.
      package mutating func clearNonSeasonalOrder() {_uniqueStorage()._nonSeasonalOrder = nil}

      /// The data frequency of a time series.
      package var dataFrequency: Google_Cloud_Bigquery_V2_Model.DataFrequency {
        get {return _storage._dataFrequency}
        set {_uniqueStorage()._dataFrequency = newValue}
      }

      /// Whether or not p-value test should be computed for this model. Only
      /// available for linear and logistic regression models.
      package var calculatePValues: SwiftProtobuf.Google_Protobuf_BoolValue {
        get {return _storage._calculatePValues ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
        set {_uniqueStorage()._calculatePValues = newValue}
      }
      /// Returns true if `calculatePValues` has been explicitly set.
      package var hasCalculatePValues: Bool {return _storage._calculatePValues != nil}
      /// Clears the value of `calculatePValues`. Subsequent reads from it will return its default value.
      package mutating func clearCalculatePValues() {_uniqueStorage()._calculatePValues = nil}

      /// Include drift when fitting an ARIMA model.
      package var includeDrift: SwiftProtobuf.Google_Protobuf_BoolValue {
        get {return _storage._includeDrift ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
        set {_uniqueStorage()._includeDrift = newValue}
      }
      /// Returns true if `includeDrift` has been explicitly set.
      package var hasIncludeDrift: Bool {return _storage._includeDrift != nil}
      /// Clears the value of `includeDrift`. Subsequent reads from it will return its default value.
      package mutating func clearIncludeDrift() {_uniqueStorage()._includeDrift = nil}

      /// The geographical region based on which the holidays are considered in
      /// time series modeling. If a valid value is specified, then holiday
      /// effects modeling is enabled.
      package var holidayRegion: Google_Cloud_Bigquery_V2_Model.HolidayRegion {
        get {return _storage._holidayRegion}
        set {_uniqueStorage()._holidayRegion = newValue}
      }

      /// A list of geographical regions that are used for time series modeling.
      package var holidayRegions: [Google_Cloud_Bigquery_V2_Model.HolidayRegion] {
        get {return _storage._holidayRegions}
        set {_uniqueStorage()._holidayRegions = newValue}
      }

      /// The time series id column that was used during ARIMA model training.
      package var timeSeriesIDColumn: String {
        get {return _storage._timeSeriesIDColumn}
        set {_uniqueStorage()._timeSeriesIDColumn = newValue}
      }

      /// The time series id columns that were used during ARIMA model training.
      package var timeSeriesIDColumns: [String] {
        get {return _storage._timeSeriesIDColumns}
        set {_uniqueStorage()._timeSeriesIDColumns = newValue}
      }

      /// The number of periods ahead that need to be forecasted.
      package var horizon: Int64 {
        get {return _storage._horizon}
        set {_uniqueStorage()._horizon = newValue}
      }

      /// The max value of the sum of non-seasonal p and q.
      package var autoArimaMaxOrder: Int64 {
        get {return _storage._autoArimaMaxOrder}
        set {_uniqueStorage()._autoArimaMaxOrder = newValue}
      }

      /// The min value of the sum of non-seasonal p and q.
      package var autoArimaMinOrder: Int64 {
        get {return _storage._autoArimaMinOrder}
        set {_uniqueStorage()._autoArimaMinOrder = newValue}
      }

      /// Number of trials to run this hyperparameter tuning job.
      package var numTrials: Int64 {
        get {return _storage._numTrials}
        set {_uniqueStorage()._numTrials = newValue}
      }

      /// Maximum number of trials to run in parallel.
      package var maxParallelTrials: Int64 {
        get {return _storage._maxParallelTrials}
        set {_uniqueStorage()._maxParallelTrials = newValue}
      }

      /// The target evaluation metrics to optimize the hyperparameters for.
      package var hparamTuningObjectives: [Google_Cloud_Bigquery_V2_Model.HparamTuningEnums.HparamTuningObjective] {
        get {return _storage._hparamTuningObjectives}
        set {_uniqueStorage()._hparamTuningObjectives = newValue}
      }

      /// If true, perform decompose time series and save the results.
      package var decomposeTimeSeries: SwiftProtobuf.Google_Protobuf_BoolValue {
        get {return _storage._decomposeTimeSeries ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
        set {_uniqueStorage()._decomposeTimeSeries = newValue}
      }
      /// Returns true if `decomposeTimeSeries` has been explicitly set.
      package var hasDecomposeTimeSeries: Bool {return _storage._decomposeTimeSeries != nil}
      /// Clears the value of `decomposeTimeSeries`. Subsequent reads from it will return its default value.
      package mutating func clearDecomposeTimeSeries() {_uniqueStorage()._decomposeTimeSeries = nil}

      /// If true, clean spikes and dips in the input time series.
      package var cleanSpikesAndDips: SwiftProtobuf.Google_Protobuf_BoolValue {
        get {return _storage._cleanSpikesAndDips ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
        set {_uniqueStorage()._cleanSpikesAndDips = newValue}
      }
      /// Returns true if `cleanSpikesAndDips` has been explicitly set.
      package var hasCleanSpikesAndDips: Bool {return _storage._cleanSpikesAndDips != nil}
      /// Clears the value of `cleanSpikesAndDips`. Subsequent reads from it will return its default value.
      package mutating func clearCleanSpikesAndDips() {_uniqueStorage()._cleanSpikesAndDips = nil}

      /// If true, detect step changes and make data adjustment in the input time
      /// series.
      package var adjustStepChanges: SwiftProtobuf.Google_Protobuf_BoolValue {
        get {return _storage._adjustStepChanges ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
        set {_uniqueStorage()._adjustStepChanges = newValue}
      }
      /// Returns true if `adjustStepChanges` has been explicitly set.
      package var hasAdjustStepChanges: Bool {return _storage._adjustStepChanges != nil}
      /// Clears the value of `adjustStepChanges`. Subsequent reads from it will return its default value.
      package mutating func clearAdjustStepChanges() {_uniqueStorage()._adjustStepChanges = nil}

      /// If true, enable global explanation during training.
      package var enableGlobalExplain: SwiftProtobuf.Google_Protobuf_BoolValue {
        get {return _storage._enableGlobalExplain ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
        set {_uniqueStorage()._enableGlobalExplain = newValue}
      }
      /// Returns true if `enableGlobalExplain` has been explicitly set.
      package var hasEnableGlobalExplain: Bool {return _storage._enableGlobalExplain != nil}
      /// Clears the value of `enableGlobalExplain`. Subsequent reads from it will return its default value.
      package mutating func clearEnableGlobalExplain() {_uniqueStorage()._enableGlobalExplain = nil}

      /// Number of paths for the sampled Shapley explain method.
      package var sampledShapleyNumPaths: Int64 {
        get {return _storage._sampledShapleyNumPaths}
        set {_uniqueStorage()._sampledShapleyNumPaths = newValue}
      }

      /// Number of integral steps for the integrated gradients explain method.
      package var integratedGradientsNumSteps: Int64 {
        get {return _storage._integratedGradientsNumSteps}
        set {_uniqueStorage()._integratedGradientsNumSteps = newValue}
      }

      /// Categorical feature encoding method.
      package var categoryEncodingMethod: Google_Cloud_Bigquery_V2_Model.CategoryEncodingMethod.EncodingMethod {
        get {return _storage._categoryEncodingMethod}
        set {_uniqueStorage()._categoryEncodingMethod = newValue}
      }

      /// Based on the selected TF version, the corresponding docker image is
      /// used to train external models.
      package var tfVersion: String {
        get {return _storage._tfVersion}
        set {_uniqueStorage()._tfVersion = newValue}
      }

      /// Enums for color space, used for processing images in Object Table.
      /// See more details at
      /// https://www.tensorflow.org/io/tutorials/colorspace.
      package var colorSpace: Google_Cloud_Bigquery_V2_Model.ColorSpace {
        get {return _storage._colorSpace}
        set {_uniqueStorage()._colorSpace = newValue}
      }

      /// Name of the instance weight column for training data.
      /// This column isn't be used as a feature.
      package var instanceWeightColumn: String {
        get {return _storage._instanceWeightColumn}
        set {_uniqueStorage()._instanceWeightColumn = newValue}
      }

      /// Smoothing window size for the trend component. When a positive value is
      /// specified, a center moving average smoothing is applied on the history
      /// trend. When the smoothing window is out of the boundary at the
      /// beginning or the end of the trend, the first element or the last
      /// element is padded to fill the smoothing window before the average is
      /// applied.
      package var trendSmoothingWindowSize: Int64 {
        get {return _storage._trendSmoothingWindowSize}
        set {_uniqueStorage()._trendSmoothingWindowSize = newValue}
      }

      /// The fraction of the interpolated length of the time series that's used
      /// to model the time series trend component. All of the time points of the
      /// time series are used to model the non-trend component. This training
      /// option accelerates modeling training without sacrificing much
      /// forecasting accuracy. You can use this option with
      /// `minTimeSeriesLength` but not with `maxTimeSeriesLength`.
      package var timeSeriesLengthFraction: Double {
        get {return _storage._timeSeriesLengthFraction}
        set {_uniqueStorage()._timeSeriesLengthFraction = newValue}
      }

      /// The minimum number of time points in a time series that are used in
      /// modeling the trend component of the time series. If you use this option
      /// you must also set the `timeSeriesLengthFraction` option. This training
      /// option ensures that enough time points are available when you use
      /// `timeSeriesLengthFraction` in trend modeling. This is particularly
      /// important when forecasting multiple time series in a single query using
      /// `timeSeriesIdColumn`. If the total number of time points is less than
      /// the `minTimeSeriesLength` value, then the query uses all available time
      /// points.
      package var minTimeSeriesLength: Int64 {
        get {return _storage._minTimeSeriesLength}
        set {_uniqueStorage()._minTimeSeriesLength = newValue}
      }

      /// The maximum number of time points in a time series that can be used in
      /// modeling the trend component of the time series. Don't use this option
      /// with the `timeSeriesLengthFraction` or `minTimeSeriesLength` options.
      package var maxTimeSeriesLength: Int64 {
        get {return _storage._maxTimeSeriesLength}
        set {_uniqueStorage()._maxTimeSeriesLength = newValue}
      }

      /// User-selected XGBoost versions for training of XGBoost models.
      package var xgboostVersion: String {
        get {return _storage._xgboostVersion}
        set {_uniqueStorage()._xgboostVersion = newValue}
      }

      /// Whether to use approximate feature contribution method in XGBoost model
      /// explanation for global explain.
      package var approxGlobalFeatureContrib: SwiftProtobuf.Google_Protobuf_BoolValue {
        get {return _storage._approxGlobalFeatureContrib ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
        set {_uniqueStorage()._approxGlobalFeatureContrib = newValue}
      }
      /// Returns true if `approxGlobalFeatureContrib` has been explicitly set.
      package var hasApproxGlobalFeatureContrib: Bool {return _storage._approxGlobalFeatureContrib != nil}
      /// Clears the value of `approxGlobalFeatureContrib`. Subsequent reads from it will return its default value.
      package mutating func clearApproxGlobalFeatureContrib() {_uniqueStorage()._approxGlobalFeatureContrib = nil}

      /// Whether the model should include intercept during model training.
      package var fitIntercept: SwiftProtobuf.Google_Protobuf_BoolValue {
        get {return _storage._fitIntercept ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
        set {_uniqueStorage()._fitIntercept = newValue}
      }
      /// Returns true if `fitIntercept` has been explicitly set.
      package var hasFitIntercept: Bool {return _storage._fitIntercept != nil}
      /// Clears the value of `fitIntercept`. Subsequent reads from it will return its default value.
      package mutating func clearFitIntercept() {_uniqueStorage()._fitIntercept = nil}

      /// Number of principal components to keep in the PCA model. Must be <= the
      /// number of features.
      package var numPrincipalComponents: Int64 {
        get {return _storage._numPrincipalComponents}
        set {_uniqueStorage()._numPrincipalComponents = newValue}
      }

      /// The minimum ratio of cumulative explained variance that needs to be
      /// given by the PCA model.
      package var pcaExplainedVarianceRatio: Double {
        get {return _storage._pcaExplainedVarianceRatio}
        set {_uniqueStorage()._pcaExplainedVarianceRatio = newValue}
      }

      /// If true, scale the feature values by dividing the feature standard
      /// deviation. Currently only apply to PCA.
      package var scaleFeatures: SwiftProtobuf.Google_Protobuf_BoolValue {
        get {return _storage._scaleFeatures ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
        set {_uniqueStorage()._scaleFeatures = newValue}
      }
      /// Returns true if `scaleFeatures` has been explicitly set.
      package var hasScaleFeatures: Bool {return _storage._scaleFeatures != nil}
      /// Clears the value of `scaleFeatures`. Subsequent reads from it will return its default value.
      package mutating func clearScaleFeatures() {_uniqueStorage()._scaleFeatures = nil}

      /// The solver for PCA.
      package var pcaSolver: Google_Cloud_Bigquery_V2_Model.PcaSolverOptionEnums.PcaSolver {
        get {return _storage._pcaSolver}
        set {_uniqueStorage()._pcaSolver = newValue}
      }

      /// Whether to calculate class weights automatically based on the
      /// popularity of each label.
      package var autoClassWeights: SwiftProtobuf.Google_Protobuf_BoolValue {
        get {return _storage._autoClassWeights ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
        set {_uniqueStorage()._autoClassWeights = newValue}
      }
      /// Returns true if `autoClassWeights` has been explicitly set.
      package var hasAutoClassWeights: Bool {return _storage._autoClassWeights != nil}
      /// Clears the value of `autoClassWeights`. Subsequent reads from it will return its default value.
      package mutating func clearAutoClassWeights() {_uniqueStorage()._autoClassWeights = nil}

      /// Activation function of the neural nets.
      package var activationFn: String {
        get {return _storage._activationFn}
        set {_uniqueStorage()._activationFn = newValue}
      }

      /// Optimizer used for training the neural nets.
      package var optimizer: String {
        get {return _storage._optimizer}
        set {_uniqueStorage()._optimizer = newValue}
      }

      /// Budget in hours for AutoML training.
      package var budgetHours: Double {
        get {return _storage._budgetHours}
        set {_uniqueStorage()._budgetHours = newValue}
      }

      /// Whether to standardize numerical features. Default to true.
      package var standardizeFeatures: SwiftProtobuf.Google_Protobuf_BoolValue {
        get {return _storage._standardizeFeatures ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
        set {_uniqueStorage()._standardizeFeatures = newValue}
      }
      /// Returns true if `standardizeFeatures` has been explicitly set.
      package var hasStandardizeFeatures: Bool {return _storage._standardizeFeatures != nil}
      /// Clears the value of `standardizeFeatures`. Subsequent reads from it will return its default value.
      package mutating func clearStandardizeFeatures() {_uniqueStorage()._standardizeFeatures = nil}

      /// L1 regularization coefficient to activations.
      package var l1RegActivation: Double {
        get {return _storage._l1RegActivation}
        set {_uniqueStorage()._l1RegActivation = newValue}
      }

      /// The model registry.
      package var modelRegistry: Google_Cloud_Bigquery_V2_Model.ModelRegistryOptionEnums.ModelRegistry {
        get {return _storage._modelRegistry}
        set {_uniqueStorage()._modelRegistry = newValue}
      }

      /// The version aliases to apply in Vertex AI model registry. Always
      /// overwrite if the version aliases exists in a existing model.
      package var vertexAiModelVersionAliases: [String] {
        get {return _storage._vertexAiModelVersionAliases}
        set {_uniqueStorage()._vertexAiModelVersionAliases = newValue}
      }

      /// Optional. Names of the columns to slice on. Applies to contribution
      /// analysis models.
      package var dimensionIDColumns: [String] {
        get {return _storage._dimensionIDColumns}
        set {_uniqueStorage()._dimensionIDColumns = newValue}
      }

      /// The contribution metric. Applies to contribution analysis models.
      /// Allowed formats supported are for summable and summable ratio
      /// contribution metrics. These include expressions such as `SUM(x)` or
      /// `SUM(x)/SUM(y)`, where x and y are column names from the base table.
      package var contributionMetric: String {
        get {return _storage._contributionMetric ?? String()}
        set {_uniqueStorage()._contributionMetric = newValue}
      }
      /// Returns true if `contributionMetric` has been explicitly set.
      package var hasContributionMetric: Bool {return _storage._contributionMetric != nil}
      /// Clears the value of `contributionMetric`. Subsequent reads from it will return its default value.
      package mutating func clearContributionMetric() {_uniqueStorage()._contributionMetric = nil}

      /// Name of the column used to determine the rows corresponding to control
      /// and test. Applies to contribution analysis models.
      package var isTestColumn: String {
        get {return _storage._isTestColumn ?? String()}
        set {_uniqueStorage()._isTestColumn = newValue}
      }
      /// Returns true if `isTestColumn` has been explicitly set.
      package var hasIsTestColumn: Bool {return _storage._isTestColumn != nil}
      /// Clears the value of `isTestColumn`. Subsequent reads from it will return its default value.
      package mutating func clearIsTestColumn() {_uniqueStorage()._isTestColumn = nil}

      /// The apriori support minimum. Applies to contribution analysis models.
      package var minAprioriSupport: Double {
        get {return _storage._minAprioriSupport ?? 0}
        set {_uniqueStorage()._minAprioriSupport = newValue}
      }
      /// Returns true if `minAprioriSupport` has been explicitly set.
      package var hasMinAprioriSupport: Bool {return _storage._minAprioriSupport != nil}
      /// Clears the value of `minAprioriSupport`. Subsequent reads from it will return its default value.
      package mutating func clearMinAprioriSupport() {_uniqueStorage()._minAprioriSupport = nil}

      package var unknownFields = SwiftProtobuf.UnknownStorage()

      package init() {}

      fileprivate var _storage = _StorageClass.defaultInstance
    }

    /// Information about a single iteration of the training run.
    package struct IterationResult: Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      /// Index of the iteration, 0 based.
      package var index: SwiftProtobuf.Google_Protobuf_Int32Value {
        get {return _index ?? SwiftProtobuf.Google_Protobuf_Int32Value()}
        set {_index = newValue}
      }
      /// Returns true if `index` has been explicitly set.
      package var hasIndex: Bool {return self._index != nil}
      /// Clears the value of `index`. Subsequent reads from it will return its default value.
      package mutating func clearIndex() {self._index = nil}

      /// Time taken to run the iteration in milliseconds.
      package var durationMs: SwiftProtobuf.Google_Protobuf_Int64Value {
        get {return _durationMs ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
        set {_durationMs = newValue}
      }
      /// Returns true if `durationMs` has been explicitly set.
      package var hasDurationMs: Bool {return self._durationMs != nil}
      /// Clears the value of `durationMs`. Subsequent reads from it will return its default value.
      package mutating func clearDurationMs() {self._durationMs = nil}

      /// Loss computed on the training data at the end of iteration.
      package var trainingLoss: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _trainingLoss ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_trainingLoss = newValue}
      }
      /// Returns true if `trainingLoss` has been explicitly set.
      package var hasTrainingLoss: Bool {return self._trainingLoss != nil}
      /// Clears the value of `trainingLoss`. Subsequent reads from it will return its default value.
      package mutating func clearTrainingLoss() {self._trainingLoss = nil}

      /// Loss computed on the eval data at the end of iteration.
      package var evalLoss: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _evalLoss ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_evalLoss = newValue}
      }
      /// Returns true if `evalLoss` has been explicitly set.
      package var hasEvalLoss: Bool {return self._evalLoss != nil}
      /// Clears the value of `evalLoss`. Subsequent reads from it will return its default value.
      package mutating func clearEvalLoss() {self._evalLoss = nil}

      /// Learn rate used for this iteration.
      package var learnRate: Double = 0

      /// Information about top clusters for clustering models.
      package var clusterInfos: [Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ClusterInfo] = []

      /// Arima result.
      package var arimaResult: Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ArimaResult {
        get {return _arimaResult ?? Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ArimaResult()}
        set {_arimaResult = newValue}
      }
      /// Returns true if `arimaResult` has been explicitly set.
      package var hasArimaResult: Bool {return self._arimaResult != nil}
      /// Clears the value of `arimaResult`. Subsequent reads from it will return its default value.
      package mutating func clearArimaResult() {self._arimaResult = nil}

      /// The information of the principal components.
      package var principalComponentInfos: [Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.PrincipalComponentInfo] = []

      package var unknownFields = SwiftProtobuf.UnknownStorage()

      /// Information about a single cluster for clustering model.
      package struct ClusterInfo: Sendable {
        // SwiftProtobuf.Message conformance is added in an extension below. See the
        // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
        // methods supported on all messages.

        /// Centroid id.
        package var centroidID: Int64 = 0

        /// Cluster radius, the average distance from centroid
        /// to each point assigned to the cluster.
        package var clusterRadius: SwiftProtobuf.Google_Protobuf_DoubleValue {
          get {return _clusterRadius ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
          set {_clusterRadius = newValue}
        }
        /// Returns true if `clusterRadius` has been explicitly set.
        package var hasClusterRadius: Bool {return self._clusterRadius != nil}
        /// Clears the value of `clusterRadius`. Subsequent reads from it will return its default value.
        package mutating func clearClusterRadius() {self._clusterRadius = nil}

        /// Cluster size, the total number of points assigned to the cluster.
        package var clusterSize: SwiftProtobuf.Google_Protobuf_Int64Value {
          get {return _clusterSize ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
          set {_clusterSize = newValue}
        }
        /// Returns true if `clusterSize` has been explicitly set.
        package var hasClusterSize: Bool {return self._clusterSize != nil}
        /// Clears the value of `clusterSize`. Subsequent reads from it will return its default value.
        package mutating func clearClusterSize() {self._clusterSize = nil}

        package var unknownFields = SwiftProtobuf.UnknownStorage()

        package init() {}

        fileprivate var _clusterRadius: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
        fileprivate var _clusterSize: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
      }

      /// (Auto-)arima fitting result. Wrap everything in ArimaResult for easier
      /// refactoring if we want to use model-specific iteration results.
      package struct ArimaResult: Sendable {
        // SwiftProtobuf.Message conformance is added in an extension below. See the
        // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
        // methods supported on all messages.

        /// This message is repeated because there are multiple arima models
        /// fitted in auto-arima. For non-auto-arima model, its size is one.
        package var arimaModelInfo: [Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ArimaResult.ArimaModelInfo] = []

        /// Seasonal periods. Repeated because multiple periods are supported for
        /// one time series.
        package var seasonalPeriods: [Google_Cloud_Bigquery_V2_Model.SeasonalPeriod.SeasonalPeriodType] = []

        package var unknownFields = SwiftProtobuf.UnknownStorage()

        /// Arima coefficients.
        package struct ArimaCoefficients: Sendable {
          // SwiftProtobuf.Message conformance is added in an extension below. See the
          // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
          // methods supported on all messages.

          /// Auto-regressive coefficients, an array of double.
          package var autoRegressiveCoefficients: [Double] = []

          /// Moving-average coefficients, an array of double.
          package var movingAverageCoefficients: [Double] = []

          /// Intercept coefficient, just a double not an array.
          package var interceptCoefficient: SwiftProtobuf.Google_Protobuf_DoubleValue {
            get {return _interceptCoefficient ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
            set {_interceptCoefficient = newValue}
          }
          /// Returns true if `interceptCoefficient` has been explicitly set.
          package var hasInterceptCoefficient: Bool {return self._interceptCoefficient != nil}
          /// Clears the value of `interceptCoefficient`. Subsequent reads from it will return its default value.
          package mutating func clearInterceptCoefficient() {self._interceptCoefficient = nil}

          package var unknownFields = SwiftProtobuf.UnknownStorage()

          package init() {}

          fileprivate var _interceptCoefficient: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
        }

        /// Arima model information.
        package struct ArimaModelInfo: Sendable {
          // SwiftProtobuf.Message conformance is added in an extension below. See the
          // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
          // methods supported on all messages.

          /// Non-seasonal order.
          package var nonSeasonalOrder: Google_Cloud_Bigquery_V2_Model.ArimaOrder {
            get {return _nonSeasonalOrder ?? Google_Cloud_Bigquery_V2_Model.ArimaOrder()}
            set {_nonSeasonalOrder = newValue}
          }
          /// Returns true if `nonSeasonalOrder` has been explicitly set.
          package var hasNonSeasonalOrder: Bool {return self._nonSeasonalOrder != nil}
          /// Clears the value of `nonSeasonalOrder`. Subsequent reads from it will return its default value.
          package mutating func clearNonSeasonalOrder() {self._nonSeasonalOrder = nil}

          /// Arima coefficients.
          package var arimaCoefficients: Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ArimaResult.ArimaCoefficients {
            get {return _arimaCoefficients ?? Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ArimaResult.ArimaCoefficients()}
            set {_arimaCoefficients = newValue}
          }
          /// Returns true if `arimaCoefficients` has been explicitly set.
          package var hasArimaCoefficients: Bool {return self._arimaCoefficients != nil}
          /// Clears the value of `arimaCoefficients`. Subsequent reads from it will return its default value.
          package mutating func clearArimaCoefficients() {self._arimaCoefficients = nil}

          /// Arima fitting metrics.
          package var arimaFittingMetrics: Google_Cloud_Bigquery_V2_Model.ArimaFittingMetrics {
            get {return _arimaFittingMetrics ?? Google_Cloud_Bigquery_V2_Model.ArimaFittingMetrics()}
            set {_arimaFittingMetrics = newValue}
          }
          /// Returns true if `arimaFittingMetrics` has been explicitly set.
          package var hasArimaFittingMetrics: Bool {return self._arimaFittingMetrics != nil}
          /// Clears the value of `arimaFittingMetrics`. Subsequent reads from it will return its default value.
          package mutating func clearArimaFittingMetrics() {self._arimaFittingMetrics = nil}

          /// Whether Arima model fitted with drift or not. It is always false
          /// when d is not 1.
          package var hasDrift_p: SwiftProtobuf.Google_Protobuf_BoolValue {
            get {return _hasDrift_p ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
            set {_hasDrift_p = newValue}
          }
          /// Returns true if `hasDrift_p` has been explicitly set.
          package var hasHasDrift_p: Bool {return self._hasDrift_p != nil}
          /// Clears the value of `hasDrift_p`. Subsequent reads from it will return its default value.
          package mutating func clearHasDrift_p() {self._hasDrift_p = nil}

          /// The time_series_id value for this time series. It will be one of
          /// the unique values from the time_series_id_column specified during
          /// ARIMA model training. Only present when time_series_id_column
          /// training option was used.
          package var timeSeriesID: String = String()

          /// The tuple of time_series_ids identifying this time series. It will
          /// be one of the unique tuples of values present in the
          /// time_series_id_columns specified during ARIMA model training. Only
          /// present when time_series_id_columns training option was used and
          /// the order of values here are same as the order of
          /// time_series_id_columns.
          package var timeSeriesIds: [String] = []

          /// Seasonal periods. Repeated because multiple periods are supported
          /// for one time series.
          package var seasonalPeriods: [Google_Cloud_Bigquery_V2_Model.SeasonalPeriod.SeasonalPeriodType] = []

          /// If true, holiday_effect is a part of time series decomposition
          /// result.
          package var hasHolidayEffect_p: SwiftProtobuf.Google_Protobuf_BoolValue {
            get {return _hasHolidayEffect_p ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
            set {_hasHolidayEffect_p = newValue}
          }
          /// Returns true if `hasHolidayEffect_p` has been explicitly set.
          package var hasHasHolidayEffect_p: Bool {return self._hasHolidayEffect_p != nil}
          /// Clears the value of `hasHolidayEffect_p`. Subsequent reads from it will return its default value.
          package mutating func clearHasHolidayEffect_p() {self._hasHolidayEffect_p = nil}

          /// If true, spikes_and_dips is a part of time series decomposition
          /// result.
          package var hasSpikesAndDips_p: SwiftProtobuf.Google_Protobuf_BoolValue {
            get {return _hasSpikesAndDips_p ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
            set {_hasSpikesAndDips_p = newValue}
          }
          /// Returns true if `hasSpikesAndDips_p` has been explicitly set.
          package var hasHasSpikesAndDips_p: Bool {return self._hasSpikesAndDips_p != nil}
          /// Clears the value of `hasSpikesAndDips_p`. Subsequent reads from it will return its default value.
          package mutating func clearHasSpikesAndDips_p() {self._hasSpikesAndDips_p = nil}

          /// If true, step_changes is a part of time series decomposition
          /// result.
          package var hasStepChanges_p: SwiftProtobuf.Google_Protobuf_BoolValue {
            get {return _hasStepChanges_p ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
            set {_hasStepChanges_p = newValue}
          }
          /// Returns true if `hasStepChanges_p` has been explicitly set.
          package var hasHasStepChanges_p: Bool {return self._hasStepChanges_p != nil}
          /// Clears the value of `hasStepChanges_p`. Subsequent reads from it will return its default value.
          package mutating func clearHasStepChanges_p() {self._hasStepChanges_p = nil}

          package var unknownFields = SwiftProtobuf.UnknownStorage()

          package init() {}

          fileprivate var _nonSeasonalOrder: Google_Cloud_Bigquery_V2_Model.ArimaOrder? = nil
          fileprivate var _arimaCoefficients: Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ArimaResult.ArimaCoefficients? = nil
          fileprivate var _arimaFittingMetrics: Google_Cloud_Bigquery_V2_Model.ArimaFittingMetrics? = nil
          fileprivate var _hasDrift_p: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
          fileprivate var _hasHolidayEffect_p: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
          fileprivate var _hasSpikesAndDips_p: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
          fileprivate var _hasStepChanges_p: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
        }

        package init() {}
      }

      /// Principal component infos, used only for eigen decomposition based
      /// models, e.g., PCA. Ordered by explained_variance in the descending
      /// order.
      package struct PrincipalComponentInfo: Sendable {
        // SwiftProtobuf.Message conformance is added in an extension below. See the
        // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
        // methods supported on all messages.

        /// Id of the principal component.
        package var principalComponentID: SwiftProtobuf.Google_Protobuf_Int64Value {
          get {return _principalComponentID ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
          set {_principalComponentID = newValue}
        }
        /// Returns true if `principalComponentID` has been explicitly set.
        package var hasPrincipalComponentID: Bool {return self._principalComponentID != nil}
        /// Clears the value of `principalComponentID`. Subsequent reads from it will return its default value.
        package mutating func clearPrincipalComponentID() {self._principalComponentID = nil}

        /// Explained variance by this principal component, which is simply the
        /// eigenvalue.
        package var explainedVariance: SwiftProtobuf.Google_Protobuf_DoubleValue {
          get {return _explainedVariance ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
          set {_explainedVariance = newValue}
        }
        /// Returns true if `explainedVariance` has been explicitly set.
        package var hasExplainedVariance: Bool {return self._explainedVariance != nil}
        /// Clears the value of `explainedVariance`. Subsequent reads from it will return its default value.
        package mutating func clearExplainedVariance() {self._explainedVariance = nil}

        /// Explained_variance over the total explained variance.
        package var explainedVarianceRatio: SwiftProtobuf.Google_Protobuf_DoubleValue {
          get {return _explainedVarianceRatio ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
          set {_explainedVarianceRatio = newValue}
        }
        /// Returns true if `explainedVarianceRatio` has been explicitly set.
        package var hasExplainedVarianceRatio: Bool {return self._explainedVarianceRatio != nil}
        /// Clears the value of `explainedVarianceRatio`. Subsequent reads from it will return its default value.
        package mutating func clearExplainedVarianceRatio() {self._explainedVarianceRatio = nil}

        /// The explained_variance is pre-ordered in the descending order to
        /// compute the cumulative explained variance ratio.
        package var cumulativeExplainedVarianceRatio: SwiftProtobuf.Google_Protobuf_DoubleValue {
          get {return _cumulativeExplainedVarianceRatio ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
          set {_cumulativeExplainedVarianceRatio = newValue}
        }
        /// Returns true if `cumulativeExplainedVarianceRatio` has been explicitly set.
        package var hasCumulativeExplainedVarianceRatio: Bool {return self._cumulativeExplainedVarianceRatio != nil}
        /// Clears the value of `cumulativeExplainedVarianceRatio`. Subsequent reads from it will return its default value.
        package mutating func clearCumulativeExplainedVarianceRatio() {self._cumulativeExplainedVarianceRatio = nil}

        package var unknownFields = SwiftProtobuf.UnknownStorage()

        package init() {}

        fileprivate var _principalComponentID: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
        fileprivate var _explainedVariance: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
        fileprivate var _explainedVarianceRatio: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
        fileprivate var _cumulativeExplainedVarianceRatio: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
      }

      package init() {}

      fileprivate var _index: SwiftProtobuf.Google_Protobuf_Int32Value? = nil
      fileprivate var _durationMs: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
      fileprivate var _trainingLoss: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
      fileprivate var _evalLoss: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
      fileprivate var _arimaResult: Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ArimaResult? = nil
    }

    package init() {}

    fileprivate var _storage = _StorageClass.defaultInstance
  }

  /// Search space for a double hyperparameter.
  package struct DoubleHparamSearchSpace: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Search space.
    package var searchSpace: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace.OneOf_SearchSpace? = nil

    /// Range of the double hyperparameter.
    package var range: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace.DoubleRange {
      get {
        if case .range(let v)? = searchSpace {return v}
        return Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace.DoubleRange()
      }
      set {searchSpace = .range(newValue)}
    }

    /// Candidates of the double hyperparameter.
    package var candidates: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace.DoubleCandidates {
      get {
        if case .candidates(let v)? = searchSpace {return v}
        return Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace.DoubleCandidates()
      }
      set {searchSpace = .candidates(newValue)}
    }

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    /// Search space.
    package enum OneOf_SearchSpace: Equatable, Sendable {
      /// Range of the double hyperparameter.
      case range(Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace.DoubleRange)
      /// Candidates of the double hyperparameter.
      case candidates(Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace.DoubleCandidates)

    }

    /// Range of a double hyperparameter.
    package struct DoubleRange: Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      /// Min value of the double parameter.
      package var min: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _min ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_min = newValue}
      }
      /// Returns true if `min` has been explicitly set.
      package var hasMin: Bool {return self._min != nil}
      /// Clears the value of `min`. Subsequent reads from it will return its default value.
      package mutating func clearMin() {self._min = nil}

      /// Max value of the double parameter.
      package var max: SwiftProtobuf.Google_Protobuf_DoubleValue {
        get {return _max ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
        set {_max = newValue}
      }
      /// Returns true if `max` has been explicitly set.
      package var hasMax: Bool {return self._max != nil}
      /// Clears the value of `max`. Subsequent reads from it will return its default value.
      package mutating func clearMax() {self._max = nil}

      package var unknownFields = SwiftProtobuf.UnknownStorage()

      package init() {}

      fileprivate var _min: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
      fileprivate var _max: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    }

    /// Discrete candidates of a double hyperparameter.
    package struct DoubleCandidates: Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      /// Candidates for the double parameter in increasing order.
      package var candidates: [SwiftProtobuf.Google_Protobuf_DoubleValue] = []

      package var unknownFields = SwiftProtobuf.UnknownStorage()

      package init() {}
    }

    package init() {}
  }

  /// Search space for an int hyperparameter.
  package struct IntHparamSearchSpace: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Search space.
    package var searchSpace: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace.OneOf_SearchSpace? = nil

    /// Range of the int hyperparameter.
    package var range: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace.IntRange {
      get {
        if case .range(let v)? = searchSpace {return v}
        return Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace.IntRange()
      }
      set {searchSpace = .range(newValue)}
    }

    /// Candidates of the int hyperparameter.
    package var candidates: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace.IntCandidates {
      get {
        if case .candidates(let v)? = searchSpace {return v}
        return Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace.IntCandidates()
      }
      set {searchSpace = .candidates(newValue)}
    }

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    /// Search space.
    package enum OneOf_SearchSpace: Equatable, Sendable {
      /// Range of the int hyperparameter.
      case range(Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace.IntRange)
      /// Candidates of the int hyperparameter.
      case candidates(Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace.IntCandidates)

    }

    /// Range of an int hyperparameter.
    package struct IntRange: Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      /// Min value of the int parameter.
      package var min: SwiftProtobuf.Google_Protobuf_Int64Value {
        get {return _min ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
        set {_min = newValue}
      }
      /// Returns true if `min` has been explicitly set.
      package var hasMin: Bool {return self._min != nil}
      /// Clears the value of `min`. Subsequent reads from it will return its default value.
      package mutating func clearMin() {self._min = nil}

      /// Max value of the int parameter.
      package var max: SwiftProtobuf.Google_Protobuf_Int64Value {
        get {return _max ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
        set {_max = newValue}
      }
      /// Returns true if `max` has been explicitly set.
      package var hasMax: Bool {return self._max != nil}
      /// Clears the value of `max`. Subsequent reads from it will return its default value.
      package mutating func clearMax() {self._max = nil}

      package var unknownFields = SwiftProtobuf.UnknownStorage()

      package init() {}

      fileprivate var _min: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
      fileprivate var _max: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    }

    /// Discrete candidates of an int hyperparameter.
    package struct IntCandidates: Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      /// Candidates for the int parameter in increasing order.
      package var candidates: [SwiftProtobuf.Google_Protobuf_Int64Value] = []

      package var unknownFields = SwiftProtobuf.UnknownStorage()

      package init() {}
    }

    package init() {}
  }

  /// Search space for string and enum.
  package struct StringHparamSearchSpace: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Canididates for the string or enum parameter in lower case.
    package var candidates: [String] = []

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    package init() {}
  }

  /// Search space for int array.
  package struct IntArrayHparamSearchSpace: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Candidates for the int array parameter.
    package var candidates: [Google_Cloud_Bigquery_V2_Model.IntArrayHparamSearchSpace.IntArray] = []

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    /// An array of int.
    package struct IntArray: Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      /// Elements in the int array.
      package var elements: [Int64] = []

      package var unknownFields = SwiftProtobuf.UnknownStorage()

      package init() {}
    }

    package init() {}
  }

  /// Hyperparameter search spaces.
  /// These should be a subset of training_options.
  package struct HparamSearchSpaces: @unchecked Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Learning rate of training jobs.
    package var learnRate: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace {
      get {return _storage._learnRate ?? Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace()}
      set {_uniqueStorage()._learnRate = newValue}
    }
    /// Returns true if `learnRate` has been explicitly set.
    package var hasLearnRate: Bool {return _storage._learnRate != nil}
    /// Clears the value of `learnRate`. Subsequent reads from it will return its default value.
    package mutating func clearLearnRate() {_uniqueStorage()._learnRate = nil}

    /// L1 regularization coefficient.
    package var l1Reg: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace {
      get {return _storage._l1Reg ?? Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace()}
      set {_uniqueStorage()._l1Reg = newValue}
    }
    /// Returns true if `l1Reg` has been explicitly set.
    package var hasL1Reg: Bool {return _storage._l1Reg != nil}
    /// Clears the value of `l1Reg`. Subsequent reads from it will return its default value.
    package mutating func clearL1Reg() {_uniqueStorage()._l1Reg = nil}

    /// L2 regularization coefficient.
    package var l2Reg: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace {
      get {return _storage._l2Reg ?? Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace()}
      set {_uniqueStorage()._l2Reg = newValue}
    }
    /// Returns true if `l2Reg` has been explicitly set.
    package var hasL2Reg: Bool {return _storage._l2Reg != nil}
    /// Clears the value of `l2Reg`. Subsequent reads from it will return its default value.
    package mutating func clearL2Reg() {_uniqueStorage()._l2Reg = nil}

    /// Number of clusters for k-means.
    package var numClusters: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace {
      get {return _storage._numClusters ?? Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace()}
      set {_uniqueStorage()._numClusters = newValue}
    }
    /// Returns true if `numClusters` has been explicitly set.
    package var hasNumClusters: Bool {return _storage._numClusters != nil}
    /// Clears the value of `numClusters`. Subsequent reads from it will return its default value.
    package mutating func clearNumClusters() {_uniqueStorage()._numClusters = nil}

    /// Number of latent factors to train on.
    package var numFactors: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace {
      get {return _storage._numFactors ?? Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace()}
      set {_uniqueStorage()._numFactors = newValue}
    }
    /// Returns true if `numFactors` has been explicitly set.
    package var hasNumFactors: Bool {return _storage._numFactors != nil}
    /// Clears the value of `numFactors`. Subsequent reads from it will return its default value.
    package mutating func clearNumFactors() {_uniqueStorage()._numFactors = nil}

    /// Hidden units for neural network models.
    package var hiddenUnits: Google_Cloud_Bigquery_V2_Model.IntArrayHparamSearchSpace {
      get {return _storage._hiddenUnits ?? Google_Cloud_Bigquery_V2_Model.IntArrayHparamSearchSpace()}
      set {_uniqueStorage()._hiddenUnits = newValue}
    }
    /// Returns true if `hiddenUnits` has been explicitly set.
    package var hasHiddenUnits: Bool {return _storage._hiddenUnits != nil}
    /// Clears the value of `hiddenUnits`. Subsequent reads from it will return its default value.
    package mutating func clearHiddenUnits() {_uniqueStorage()._hiddenUnits = nil}

    /// Mini batch sample size.
    package var batchSize: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace {
      get {return _storage._batchSize ?? Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace()}
      set {_uniqueStorage()._batchSize = newValue}
    }
    /// Returns true if `batchSize` has been explicitly set.
    package var hasBatchSize: Bool {return _storage._batchSize != nil}
    /// Clears the value of `batchSize`. Subsequent reads from it will return its default value.
    package mutating func clearBatchSize() {_uniqueStorage()._batchSize = nil}

    /// Dropout probability for dnn model training and boosted tree models
    /// using dart booster.
    package var dropout: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace {
      get {return _storage._dropout ?? Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace()}
      set {_uniqueStorage()._dropout = newValue}
    }
    /// Returns true if `dropout` has been explicitly set.
    package var hasDropout: Bool {return _storage._dropout != nil}
    /// Clears the value of `dropout`. Subsequent reads from it will return its default value.
    package mutating func clearDropout() {_uniqueStorage()._dropout = nil}

    /// Maximum depth of a tree for boosted tree models.
    package var maxTreeDepth: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace {
      get {return _storage._maxTreeDepth ?? Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace()}
      set {_uniqueStorage()._maxTreeDepth = newValue}
    }
    /// Returns true if `maxTreeDepth` has been explicitly set.
    package var hasMaxTreeDepth: Bool {return _storage._maxTreeDepth != nil}
    /// Clears the value of `maxTreeDepth`. Subsequent reads from it will return its default value.
    package mutating func clearMaxTreeDepth() {_uniqueStorage()._maxTreeDepth = nil}

    /// Subsample the training data to grow tree to prevent overfitting for
    /// boosted tree models.
    package var subsample: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace {
      get {return _storage._subsample ?? Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace()}
      set {_uniqueStorage()._subsample = newValue}
    }
    /// Returns true if `subsample` has been explicitly set.
    package var hasSubsample: Bool {return _storage._subsample != nil}
    /// Clears the value of `subsample`. Subsequent reads from it will return its default value.
    package mutating func clearSubsample() {_uniqueStorage()._subsample = nil}

    /// Minimum split loss for boosted tree models.
    package var minSplitLoss: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace {
      get {return _storage._minSplitLoss ?? Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace()}
      set {_uniqueStorage()._minSplitLoss = newValue}
    }
    /// Returns true if `minSplitLoss` has been explicitly set.
    package var hasMinSplitLoss: Bool {return _storage._minSplitLoss != nil}
    /// Clears the value of `minSplitLoss`. Subsequent reads from it will return its default value.
    package mutating func clearMinSplitLoss() {_uniqueStorage()._minSplitLoss = nil}

    /// Hyperparameter for matrix factoration when implicit feedback type is
    /// specified.
    package var walsAlpha: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace {
      get {return _storage._walsAlpha ?? Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace()}
      set {_uniqueStorage()._walsAlpha = newValue}
    }
    /// Returns true if `walsAlpha` has been explicitly set.
    package var hasWalsAlpha: Bool {return _storage._walsAlpha != nil}
    /// Clears the value of `walsAlpha`. Subsequent reads from it will return its default value.
    package mutating func clearWalsAlpha() {_uniqueStorage()._walsAlpha = nil}

    /// Booster type for boosted tree models.
    package var boosterType: Google_Cloud_Bigquery_V2_Model.StringHparamSearchSpace {
      get {return _storage._boosterType ?? Google_Cloud_Bigquery_V2_Model.StringHparamSearchSpace()}
      set {_uniqueStorage()._boosterType = newValue}
    }
    /// Returns true if `boosterType` has been explicitly set.
    package var hasBoosterType: Bool {return _storage._boosterType != nil}
    /// Clears the value of `boosterType`. Subsequent reads from it will return its default value.
    package mutating func clearBoosterType() {_uniqueStorage()._boosterType = nil}

    /// Number of parallel trees for boosted tree models.
    package var numParallelTree: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace {
      get {return _storage._numParallelTree ?? Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace()}
      set {_uniqueStorage()._numParallelTree = newValue}
    }
    /// Returns true if `numParallelTree` has been explicitly set.
    package var hasNumParallelTree: Bool {return _storage._numParallelTree != nil}
    /// Clears the value of `numParallelTree`. Subsequent reads from it will return its default value.
    package mutating func clearNumParallelTree() {_uniqueStorage()._numParallelTree = nil}

    /// Dart normalization type for boosted tree models.
    package var dartNormalizeType: Google_Cloud_Bigquery_V2_Model.StringHparamSearchSpace {
      get {return _storage._dartNormalizeType ?? Google_Cloud_Bigquery_V2_Model.StringHparamSearchSpace()}
      set {_uniqueStorage()._dartNormalizeType = newValue}
    }
    /// Returns true if `dartNormalizeType` has been explicitly set.
    package var hasDartNormalizeType: Bool {return _storage._dartNormalizeType != nil}
    /// Clears the value of `dartNormalizeType`. Subsequent reads from it will return its default value.
    package mutating func clearDartNormalizeType() {_uniqueStorage()._dartNormalizeType = nil}

    /// Tree construction algorithm for boosted tree models.
    package var treeMethod: Google_Cloud_Bigquery_V2_Model.StringHparamSearchSpace {
      get {return _storage._treeMethod ?? Google_Cloud_Bigquery_V2_Model.StringHparamSearchSpace()}
      set {_uniqueStorage()._treeMethod = newValue}
    }
    /// Returns true if `treeMethod` has been explicitly set.
    package var hasTreeMethod: Bool {return _storage._treeMethod != nil}
    /// Clears the value of `treeMethod`. Subsequent reads from it will return its default value.
    package mutating func clearTreeMethod() {_uniqueStorage()._treeMethod = nil}

    /// Minimum sum of instance weight needed in a child for boosted tree models.
    package var minTreeChildWeight: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace {
      get {return _storage._minTreeChildWeight ?? Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace()}
      set {_uniqueStorage()._minTreeChildWeight = newValue}
    }
    /// Returns true if `minTreeChildWeight` has been explicitly set.
    package var hasMinTreeChildWeight: Bool {return _storage._minTreeChildWeight != nil}
    /// Clears the value of `minTreeChildWeight`. Subsequent reads from it will return its default value.
    package mutating func clearMinTreeChildWeight() {_uniqueStorage()._minTreeChildWeight = nil}

    /// Subsample ratio of columns when constructing each tree for boosted tree
    /// models.
    package var colsampleBytree: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace {
      get {return _storage._colsampleBytree ?? Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace()}
      set {_uniqueStorage()._colsampleBytree = newValue}
    }
    /// Returns true if `colsampleBytree` has been explicitly set.
    package var hasColsampleBytree: Bool {return _storage._colsampleBytree != nil}
    /// Clears the value of `colsampleBytree`. Subsequent reads from it will return its default value.
    package mutating func clearColsampleBytree() {_uniqueStorage()._colsampleBytree = nil}

    /// Subsample ratio of columns for each level for boosted tree models.
    package var colsampleBylevel: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace {
      get {return _storage._colsampleBylevel ?? Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace()}
      set {_uniqueStorage()._colsampleBylevel = newValue}
    }
    /// Returns true if `colsampleBylevel` has been explicitly set.
    package var hasColsampleBylevel: Bool {return _storage._colsampleBylevel != nil}
    /// Clears the value of `colsampleBylevel`. Subsequent reads from it will return its default value.
    package mutating func clearColsampleBylevel() {_uniqueStorage()._colsampleBylevel = nil}

    /// Subsample ratio of columns for each node(split) for boosted tree models.
    package var colsampleBynode: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace {
      get {return _storage._colsampleBynode ?? Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace()}
      set {_uniqueStorage()._colsampleBynode = newValue}
    }
    /// Returns true if `colsampleBynode` has been explicitly set.
    package var hasColsampleBynode: Bool {return _storage._colsampleBynode != nil}
    /// Clears the value of `colsampleBynode`. Subsequent reads from it will return its default value.
    package mutating func clearColsampleBynode() {_uniqueStorage()._colsampleBynode = nil}

    /// Activation functions of neural network models.
    package var activationFn: Google_Cloud_Bigquery_V2_Model.StringHparamSearchSpace {
      get {return _storage._activationFn ?? Google_Cloud_Bigquery_V2_Model.StringHparamSearchSpace()}
      set {_uniqueStorage()._activationFn = newValue}
    }
    /// Returns true if `activationFn` has been explicitly set.
    package var hasActivationFn: Bool {return _storage._activationFn != nil}
    /// Clears the value of `activationFn`. Subsequent reads from it will return its default value.
    package mutating func clearActivationFn() {_uniqueStorage()._activationFn = nil}

    /// Optimizer of TF models.
    package var optimizer: Google_Cloud_Bigquery_V2_Model.StringHparamSearchSpace {
      get {return _storage._optimizer ?? Google_Cloud_Bigquery_V2_Model.StringHparamSearchSpace()}
      set {_uniqueStorage()._optimizer = newValue}
    }
    /// Returns true if `optimizer` has been explicitly set.
    package var hasOptimizer: Bool {return _storage._optimizer != nil}
    /// Clears the value of `optimizer`. Subsequent reads from it will return its default value.
    package mutating func clearOptimizer() {_uniqueStorage()._optimizer = nil}

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    package init() {}

    fileprivate var _storage = _StorageClass.defaultInstance
  }

  /// Training info of a trial in [hyperparameter
  /// tuning](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview)
  /// models.
  package struct HparamTuningTrial: @unchecked Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// 1-based index of the trial.
    package var trialID: Int64 {
      get {return _storage._trialID}
      set {_uniqueStorage()._trialID = newValue}
    }

    /// Starting time of the trial.
    package var startTimeMs: Int64 {
      get {return _storage._startTimeMs}
      set {_uniqueStorage()._startTimeMs = newValue}
    }

    /// Ending time of the trial.
    package var endTimeMs: Int64 {
      get {return _storage._endTimeMs}
      set {_uniqueStorage()._endTimeMs = newValue}
    }

    /// The hyperprameters selected for this trial.
    package var hparams: Google_Cloud_Bigquery_V2_Model.TrainingRun.TrainingOptions {
      get {return _storage._hparams ?? Google_Cloud_Bigquery_V2_Model.TrainingRun.TrainingOptions()}
      set {_uniqueStorage()._hparams = newValue}
    }
    /// Returns true if `hparams` has been explicitly set.
    package var hasHparams: Bool {return _storage._hparams != nil}
    /// Clears the value of `hparams`. Subsequent reads from it will return its default value.
    package mutating func clearHparams() {_uniqueStorage()._hparams = nil}

    /// Evaluation metrics of this trial calculated on the test data.
    /// Empty in Job API.
    package var evaluationMetrics: Google_Cloud_Bigquery_V2_Model.EvaluationMetrics {
      get {return _storage._evaluationMetrics ?? Google_Cloud_Bigquery_V2_Model.EvaluationMetrics()}
      set {_uniqueStorage()._evaluationMetrics = newValue}
    }
    /// Returns true if `evaluationMetrics` has been explicitly set.
    package var hasEvaluationMetrics: Bool {return _storage._evaluationMetrics != nil}
    /// Clears the value of `evaluationMetrics`. Subsequent reads from it will return its default value.
    package mutating func clearEvaluationMetrics() {_uniqueStorage()._evaluationMetrics = nil}

    /// The status of the trial.
    package var status: Google_Cloud_Bigquery_V2_Model.HparamTuningTrial.TrialStatus {
      get {return _storage._status}
      set {_uniqueStorage()._status = newValue}
    }

    /// Error message for FAILED and INFEASIBLE trial.
    package var errorMessage: String {
      get {return _storage._errorMessage}
      set {_uniqueStorage()._errorMessage = newValue}
    }

    /// Loss computed on the training data at the end of trial.
    package var trainingLoss: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _storage._trainingLoss ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_uniqueStorage()._trainingLoss = newValue}
    }
    /// Returns true if `trainingLoss` has been explicitly set.
    package var hasTrainingLoss: Bool {return _storage._trainingLoss != nil}
    /// Clears the value of `trainingLoss`. Subsequent reads from it will return its default value.
    package mutating func clearTrainingLoss() {_uniqueStorage()._trainingLoss = nil}

    /// Loss computed on the eval data at the end of trial.
    package var evalLoss: SwiftProtobuf.Google_Protobuf_DoubleValue {
      get {return _storage._evalLoss ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
      set {_uniqueStorage()._evalLoss = newValue}
    }
    /// Returns true if `evalLoss` has been explicitly set.
    package var hasEvalLoss: Bool {return _storage._evalLoss != nil}
    /// Clears the value of `evalLoss`. Subsequent reads from it will return its default value.
    package mutating func clearEvalLoss() {_uniqueStorage()._evalLoss = nil}

    /// Hyperparameter tuning evaluation metrics of this trial calculated on the
    /// eval data. Unlike evaluation_metrics, only the fields corresponding to
    /// the hparam_tuning_objectives are set.
    package var hparamTuningEvaluationMetrics: Google_Cloud_Bigquery_V2_Model.EvaluationMetrics {
      get {return _storage._hparamTuningEvaluationMetrics ?? Google_Cloud_Bigquery_V2_Model.EvaluationMetrics()}
      set {_uniqueStorage()._hparamTuningEvaluationMetrics = newValue}
    }
    /// Returns true if `hparamTuningEvaluationMetrics` has been explicitly set.
    package var hasHparamTuningEvaluationMetrics: Bool {return _storage._hparamTuningEvaluationMetrics != nil}
    /// Clears the value of `hparamTuningEvaluationMetrics`. Subsequent reads from it will return its default value.
    package mutating func clearHparamTuningEvaluationMetrics() {_uniqueStorage()._hparamTuningEvaluationMetrics = nil}

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    /// Current status of the trial.
    package enum TrialStatus: SwiftProtobuf.Enum, Swift.CaseIterable {
      package typealias RawValue = Int

      /// Default value.
      case unspecified // = 0

      /// Scheduled but not started.
      case notStarted // = 1

      /// Running state.
      case running // = 2

      /// The trial succeeded.
      case succeeded // = 3

      /// The trial failed.
      case failed // = 4

      /// The trial is infeasible due to the invalid params.
      case infeasible // = 5

      /// Trial stopped early because it's not promising.
      case stoppedEarly // = 6
      case UNRECOGNIZED(Int)

      package init() {
        self = .unspecified
      }

      package init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .unspecified
        case 1: self = .notStarted
        case 2: self = .running
        case 3: self = .succeeded
        case 4: self = .failed
        case 5: self = .infeasible
        case 6: self = .stoppedEarly
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      package var rawValue: Int {
        switch self {
        case .unspecified: return 0
        case .notStarted: return 1
        case .running: return 2
        case .succeeded: return 3
        case .failed: return 4
        case .infeasible: return 5
        case .stoppedEarly: return 6
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      package static let allCases: [Google_Cloud_Bigquery_V2_Model.HparamTuningTrial.TrialStatus] = [
        .unspecified,
        .notStarted,
        .running,
        .succeeded,
        .failed,
        .infeasible,
        .stoppedEarly,
      ]

    }

    package init() {}

    fileprivate var _storage = _StorageClass.defaultInstance
  }

  package init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Request format for getting information about a BigQuery ML model.
package struct Google_Cloud_Bigquery_V2_GetModelRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the requested model.
  package var projectID: String = String()

  /// Required. Dataset ID of the requested model.
  package var datasetID: String = String()

  /// Required. Model ID of the requested model.
  package var modelID: String = String()

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

package struct Google_Cloud_Bigquery_V2_PatchModelRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the model to patch.
  package var projectID: String = String()

  /// Required. Dataset ID of the model to patch.
  package var datasetID: String = String()

  /// Required. Model ID of the model to patch.
  package var modelID: String = String()

  /// Required. Patched model.
  /// Follows RFC5789 patch semantics. Missing fields are not updated.
  /// To clear a field, explicitly set to default value.
  package var model: Google_Cloud_Bigquery_V2_Model {
    get {return _model ?? Google_Cloud_Bigquery_V2_Model()}
    set {_model = newValue}
  }
  /// Returns true if `model` has been explicitly set.
  package var hasModel: Bool {return self._model != nil}
  /// Clears the value of `model`. Subsequent reads from it will return its default value.
  package mutating func clearModel() {self._model = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _model: Google_Cloud_Bigquery_V2_Model? = nil
}

/// Request format for deleting BigQuery ML models.
package struct Google_Cloud_Bigquery_V2_DeleteModelRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the model to delete.
  package var projectID: String = String()

  /// Required. Dataset ID of the model to delete.
  package var datasetID: String = String()

  /// Required. Model ID of the model to delete.
  package var modelID: String = String()

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

/// Request format for listing BigQuery ML models.
package struct Google_Cloud_Bigquery_V2_ListModelsRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the models to list.
  package var projectID: String = String()

  /// Required. Dataset ID of the models to list.
  package var datasetID: String = String()

  /// The maximum number of results to return in a single response page.
  /// Leverage the page tokens to iterate through the entire collection.
  package var maxResults: SwiftProtobuf.Google_Protobuf_UInt32Value {
    get {return _maxResults ?? SwiftProtobuf.Google_Protobuf_UInt32Value()}
    set {_maxResults = newValue}
  }
  /// Returns true if `maxResults` has been explicitly set.
  package var hasMaxResults: Bool {return self._maxResults != nil}
  /// Clears the value of `maxResults`. Subsequent reads from it will return its default value.
  package mutating func clearMaxResults() {self._maxResults = nil}

  /// Page token, returned by a previous call to request the next page of
  /// results
  package var pageToken: String = String()

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _maxResults: SwiftProtobuf.Google_Protobuf_UInt32Value? = nil
}

/// Response format for a single page when listing BigQuery ML models.
package struct Google_Cloud_Bigquery_V2_ListModelsResponse: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Models in the requested dataset. Only the following fields are populated:
  /// model_reference, model_type, creation_time, last_modified_time and
  /// labels.
  package var models: [Google_Cloud_Bigquery_V2_Model] = []

  /// A token to request the next page of results.
  package var nextPageToken: String = String()

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.bigquery.v2"

extension Google_Cloud_Bigquery_V2_RemoteModelInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".RemoteModelInfo"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "endpoint"),
    2: .standard(proto: "remote_service_type"),
    3: .same(proto: "connection"),
    4: .standard(proto: "max_batching_rows"),
    5: .standard(proto: "remote_model_version"),
    7: .standard(proto: "speech_recognizer"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.remoteService != nil {try decoder.handleConflictingOneOf()}
          self.remoteService = .endpoint(v)
        }
      }()
      case 2: try {
        var v: Google_Cloud_Bigquery_V2_RemoteModelInfo.RemoteServiceType?
        try decoder.decodeSingularEnumField(value: &v)
        if let v = v {
          if self.remoteService != nil {try decoder.handleConflictingOneOf()}
          self.remoteService = .remoteServiceType(v)
        }
      }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.connection) }()
      case 4: try { try decoder.decodeSingularInt64Field(value: &self.maxBatchingRows) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self.remoteModelVersion) }()
      case 7: try { try decoder.decodeSingularStringField(value: &self.speechRecognizer) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.remoteService {
    case .endpoint?: try {
      guard case .endpoint(let v)? = self.remoteService else { preconditionFailure() }
      try visitor.visitSingularStringField(value: v, fieldNumber: 1)
    }()
    case .remoteServiceType?: try {
      guard case .remoteServiceType(let v)? = self.remoteService else { preconditionFailure() }
      try visitor.visitSingularEnumField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    if !self.connection.isEmpty {
      try visitor.visitSingularStringField(value: self.connection, fieldNumber: 3)
    }
    if self.maxBatchingRows != 0 {
      try visitor.visitSingularInt64Field(value: self.maxBatchingRows, fieldNumber: 4)
    }
    if !self.remoteModelVersion.isEmpty {
      try visitor.visitSingularStringField(value: self.remoteModelVersion, fieldNumber: 5)
    }
    if !self.speechRecognizer.isEmpty {
      try visitor.visitSingularStringField(value: self.speechRecognizer, fieldNumber: 7)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_RemoteModelInfo, rhs: Google_Cloud_Bigquery_V2_RemoteModelInfo) -> Bool {
    if lhs.remoteService != rhs.remoteService {return false}
    if lhs.connection != rhs.connection {return false}
    if lhs.maxBatchingRows != rhs.maxBatchingRows {return false}
    if lhs.remoteModelVersion != rhs.remoteModelVersion {return false}
    if lhs.speechRecognizer != rhs.speechRecognizer {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_RemoteModelInfo.RemoteServiceType: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "REMOTE_SERVICE_TYPE_UNSPECIFIED"),
    1: .same(proto: "CLOUD_AI_TRANSLATE_V3"),
    2: .same(proto: "CLOUD_AI_VISION_V1"),
    3: .same(proto: "CLOUD_AI_NATURAL_LANGUAGE_V1"),
    7: .same(proto: "CLOUD_AI_SPEECH_TO_TEXT_V2"),
  ]
}

extension Google_Cloud_Bigquery_V2_TransformColumn: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".TransformColumn"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .same(proto: "type"),
    3: .standard(proto: "transform_sql"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._type) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.transformSql) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    try { if let v = self._type {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if !self.transformSql.isEmpty {
      try visitor.visitSingularStringField(value: self.transformSql, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_TransformColumn, rhs: Google_Cloud_Bigquery_V2_TransformColumn) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs._type != rhs._type {return false}
    if lhs.transformSql != rhs.transformSql {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".Model"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "etag"),
    2: .standard(proto: "model_reference"),
    5: .standard(proto: "creation_time"),
    6: .standard(proto: "last_modified_time"),
    12: .same(proto: "description"),
    14: .standard(proto: "friendly_name"),
    15: .same(proto: "labels"),
    16: .standard(proto: "expiration_time"),
    13: .same(proto: "location"),
    17: .standard(proto: "encryption_configuration"),
    7: .standard(proto: "model_type"),
    9: .standard(proto: "training_runs"),
    10: .standard(proto: "feature_columns"),
    11: .standard(proto: "label_columns"),
    26: .standard(proto: "transform_columns"),
    18: .standard(proto: "hparam_search_spaces"),
    21: .standard(proto: "default_trial_id"),
    20: .standard(proto: "hparam_trials"),
    22: .standard(proto: "optimal_trial_ids"),
    25: .standard(proto: "remote_model_info"),
  ]

  fileprivate class _StorageClass {
    var _etag: String = String()
    var _modelReference: Google_Cloud_Bigquery_V2_ModelReference? = nil
    var _creationTime: Int64 = 0
    var _lastModifiedTime: Int64 = 0
    var _description_p: String = String()
    var _friendlyName: String = String()
    var _labels: Dictionary<String,String> = [:]
    var _expirationTime: Int64 = 0
    var _location: String = String()
    var _encryptionConfiguration: Google_Cloud_Bigquery_V2_EncryptionConfiguration? = nil
    var _modelType: Google_Cloud_Bigquery_V2_Model.ModelType = .unspecified
    var _trainingRuns: [Google_Cloud_Bigquery_V2_Model.TrainingRun] = []
    var _featureColumns: [Google_Cloud_Bigquery_V2_StandardSqlField] = []
    var _labelColumns: [Google_Cloud_Bigquery_V2_StandardSqlField] = []
    var _transformColumns: [Google_Cloud_Bigquery_V2_TransformColumn] = []
    var _hparamSearchSpaces: Google_Cloud_Bigquery_V2_Model.HparamSearchSpaces? = nil
    var _defaultTrialID: Int64 = 0
    var _hparamTrials: [Google_Cloud_Bigquery_V2_Model.HparamTuningTrial] = []
    var _optimalTrialIds: [Int64] = []
    var _remoteModelInfo: Google_Cloud_Bigquery_V2_RemoteModelInfo? = nil

    #if swift(>=5.10)
      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()
    #else
      static let defaultInstance = _StorageClass()
    #endif

    private init() {}

    init(copying source: _StorageClass) {
      _etag = source._etag
      _modelReference = source._modelReference
      _creationTime = source._creationTime
      _lastModifiedTime = source._lastModifiedTime
      _description_p = source._description_p
      _friendlyName = source._friendlyName
      _labels = source._labels
      _expirationTime = source._expirationTime
      _location = source._location
      _encryptionConfiguration = source._encryptionConfiguration
      _modelType = source._modelType
      _trainingRuns = source._trainingRuns
      _featureColumns = source._featureColumns
      _labelColumns = source._labelColumns
      _transformColumns = source._transformColumns
      _hparamSearchSpaces = source._hparamSearchSpaces
      _defaultTrialID = source._defaultTrialID
      _hparamTrials = source._hparamTrials
      _optimalTrialIds = source._optimalTrialIds
      _remoteModelInfo = source._remoteModelInfo
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._etag) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._modelReference) }()
        case 5: try { try decoder.decodeSingularInt64Field(value: &_storage._creationTime) }()
        case 6: try { try decoder.decodeSingularInt64Field(value: &_storage._lastModifiedTime) }()
        case 7: try { try decoder.decodeSingularEnumField(value: &_storage._modelType) }()
        case 9: try { try decoder.decodeRepeatedMessageField(value: &_storage._trainingRuns) }()
        case 10: try { try decoder.decodeRepeatedMessageField(value: &_storage._featureColumns) }()
        case 11: try { try decoder.decodeRepeatedMessageField(value: &_storage._labelColumns) }()
        case 12: try { try decoder.decodeSingularStringField(value: &_storage._description_p) }()
        case 13: try { try decoder.decodeSingularStringField(value: &_storage._location) }()
        case 14: try { try decoder.decodeSingularStringField(value: &_storage._friendlyName) }()
        case 15: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &_storage._labels) }()
        case 16: try { try decoder.decodeSingularInt64Field(value: &_storage._expirationTime) }()
        case 17: try { try decoder.decodeSingularMessageField(value: &_storage._encryptionConfiguration) }()
        case 18: try { try decoder.decodeSingularMessageField(value: &_storage._hparamSearchSpaces) }()
        case 20: try { try decoder.decodeRepeatedMessageField(value: &_storage._hparamTrials) }()
        case 21: try { try decoder.decodeSingularInt64Field(value: &_storage._defaultTrialID) }()
        case 22: try { try decoder.decodeRepeatedInt64Field(value: &_storage._optimalTrialIds) }()
        case 25: try { try decoder.decodeSingularMessageField(value: &_storage._remoteModelInfo) }()
        case 26: try { try decoder.decodeRepeatedMessageField(value: &_storage._transformColumns) }()
        default: break
        }
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if !_storage._etag.isEmpty {
        try visitor.visitSingularStringField(value: _storage._etag, fieldNumber: 1)
      }
      try { if let v = _storage._modelReference {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      } }()
      if _storage._creationTime != 0 {
        try visitor.visitSingularInt64Field(value: _storage._creationTime, fieldNumber: 5)
      }
      if _storage._lastModifiedTime != 0 {
        try visitor.visitSingularInt64Field(value: _storage._lastModifiedTime, fieldNumber: 6)
      }
      if _storage._modelType != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._modelType, fieldNumber: 7)
      }
      if !_storage._trainingRuns.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._trainingRuns, fieldNumber: 9)
      }
      if !_storage._featureColumns.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._featureColumns, fieldNumber: 10)
      }
      if !_storage._labelColumns.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._labelColumns, fieldNumber: 11)
      }
      if !_storage._description_p.isEmpty {
        try visitor.visitSingularStringField(value: _storage._description_p, fieldNumber: 12)
      }
      if !_storage._location.isEmpty {
        try visitor.visitSingularStringField(value: _storage._location, fieldNumber: 13)
      }
      if !_storage._friendlyName.isEmpty {
        try visitor.visitSingularStringField(value: _storage._friendlyName, fieldNumber: 14)
      }
      if !_storage._labels.isEmpty {
        try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: _storage._labels, fieldNumber: 15)
      }
      if _storage._expirationTime != 0 {
        try visitor.visitSingularInt64Field(value: _storage._expirationTime, fieldNumber: 16)
      }
      try { if let v = _storage._encryptionConfiguration {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 17)
      } }()
      try { if let v = _storage._hparamSearchSpaces {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 18)
      } }()
      if !_storage._hparamTrials.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._hparamTrials, fieldNumber: 20)
      }
      if _storage._defaultTrialID != 0 {
        try visitor.visitSingularInt64Field(value: _storage._defaultTrialID, fieldNumber: 21)
      }
      if !_storage._optimalTrialIds.isEmpty {
        try visitor.visitPackedInt64Field(value: _storage._optimalTrialIds, fieldNumber: 22)
      }
      try { if let v = _storage._remoteModelInfo {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 25)
      } }()
      if !_storage._transformColumns.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._transformColumns, fieldNumber: 26)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model, rhs: Google_Cloud_Bigquery_V2_Model) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._etag != rhs_storage._etag {return false}
        if _storage._modelReference != rhs_storage._modelReference {return false}
        if _storage._creationTime != rhs_storage._creationTime {return false}
        if _storage._lastModifiedTime != rhs_storage._lastModifiedTime {return false}
        if _storage._description_p != rhs_storage._description_p {return false}
        if _storage._friendlyName != rhs_storage._friendlyName {return false}
        if _storage._labels != rhs_storage._labels {return false}
        if _storage._expirationTime != rhs_storage._expirationTime {return false}
        if _storage._location != rhs_storage._location {return false}
        if _storage._encryptionConfiguration != rhs_storage._encryptionConfiguration {return false}
        if _storage._modelType != rhs_storage._modelType {return false}
        if _storage._trainingRuns != rhs_storage._trainingRuns {return false}
        if _storage._featureColumns != rhs_storage._featureColumns {return false}
        if _storage._labelColumns != rhs_storage._labelColumns {return false}
        if _storage._transformColumns != rhs_storage._transformColumns {return false}
        if _storage._hparamSearchSpaces != rhs_storage._hparamSearchSpaces {return false}
        if _storage._defaultTrialID != rhs_storage._defaultTrialID {return false}
        if _storage._hparamTrials != rhs_storage._hparamTrials {return false}
        if _storage._optimalTrialIds != rhs_storage._optimalTrialIds {return false}
        if _storage._remoteModelInfo != rhs_storage._remoteModelInfo {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.ModelType: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "MODEL_TYPE_UNSPECIFIED"),
    1: .same(proto: "LINEAR_REGRESSION"),
    2: .same(proto: "LOGISTIC_REGRESSION"),
    3: .same(proto: "KMEANS"),
    4: .same(proto: "MATRIX_FACTORIZATION"),
    5: .same(proto: "DNN_CLASSIFIER"),
    6: .same(proto: "TENSORFLOW"),
    7: .same(proto: "DNN_REGRESSOR"),
    8: .same(proto: "XGBOOST"),
    9: .same(proto: "BOOSTED_TREE_REGRESSOR"),
    10: .same(proto: "BOOSTED_TREE_CLASSIFIER"),
    11: .same(proto: "ARIMA"),
    12: .same(proto: "AUTOML_REGRESSOR"),
    13: .same(proto: "AUTOML_CLASSIFIER"),
    14: .same(proto: "PCA"),
    16: .same(proto: "DNN_LINEAR_COMBINED_CLASSIFIER"),
    17: .same(proto: "DNN_LINEAR_COMBINED_REGRESSOR"),
    18: .same(proto: "AUTOENCODER"),
    19: .same(proto: "ARIMA_PLUS"),
    23: .same(proto: "ARIMA_PLUS_XREG"),
    24: .same(proto: "RANDOM_FOREST_REGRESSOR"),
    25: .same(proto: "RANDOM_FOREST_CLASSIFIER"),
    26: .same(proto: "TENSORFLOW_LITE"),
    28: .same(proto: "ONNX"),
    29: .same(proto: "TRANSFORM_ONLY"),
    37: .same(proto: "CONTRIBUTION_ANALYSIS"),
  ]
}

extension Google_Cloud_Bigquery_V2_Model.LossType: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "LOSS_TYPE_UNSPECIFIED"),
    1: .same(proto: "MEAN_SQUARED_LOSS"),
    2: .same(proto: "MEAN_LOG_LOSS"),
  ]
}

extension Google_Cloud_Bigquery_V2_Model.DistanceType: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "DISTANCE_TYPE_UNSPECIFIED"),
    1: .same(proto: "EUCLIDEAN"),
    2: .same(proto: "COSINE"),
  ]
}

extension Google_Cloud_Bigquery_V2_Model.DataSplitMethod: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "DATA_SPLIT_METHOD_UNSPECIFIED"),
    1: .same(proto: "RANDOM"),
    2: .same(proto: "CUSTOM"),
    3: .same(proto: "SEQUENTIAL"),
    4: .same(proto: "NO_SPLIT"),
    5: .same(proto: "AUTO_SPLIT"),
  ]
}

extension Google_Cloud_Bigquery_V2_Model.DataFrequency: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "DATA_FREQUENCY_UNSPECIFIED"),
    1: .same(proto: "AUTO_FREQUENCY"),
    2: .same(proto: "YEARLY"),
    3: .same(proto: "QUARTERLY"),
    4: .same(proto: "MONTHLY"),
    5: .same(proto: "WEEKLY"),
    6: .same(proto: "DAILY"),
    7: .same(proto: "HOURLY"),
    8: .same(proto: "PER_MINUTE"),
  ]
}

extension Google_Cloud_Bigquery_V2_Model.HolidayRegion: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "HOLIDAY_REGION_UNSPECIFIED"),
    1: .same(proto: "GLOBAL"),
    2: .same(proto: "NA"),
    3: .same(proto: "JAPAC"),
    4: .same(proto: "EMEA"),
    5: .same(proto: "LAC"),
    6: .same(proto: "AE"),
    7: .same(proto: "AR"),
    8: .same(proto: "AT"),
    9: .same(proto: "AU"),
    10: .same(proto: "BE"),
    11: .same(proto: "BR"),
    12: .same(proto: "CA"),
    13: .same(proto: "CH"),
    14: .same(proto: "CL"),
    15: .same(proto: "CN"),
    16: .same(proto: "CO"),
    17: .same(proto: "CS"),
    18: .same(proto: "CZ"),
    19: .same(proto: "DE"),
    20: .same(proto: "DK"),
    21: .same(proto: "DZ"),
    22: .same(proto: "EC"),
    23: .same(proto: "EE"),
    24: .same(proto: "EG"),
    25: .same(proto: "ES"),
    26: .same(proto: "FI"),
    27: .same(proto: "FR"),
    28: .same(proto: "GB"),
    29: .same(proto: "GR"),
    30: .same(proto: "HK"),
    31: .same(proto: "HU"),
    32: .same(proto: "ID"),
    33: .same(proto: "IE"),
    34: .same(proto: "IL"),
    35: .same(proto: "IN"),
    36: .same(proto: "IR"),
    37: .same(proto: "IT"),
    38: .same(proto: "JP"),
    39: .same(proto: "KR"),
    40: .same(proto: "LV"),
    41: .same(proto: "MA"),
    42: .same(proto: "MX"),
    43: .same(proto: "MY"),
    44: .same(proto: "NG"),
    45: .same(proto: "NL"),
    46: .same(proto: "NO"),
    47: .same(proto: "NZ"),
    48: .same(proto: "PE"),
    49: .same(proto: "PH"),
    50: .same(proto: "PK"),
    51: .same(proto: "PL"),
    52: .same(proto: "PT"),
    53: .same(proto: "RO"),
    54: .same(proto: "RS"),
    55: .same(proto: "RU"),
    56: .same(proto: "SA"),
    57: .same(proto: "SE"),
    58: .same(proto: "SG"),
    59: .same(proto: "SI"),
    60: .same(proto: "SK"),
    61: .same(proto: "TH"),
    62: .same(proto: "TR"),
    63: .same(proto: "TW"),
    64: .same(proto: "UA"),
    65: .same(proto: "US"),
    66: .same(proto: "VE"),
    67: .same(proto: "VN"),
    68: .same(proto: "ZA"),
  ]
}

extension Google_Cloud_Bigquery_V2_Model.ColorSpace: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "COLOR_SPACE_UNSPECIFIED"),
    1: .same(proto: "RGB"),
    2: .same(proto: "HSV"),
    3: .same(proto: "YIQ"),
    4: .same(proto: "YUV"),
    5: .same(proto: "GRAYSCALE"),
  ]
}

extension Google_Cloud_Bigquery_V2_Model.LearnRateStrategy: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "LEARN_RATE_STRATEGY_UNSPECIFIED"),
    1: .same(proto: "LINE_SEARCH"),
    2: .same(proto: "CONSTANT"),
  ]
}

extension Google_Cloud_Bigquery_V2_Model.OptimizationStrategy: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "OPTIMIZATION_STRATEGY_UNSPECIFIED"),
    1: .same(proto: "BATCH_GRADIENT_DESCENT"),
    2: .same(proto: "NORMAL_EQUATION"),
  ]
}

extension Google_Cloud_Bigquery_V2_Model.FeedbackType: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "FEEDBACK_TYPE_UNSPECIFIED"),
    1: .same(proto: "IMPLICIT"),
    2: .same(proto: "EXPLICIT"),
  ]
}

extension Google_Cloud_Bigquery_V2_Model.SeasonalPeriod: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".SeasonalPeriod"
  package static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    // Load everything into unknown fields
    while try decoder.nextFieldNumber() != nil {}
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.SeasonalPeriod, rhs: Google_Cloud_Bigquery_V2_Model.SeasonalPeriod) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.SeasonalPeriod.SeasonalPeriodType: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "SEASONAL_PERIOD_TYPE_UNSPECIFIED"),
    1: .same(proto: "NO_SEASONALITY"),
    2: .same(proto: "DAILY"),
    3: .same(proto: "WEEKLY"),
    4: .same(proto: "MONTHLY"),
    5: .same(proto: "QUARTERLY"),
    6: .same(proto: "YEARLY"),
  ]
}

extension Google_Cloud_Bigquery_V2_Model.KmeansEnums: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".KmeansEnums"
  package static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    // Load everything into unknown fields
    while try decoder.nextFieldNumber() != nil {}
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.KmeansEnums, rhs: Google_Cloud_Bigquery_V2_Model.KmeansEnums) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.KmeansEnums.KmeansInitializationMethod: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "KMEANS_INITIALIZATION_METHOD_UNSPECIFIED"),
    1: .same(proto: "RANDOM"),
    2: .same(proto: "CUSTOM"),
    3: .same(proto: "KMEANS_PLUS_PLUS"),
  ]
}

extension Google_Cloud_Bigquery_V2_Model.BoostedTreeOptionEnums: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".BoostedTreeOptionEnums"
  package static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    // Load everything into unknown fields
    while try decoder.nextFieldNumber() != nil {}
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.BoostedTreeOptionEnums, rhs: Google_Cloud_Bigquery_V2_Model.BoostedTreeOptionEnums) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.BoostedTreeOptionEnums.BoosterType: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "BOOSTER_TYPE_UNSPECIFIED"),
    1: .same(proto: "GBTREE"),
    2: .same(proto: "DART"),
  ]
}

extension Google_Cloud_Bigquery_V2_Model.BoostedTreeOptionEnums.DartNormalizeType: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "DART_NORMALIZE_TYPE_UNSPECIFIED"),
    1: .same(proto: "TREE"),
    2: .same(proto: "FOREST"),
  ]
}

extension Google_Cloud_Bigquery_V2_Model.BoostedTreeOptionEnums.TreeMethod: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "TREE_METHOD_UNSPECIFIED"),
    1: .same(proto: "AUTO"),
    2: .same(proto: "EXACT"),
    3: .same(proto: "APPROX"),
    4: .same(proto: "HIST"),
  ]
}

extension Google_Cloud_Bigquery_V2_Model.HparamTuningEnums: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".HparamTuningEnums"
  package static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    // Load everything into unknown fields
    while try decoder.nextFieldNumber() != nil {}
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.HparamTuningEnums, rhs: Google_Cloud_Bigquery_V2_Model.HparamTuningEnums) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.HparamTuningEnums.HparamTuningObjective: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "HPARAM_TUNING_OBJECTIVE_UNSPECIFIED"),
    1: .same(proto: "MEAN_ABSOLUTE_ERROR"),
    2: .same(proto: "MEAN_SQUARED_ERROR"),
    3: .same(proto: "MEAN_SQUARED_LOG_ERROR"),
    4: .same(proto: "MEDIAN_ABSOLUTE_ERROR"),
    5: .same(proto: "R_SQUARED"),
    6: .same(proto: "EXPLAINED_VARIANCE"),
    7: .same(proto: "PRECISION"),
    8: .same(proto: "RECALL"),
    9: .same(proto: "ACCURACY"),
    10: .same(proto: "F1_SCORE"),
    11: .same(proto: "LOG_LOSS"),
    12: .same(proto: "ROC_AUC"),
    13: .same(proto: "DAVIES_BOULDIN_INDEX"),
    14: .same(proto: "MEAN_AVERAGE_PRECISION"),
    15: .same(proto: "NORMALIZED_DISCOUNTED_CUMULATIVE_GAIN"),
    16: .same(proto: "AVERAGE_RANK"),
  ]
}

extension Google_Cloud_Bigquery_V2_Model.RegressionMetrics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".RegressionMetrics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "mean_absolute_error"),
    2: .standard(proto: "mean_squared_error"),
    3: .standard(proto: "mean_squared_log_error"),
    4: .standard(proto: "median_absolute_error"),
    5: .standard(proto: "r_squared"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._meanAbsoluteError) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._meanSquaredError) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._meanSquaredLogError) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._medianAbsoluteError) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._rSquared) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._meanAbsoluteError {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._meanSquaredError {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._meanSquaredLogError {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._medianAbsoluteError {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try { if let v = self._rSquared {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.RegressionMetrics, rhs: Google_Cloud_Bigquery_V2_Model.RegressionMetrics) -> Bool {
    if lhs._meanAbsoluteError != rhs._meanAbsoluteError {return false}
    if lhs._meanSquaredError != rhs._meanSquaredError {return false}
    if lhs._meanSquaredLogError != rhs._meanSquaredLogError {return false}
    if lhs._medianAbsoluteError != rhs._medianAbsoluteError {return false}
    if lhs._rSquared != rhs._rSquared {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.AggregateClassificationMetrics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".AggregateClassificationMetrics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "precision"),
    2: .same(proto: "recall"),
    3: .same(proto: "accuracy"),
    4: .same(proto: "threshold"),
    5: .standard(proto: "f1_score"),
    6: .standard(proto: "log_loss"),
    7: .standard(proto: "roc_auc"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._precision) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._recall) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._accuracy) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._threshold) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._f1Score) }()
      case 6: try { try decoder.decodeSingularMessageField(value: &self._logLoss) }()
      case 7: try { try decoder.decodeSingularMessageField(value: &self._rocAuc) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._precision {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._recall {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._accuracy {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._threshold {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try { if let v = self._f1Score {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    try { if let v = self._logLoss {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    } }()
    try { if let v = self._rocAuc {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.AggregateClassificationMetrics, rhs: Google_Cloud_Bigquery_V2_Model.AggregateClassificationMetrics) -> Bool {
    if lhs._precision != rhs._precision {return false}
    if lhs._recall != rhs._recall {return false}
    if lhs._accuracy != rhs._accuracy {return false}
    if lhs._threshold != rhs._threshold {return false}
    if lhs._f1Score != rhs._f1Score {return false}
    if lhs._logLoss != rhs._logLoss {return false}
    if lhs._rocAuc != rhs._rocAuc {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.BinaryClassificationMetrics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".BinaryClassificationMetrics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "aggregate_classification_metrics"),
    2: .standard(proto: "binary_confusion_matrix_list"),
    3: .standard(proto: "positive_label"),
    4: .standard(proto: "negative_label"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._aggregateClassificationMetrics) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.binaryConfusionMatrixList) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.positiveLabel) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.negativeLabel) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._aggregateClassificationMetrics {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if !self.binaryConfusionMatrixList.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.binaryConfusionMatrixList, fieldNumber: 2)
    }
    if !self.positiveLabel.isEmpty {
      try visitor.visitSingularStringField(value: self.positiveLabel, fieldNumber: 3)
    }
    if !self.negativeLabel.isEmpty {
      try visitor.visitSingularStringField(value: self.negativeLabel, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.BinaryClassificationMetrics, rhs: Google_Cloud_Bigquery_V2_Model.BinaryClassificationMetrics) -> Bool {
    if lhs._aggregateClassificationMetrics != rhs._aggregateClassificationMetrics {return false}
    if lhs.binaryConfusionMatrixList != rhs.binaryConfusionMatrixList {return false}
    if lhs.positiveLabel != rhs.positiveLabel {return false}
    if lhs.negativeLabel != rhs.negativeLabel {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.BinaryClassificationMetrics.BinaryConfusionMatrix: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.BinaryClassificationMetrics.protoMessageName + ".BinaryConfusionMatrix"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "positive_class_threshold"),
    2: .standard(proto: "true_positives"),
    3: .standard(proto: "false_positives"),
    4: .standard(proto: "true_negatives"),
    5: .standard(proto: "false_negatives"),
    6: .same(proto: "precision"),
    7: .same(proto: "recall"),
    8: .standard(proto: "f1_score"),
    9: .same(proto: "accuracy"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._positiveClassThreshold) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._truePositives) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._falsePositives) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._trueNegatives) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._falseNegatives) }()
      case 6: try { try decoder.decodeSingularMessageField(value: &self._precision) }()
      case 7: try { try decoder.decodeSingularMessageField(value: &self._recall) }()
      case 8: try { try decoder.decodeSingularMessageField(value: &self._f1Score) }()
      case 9: try { try decoder.decodeSingularMessageField(value: &self._accuracy) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._positiveClassThreshold {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._truePositives {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._falsePositives {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._trueNegatives {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try { if let v = self._falseNegatives {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    try { if let v = self._precision {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    } }()
    try { if let v = self._recall {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
    } }()
    try { if let v = self._f1Score {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
    } }()
    try { if let v = self._accuracy {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.BinaryClassificationMetrics.BinaryConfusionMatrix, rhs: Google_Cloud_Bigquery_V2_Model.BinaryClassificationMetrics.BinaryConfusionMatrix) -> Bool {
    if lhs._positiveClassThreshold != rhs._positiveClassThreshold {return false}
    if lhs._truePositives != rhs._truePositives {return false}
    if lhs._falsePositives != rhs._falsePositives {return false}
    if lhs._trueNegatives != rhs._trueNegatives {return false}
    if lhs._falseNegatives != rhs._falseNegatives {return false}
    if lhs._precision != rhs._precision {return false}
    if lhs._recall != rhs._recall {return false}
    if lhs._f1Score != rhs._f1Score {return false}
    if lhs._accuracy != rhs._accuracy {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".MultiClassClassificationMetrics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "aggregate_classification_metrics"),
    2: .standard(proto: "confusion_matrix_list"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._aggregateClassificationMetrics) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.confusionMatrixList) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._aggregateClassificationMetrics {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if !self.confusionMatrixList.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.confusionMatrixList, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics, rhs: Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics) -> Bool {
    if lhs._aggregateClassificationMetrics != rhs._aggregateClassificationMetrics {return false}
    if lhs.confusionMatrixList != rhs.confusionMatrixList {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics.ConfusionMatrix: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics.protoMessageName + ".ConfusionMatrix"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "confidence_threshold"),
    2: .same(proto: "rows"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._confidenceThreshold) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.rows) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._confidenceThreshold {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if !self.rows.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.rows, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics.ConfusionMatrix, rhs: Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics.ConfusionMatrix) -> Bool {
    if lhs._confidenceThreshold != rhs._confidenceThreshold {return false}
    if lhs.rows != rhs.rows {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics.ConfusionMatrix.Entry: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics.ConfusionMatrix.protoMessageName + ".Entry"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "predicted_label"),
    2: .standard(proto: "item_count"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.predictedLabel) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._itemCount) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.predictedLabel.isEmpty {
      try visitor.visitSingularStringField(value: self.predictedLabel, fieldNumber: 1)
    }
    try { if let v = self._itemCount {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics.ConfusionMatrix.Entry, rhs: Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics.ConfusionMatrix.Entry) -> Bool {
    if lhs.predictedLabel != rhs.predictedLabel {return false}
    if lhs._itemCount != rhs._itemCount {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics.ConfusionMatrix.Row: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics.ConfusionMatrix.protoMessageName + ".Row"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "actual_label"),
    2: .same(proto: "entries"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.actualLabel) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.entries) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.actualLabel.isEmpty {
      try visitor.visitSingularStringField(value: self.actualLabel, fieldNumber: 1)
    }
    if !self.entries.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.entries, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics.ConfusionMatrix.Row, rhs: Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics.ConfusionMatrix.Row) -> Bool {
    if lhs.actualLabel != rhs.actualLabel {return false}
    if lhs.entries != rhs.entries {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.ClusteringMetrics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".ClusteringMetrics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "davies_bouldin_index"),
    2: .standard(proto: "mean_squared_distance"),
    3: .same(proto: "clusters"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._daviesBouldinIndex) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._meanSquaredDistance) }()
      case 3: try { try decoder.decodeRepeatedMessageField(value: &self.clusters) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._daviesBouldinIndex {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._meanSquaredDistance {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if !self.clusters.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.clusters, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.ClusteringMetrics, rhs: Google_Cloud_Bigquery_V2_Model.ClusteringMetrics) -> Bool {
    if lhs._daviesBouldinIndex != rhs._daviesBouldinIndex {return false}
    if lhs._meanSquaredDistance != rhs._meanSquaredDistance {return false}
    if lhs.clusters != rhs.clusters {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.protoMessageName + ".Cluster"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "centroid_id"),
    2: .standard(proto: "feature_values"),
    3: .same(proto: "count"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.centroidID) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.featureValues) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._count) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.centroidID != 0 {
      try visitor.visitSingularInt64Field(value: self.centroidID, fieldNumber: 1)
    }
    if !self.featureValues.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.featureValues, fieldNumber: 2)
    }
    try { if let v = self._count {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster, rhs: Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster) -> Bool {
    if lhs.centroidID != rhs.centroidID {return false}
    if lhs.featureValues != rhs.featureValues {return false}
    if lhs._count != rhs._count {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster.FeatureValue: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster.protoMessageName + ".FeatureValue"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "feature_column"),
    2: .standard(proto: "numerical_value"),
    3: .standard(proto: "categorical_value"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.featureColumn) }()
      case 2: try {
        var v: SwiftProtobuf.Google_Protobuf_DoubleValue?
        var hadOneofValue = false
        if let current = self.value {
          hadOneofValue = true
          if case .numericalValue(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.value = .numericalValue(v)
        }
      }()
      case 3: try {
        var v: Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster.FeatureValue.CategoricalValue?
        var hadOneofValue = false
        if let current = self.value {
          hadOneofValue = true
          if case .categoricalValue(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.value = .categoricalValue(v)
        }
      }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.featureColumn.isEmpty {
      try visitor.visitSingularStringField(value: self.featureColumn, fieldNumber: 1)
    }
    switch self.value {
    case .numericalValue?: try {
      guard case .numericalValue(let v)? = self.value else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case .categoricalValue?: try {
      guard case .categoricalValue(let v)? = self.value else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster.FeatureValue, rhs: Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster.FeatureValue) -> Bool {
    if lhs.featureColumn != rhs.featureColumn {return false}
    if lhs.value != rhs.value {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster.FeatureValue.CategoricalValue: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster.FeatureValue.protoMessageName + ".CategoricalValue"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "category_counts"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.categoryCounts) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.categoryCounts.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.categoryCounts, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster.FeatureValue.CategoricalValue, rhs: Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster.FeatureValue.CategoricalValue) -> Bool {
    if lhs.categoryCounts != rhs.categoryCounts {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster.FeatureValue.CategoricalValue.CategoryCount: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster.FeatureValue.CategoricalValue.protoMessageName + ".CategoryCount"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "category"),
    2: .same(proto: "count"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.category) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._count) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.category.isEmpty {
      try visitor.visitSingularStringField(value: self.category, fieldNumber: 1)
    }
    try { if let v = self._count {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster.FeatureValue.CategoricalValue.CategoryCount, rhs: Google_Cloud_Bigquery_V2_Model.ClusteringMetrics.Cluster.FeatureValue.CategoricalValue.CategoryCount) -> Bool {
    if lhs.category != rhs.category {return false}
    if lhs._count != rhs._count {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.RankingMetrics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".RankingMetrics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "mean_average_precision"),
    2: .standard(proto: "mean_squared_error"),
    3: .standard(proto: "normalized_discounted_cumulative_gain"),
    4: .standard(proto: "average_rank"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._meanAveragePrecision) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._meanSquaredError) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._normalizedDiscountedCumulativeGain) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._averageRank) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._meanAveragePrecision {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._meanSquaredError {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._normalizedDiscountedCumulativeGain {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._averageRank {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.RankingMetrics, rhs: Google_Cloud_Bigquery_V2_Model.RankingMetrics) -> Bool {
    if lhs._meanAveragePrecision != rhs._meanAveragePrecision {return false}
    if lhs._meanSquaredError != rhs._meanSquaredError {return false}
    if lhs._normalizedDiscountedCumulativeGain != rhs._normalizedDiscountedCumulativeGain {return false}
    if lhs._averageRank != rhs._averageRank {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.ArimaForecastingMetrics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".ArimaForecastingMetrics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    6: .standard(proto: "arima_single_model_forecasting_metrics"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 6: try { try decoder.decodeRepeatedMessageField(value: &self.arimaSingleModelForecastingMetrics) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.arimaSingleModelForecastingMetrics.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.arimaSingleModelForecastingMetrics, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.ArimaForecastingMetrics, rhs: Google_Cloud_Bigquery_V2_Model.ArimaForecastingMetrics) -> Bool {
    if lhs.arimaSingleModelForecastingMetrics != rhs.arimaSingleModelForecastingMetrics {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.ArimaForecastingMetrics.ArimaSingleModelForecastingMetrics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.ArimaForecastingMetrics.protoMessageName + ".ArimaSingleModelForecastingMetrics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "non_seasonal_order"),
    2: .standard(proto: "arima_fitting_metrics"),
    3: .standard(proto: "has_drift"),
    4: .standard(proto: "time_series_id"),
    9: .standard(proto: "time_series_ids"),
    5: .standard(proto: "seasonal_periods"),
    6: .standard(proto: "has_holiday_effect"),
    7: .standard(proto: "has_spikes_and_dips"),
    8: .standard(proto: "has_step_changes"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._nonSeasonalOrder) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._arimaFittingMetrics) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._hasDrift_p) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.timeSeriesID) }()
      case 5: try { try decoder.decodeRepeatedEnumField(value: &self.seasonalPeriods) }()
      case 6: try { try decoder.decodeSingularMessageField(value: &self._hasHolidayEffect_p) }()
      case 7: try { try decoder.decodeSingularMessageField(value: &self._hasSpikesAndDips_p) }()
      case 8: try { try decoder.decodeSingularMessageField(value: &self._hasStepChanges_p) }()
      case 9: try { try decoder.decodeRepeatedStringField(value: &self.timeSeriesIds) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._nonSeasonalOrder {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._arimaFittingMetrics {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._hasDrift_p {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    if !self.timeSeriesID.isEmpty {
      try visitor.visitSingularStringField(value: self.timeSeriesID, fieldNumber: 4)
    }
    if !self.seasonalPeriods.isEmpty {
      try visitor.visitPackedEnumField(value: self.seasonalPeriods, fieldNumber: 5)
    }
    try { if let v = self._hasHolidayEffect_p {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    } }()
    try { if let v = self._hasSpikesAndDips_p {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
    } }()
    try { if let v = self._hasStepChanges_p {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
    } }()
    if !self.timeSeriesIds.isEmpty {
      try visitor.visitRepeatedStringField(value: self.timeSeriesIds, fieldNumber: 9)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.ArimaForecastingMetrics.ArimaSingleModelForecastingMetrics, rhs: Google_Cloud_Bigquery_V2_Model.ArimaForecastingMetrics.ArimaSingleModelForecastingMetrics) -> Bool {
    if lhs._nonSeasonalOrder != rhs._nonSeasonalOrder {return false}
    if lhs._arimaFittingMetrics != rhs._arimaFittingMetrics {return false}
    if lhs._hasDrift_p != rhs._hasDrift_p {return false}
    if lhs.timeSeriesID != rhs.timeSeriesID {return false}
    if lhs.timeSeriesIds != rhs.timeSeriesIds {return false}
    if lhs.seasonalPeriods != rhs.seasonalPeriods {return false}
    if lhs._hasHolidayEffect_p != rhs._hasHolidayEffect_p {return false}
    if lhs._hasSpikesAndDips_p != rhs._hasSpikesAndDips_p {return false}
    if lhs._hasStepChanges_p != rhs._hasStepChanges_p {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.DimensionalityReductionMetrics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".DimensionalityReductionMetrics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "total_explained_variance_ratio"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._totalExplainedVarianceRatio) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._totalExplainedVarianceRatio {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.DimensionalityReductionMetrics, rhs: Google_Cloud_Bigquery_V2_Model.DimensionalityReductionMetrics) -> Bool {
    if lhs._totalExplainedVarianceRatio != rhs._totalExplainedVarianceRatio {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.EvaluationMetrics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".EvaluationMetrics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "regression_metrics"),
    2: .standard(proto: "binary_classification_metrics"),
    3: .standard(proto: "multi_class_classification_metrics"),
    4: .standard(proto: "clustering_metrics"),
    5: .standard(proto: "ranking_metrics"),
    6: .standard(proto: "arima_forecasting_metrics"),
    7: .standard(proto: "dimensionality_reduction_metrics"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Google_Cloud_Bigquery_V2_Model.RegressionMetrics?
        var hadOneofValue = false
        if let current = self.metrics {
          hadOneofValue = true
          if case .regressionMetrics(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.metrics = .regressionMetrics(v)
        }
      }()
      case 2: try {
        var v: Google_Cloud_Bigquery_V2_Model.BinaryClassificationMetrics?
        var hadOneofValue = false
        if let current = self.metrics {
          hadOneofValue = true
          if case .binaryClassificationMetrics(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.metrics = .binaryClassificationMetrics(v)
        }
      }()
      case 3: try {
        var v: Google_Cloud_Bigquery_V2_Model.MultiClassClassificationMetrics?
        var hadOneofValue = false
        if let current = self.metrics {
          hadOneofValue = true
          if case .multiClassClassificationMetrics(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.metrics = .multiClassClassificationMetrics(v)
        }
      }()
      case 4: try {
        var v: Google_Cloud_Bigquery_V2_Model.ClusteringMetrics?
        var hadOneofValue = false
        if let current = self.metrics {
          hadOneofValue = true
          if case .clusteringMetrics(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.metrics = .clusteringMetrics(v)
        }
      }()
      case 5: try {
        var v: Google_Cloud_Bigquery_V2_Model.RankingMetrics?
        var hadOneofValue = false
        if let current = self.metrics {
          hadOneofValue = true
          if case .rankingMetrics(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.metrics = .rankingMetrics(v)
        }
      }()
      case 6: try {
        var v: Google_Cloud_Bigquery_V2_Model.ArimaForecastingMetrics?
        var hadOneofValue = false
        if let current = self.metrics {
          hadOneofValue = true
          if case .arimaForecastingMetrics(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.metrics = .arimaForecastingMetrics(v)
        }
      }()
      case 7: try {
        var v: Google_Cloud_Bigquery_V2_Model.DimensionalityReductionMetrics?
        var hadOneofValue = false
        if let current = self.metrics {
          hadOneofValue = true
          if case .dimensionalityReductionMetrics(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.metrics = .dimensionalityReductionMetrics(v)
        }
      }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.metrics {
    case .regressionMetrics?: try {
      guard case .regressionMetrics(let v)? = self.metrics else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .binaryClassificationMetrics?: try {
      guard case .binaryClassificationMetrics(let v)? = self.metrics else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case .multiClassClassificationMetrics?: try {
      guard case .multiClassClassificationMetrics(let v)? = self.metrics else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }()
    case .clusteringMetrics?: try {
      guard case .clusteringMetrics(let v)? = self.metrics else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }()
    case .rankingMetrics?: try {
      guard case .rankingMetrics(let v)? = self.metrics else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }()
    case .arimaForecastingMetrics?: try {
      guard case .arimaForecastingMetrics(let v)? = self.metrics else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    }()
    case .dimensionalityReductionMetrics?: try {
      guard case .dimensionalityReductionMetrics(let v)? = self.metrics else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.EvaluationMetrics, rhs: Google_Cloud_Bigquery_V2_Model.EvaluationMetrics) -> Bool {
    if lhs.metrics != rhs.metrics {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.DataSplitResult: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".DataSplitResult"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "training_table"),
    2: .standard(proto: "evaluation_table"),
    3: .standard(proto: "test_table"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._trainingTable) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._evaluationTable) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._testTable) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._trainingTable {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._evaluationTable {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._testTable {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.DataSplitResult, rhs: Google_Cloud_Bigquery_V2_Model.DataSplitResult) -> Bool {
    if lhs._trainingTable != rhs._trainingTable {return false}
    if lhs._evaluationTable != rhs._evaluationTable {return false}
    if lhs._testTable != rhs._testTable {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.ArimaOrder: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".ArimaOrder"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "p"),
    2: .same(proto: "d"),
    3: .same(proto: "q"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._p) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._d) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._q) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._p {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._d {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._q {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.ArimaOrder, rhs: Google_Cloud_Bigquery_V2_Model.ArimaOrder) -> Bool {
    if lhs._p != rhs._p {return false}
    if lhs._d != rhs._d {return false}
    if lhs._q != rhs._q {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.ArimaFittingMetrics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".ArimaFittingMetrics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "log_likelihood"),
    2: .same(proto: "aic"),
    3: .same(proto: "variance"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._logLikelihood) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._aic) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._variance) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._logLikelihood {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._aic {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._variance {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.ArimaFittingMetrics, rhs: Google_Cloud_Bigquery_V2_Model.ArimaFittingMetrics) -> Bool {
    if lhs._logLikelihood != rhs._logLikelihood {return false}
    if lhs._aic != rhs._aic {return false}
    if lhs._variance != rhs._variance {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.GlobalExplanation: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".GlobalExplanation"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "explanations"),
    2: .standard(proto: "class_label"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.explanations) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.classLabel) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.explanations.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.explanations, fieldNumber: 1)
    }
    if !self.classLabel.isEmpty {
      try visitor.visitSingularStringField(value: self.classLabel, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.GlobalExplanation, rhs: Google_Cloud_Bigquery_V2_Model.GlobalExplanation) -> Bool {
    if lhs.explanations != rhs.explanations {return false}
    if lhs.classLabel != rhs.classLabel {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.GlobalExplanation.Explanation: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.GlobalExplanation.protoMessageName + ".Explanation"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "feature_name"),
    2: .same(proto: "attribution"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.featureName) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._attribution) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.featureName.isEmpty {
      try visitor.visitSingularStringField(value: self.featureName, fieldNumber: 1)
    }
    try { if let v = self._attribution {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.GlobalExplanation.Explanation, rhs: Google_Cloud_Bigquery_V2_Model.GlobalExplanation.Explanation) -> Bool {
    if lhs.featureName != rhs.featureName {return false}
    if lhs._attribution != rhs._attribution {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.CategoryEncodingMethod: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".CategoryEncodingMethod"
  package static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    // Load everything into unknown fields
    while try decoder.nextFieldNumber() != nil {}
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.CategoryEncodingMethod, rhs: Google_Cloud_Bigquery_V2_Model.CategoryEncodingMethod) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.CategoryEncodingMethod.EncodingMethod: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "ENCODING_METHOD_UNSPECIFIED"),
    1: .same(proto: "ONE_HOT_ENCODING"),
    2: .same(proto: "LABEL_ENCODING"),
    3: .same(proto: "DUMMY_ENCODING"),
  ]
}

extension Google_Cloud_Bigquery_V2_Model.PcaSolverOptionEnums: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".PcaSolverOptionEnums"
  package static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    // Load everything into unknown fields
    while try decoder.nextFieldNumber() != nil {}
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.PcaSolverOptionEnums, rhs: Google_Cloud_Bigquery_V2_Model.PcaSolverOptionEnums) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.PcaSolverOptionEnums.PcaSolver: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "UNSPECIFIED"),
    1: .same(proto: "FULL"),
    2: .same(proto: "RANDOMIZED"),
    3: .same(proto: "AUTO"),
  ]
}

extension Google_Cloud_Bigquery_V2_Model.ModelRegistryOptionEnums: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".ModelRegistryOptionEnums"
  package static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    // Load everything into unknown fields
    while try decoder.nextFieldNumber() != nil {}
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.ModelRegistryOptionEnums, rhs: Google_Cloud_Bigquery_V2_Model.ModelRegistryOptionEnums) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.ModelRegistryOptionEnums.ModelRegistry: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "MODEL_REGISTRY_UNSPECIFIED"),
    1: .same(proto: "VERTEX_AI"),
  ]
}

extension Google_Cloud_Bigquery_V2_Model.TrainingRun: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".TrainingRun"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "training_options"),
    8: .standard(proto: "start_time"),
    6: .same(proto: "results"),
    7: .standard(proto: "evaluation_metrics"),
    9: .standard(proto: "data_split_result"),
    11: .standard(proto: "model_level_global_explanation"),
    12: .standard(proto: "class_level_global_explanations"),
    14: .standard(proto: "vertex_ai_model_id"),
    15: .standard(proto: "vertex_ai_model_version"),
  ]

  fileprivate class _StorageClass {
    var _trainingOptions: Google_Cloud_Bigquery_V2_Model.TrainingRun.TrainingOptions? = nil
    var _startTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _results: [Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult] = []
    var _evaluationMetrics: Google_Cloud_Bigquery_V2_Model.EvaluationMetrics? = nil
    var _dataSplitResult: Google_Cloud_Bigquery_V2_Model.DataSplitResult? = nil
    var _modelLevelGlobalExplanation: Google_Cloud_Bigquery_V2_Model.GlobalExplanation? = nil
    var _classLevelGlobalExplanations: [Google_Cloud_Bigquery_V2_Model.GlobalExplanation] = []
    var _vertexAiModelID: String = String()
    var _vertexAiModelVersion: String = String()

    #if swift(>=5.10)
      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()
    #else
      static let defaultInstance = _StorageClass()
    #endif

    private init() {}

    init(copying source: _StorageClass) {
      _trainingOptions = source._trainingOptions
      _startTime = source._startTime
      _results = source._results
      _evaluationMetrics = source._evaluationMetrics
      _dataSplitResult = source._dataSplitResult
      _modelLevelGlobalExplanation = source._modelLevelGlobalExplanation
      _classLevelGlobalExplanations = source._classLevelGlobalExplanations
      _vertexAiModelID = source._vertexAiModelID
      _vertexAiModelVersion = source._vertexAiModelVersion
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularMessageField(value: &_storage._trainingOptions) }()
        case 6: try { try decoder.decodeRepeatedMessageField(value: &_storage._results) }()
        case 7: try { try decoder.decodeSingularMessageField(value: &_storage._evaluationMetrics) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._startTime) }()
        case 9: try { try decoder.decodeSingularMessageField(value: &_storage._dataSplitResult) }()
        case 11: try { try decoder.decodeSingularMessageField(value: &_storage._modelLevelGlobalExplanation) }()
        case 12: try { try decoder.decodeRepeatedMessageField(value: &_storage._classLevelGlobalExplanations) }()
        case 14: try { try decoder.decodeSingularStringField(value: &_storage._vertexAiModelID) }()
        case 15: try { try decoder.decodeSingularStringField(value: &_storage._vertexAiModelVersion) }()
        default: break
        }
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      try { if let v = _storage._trainingOptions {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      } }()
      if !_storage._results.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._results, fieldNumber: 6)
      }
      try { if let v = _storage._evaluationMetrics {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      } }()
      try { if let v = _storage._startTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      } }()
      try { if let v = _storage._dataSplitResult {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      } }()
      try { if let v = _storage._modelLevelGlobalExplanation {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
      } }()
      if !_storage._classLevelGlobalExplanations.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._classLevelGlobalExplanations, fieldNumber: 12)
      }
      if !_storage._vertexAiModelID.isEmpty {
        try visitor.visitSingularStringField(value: _storage._vertexAiModelID, fieldNumber: 14)
      }
      if !_storage._vertexAiModelVersion.isEmpty {
        try visitor.visitSingularStringField(value: _storage._vertexAiModelVersion, fieldNumber: 15)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.TrainingRun, rhs: Google_Cloud_Bigquery_V2_Model.TrainingRun) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._trainingOptions != rhs_storage._trainingOptions {return false}
        if _storage._startTime != rhs_storage._startTime {return false}
        if _storage._results != rhs_storage._results {return false}
        if _storage._evaluationMetrics != rhs_storage._evaluationMetrics {return false}
        if _storage._dataSplitResult != rhs_storage._dataSplitResult {return false}
        if _storage._modelLevelGlobalExplanation != rhs_storage._modelLevelGlobalExplanation {return false}
        if _storage._classLevelGlobalExplanations != rhs_storage._classLevelGlobalExplanations {return false}
        if _storage._vertexAiModelID != rhs_storage._vertexAiModelID {return false}
        if _storage._vertexAiModelVersion != rhs_storage._vertexAiModelVersion {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.TrainingRun.TrainingOptions: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.TrainingRun.protoMessageName + ".TrainingOptions"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "max_iterations"),
    2: .standard(proto: "loss_type"),
    3: .standard(proto: "learn_rate"),
    4: .standard(proto: "l1_regularization"),
    5: .standard(proto: "l2_regularization"),
    6: .standard(proto: "min_relative_progress"),
    7: .standard(proto: "warm_start"),
    8: .standard(proto: "early_stop"),
    9: .standard(proto: "input_label_columns"),
    10: .standard(proto: "data_split_method"),
    11: .standard(proto: "data_split_eval_fraction"),
    12: .standard(proto: "data_split_column"),
    13: .standard(proto: "learn_rate_strategy"),
    16: .standard(proto: "initial_learn_rate"),
    17: .standard(proto: "label_class_weights"),
    18: .standard(proto: "user_column"),
    19: .standard(proto: "item_column"),
    20: .standard(proto: "distance_type"),
    21: .standard(proto: "num_clusters"),
    22: .standard(proto: "model_uri"),
    23: .standard(proto: "optimization_strategy"),
    24: .standard(proto: "hidden_units"),
    25: .standard(proto: "batch_size"),
    26: .same(proto: "dropout"),
    27: .standard(proto: "max_tree_depth"),
    28: .same(proto: "subsample"),
    29: .standard(proto: "min_split_loss"),
    60: .standard(proto: "booster_type"),
    61: .standard(proto: "num_parallel_tree"),
    62: .standard(proto: "dart_normalize_type"),
    63: .standard(proto: "tree_method"),
    64: .standard(proto: "min_tree_child_weight"),
    65: .standard(proto: "colsample_bytree"),
    66: .standard(proto: "colsample_bylevel"),
    67: .standard(proto: "colsample_bynode"),
    30: .standard(proto: "num_factors"),
    31: .standard(proto: "feedback_type"),
    32: .standard(proto: "wals_alpha"),
    33: .standard(proto: "kmeans_initialization_method"),
    34: .standard(proto: "kmeans_initialization_column"),
    35: .standard(proto: "time_series_timestamp_column"),
    36: .standard(proto: "time_series_data_column"),
    37: .standard(proto: "auto_arima"),
    38: .standard(proto: "non_seasonal_order"),
    39: .standard(proto: "data_frequency"),
    40: .standard(proto: "calculate_p_values"),
    41: .standard(proto: "include_drift"),
    42: .standard(proto: "holiday_region"),
    71: .standard(proto: "holiday_regions"),
    43: .standard(proto: "time_series_id_column"),
    51: .standard(proto: "time_series_id_columns"),
    44: .same(proto: "horizon"),
    46: .standard(proto: "auto_arima_max_order"),
    83: .standard(proto: "auto_arima_min_order"),
    47: .standard(proto: "num_trials"),
    48: .standard(proto: "max_parallel_trials"),
    54: .standard(proto: "hparam_tuning_objectives"),
    50: .standard(proto: "decompose_time_series"),
    52: .standard(proto: "clean_spikes_and_dips"),
    53: .standard(proto: "adjust_step_changes"),
    55: .standard(proto: "enable_global_explain"),
    56: .standard(proto: "sampled_shapley_num_paths"),
    57: .standard(proto: "integrated_gradients_num_steps"),
    58: .standard(proto: "category_encoding_method"),
    70: .standard(proto: "tf_version"),
    72: .standard(proto: "color_space"),
    73: .standard(proto: "instance_weight_column"),
    74: .standard(proto: "trend_smoothing_window_size"),
    75: .standard(proto: "time_series_length_fraction"),
    76: .standard(proto: "min_time_series_length"),
    77: .standard(proto: "max_time_series_length"),
    78: .standard(proto: "xgboost_version"),
    84: .standard(proto: "approx_global_feature_contrib"),
    85: .standard(proto: "fit_intercept"),
    86: .standard(proto: "num_principal_components"),
    87: .standard(proto: "pca_explained_variance_ratio"),
    88: .standard(proto: "scale_features"),
    89: .standard(proto: "pca_solver"),
    90: .standard(proto: "auto_class_weights"),
    91: .standard(proto: "activation_fn"),
    92: .same(proto: "optimizer"),
    93: .standard(proto: "budget_hours"),
    94: .standard(proto: "standardize_features"),
    95: .standard(proto: "l1_reg_activation"),
    96: .standard(proto: "model_registry"),
    97: .standard(proto: "vertex_ai_model_version_aliases"),
    104: .standard(proto: "dimension_id_columns"),
    105: .standard(proto: "contribution_metric"),
    106: .standard(proto: "is_test_column"),
    107: .standard(proto: "min_apriori_support"),
  ]

  fileprivate class _StorageClass {
    var _maxIterations: Int64 = 0
    var _lossType: Google_Cloud_Bigquery_V2_Model.LossType = .unspecified
    var _learnRate: Double = 0
    var _l1Regularization: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _l2Regularization: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _minRelativeProgress: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _warmStart: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _earlyStop: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _inputLabelColumns: [String] = []
    var _dataSplitMethod: Google_Cloud_Bigquery_V2_Model.DataSplitMethod = .unspecified
    var _dataSplitEvalFraction: Double = 0
    var _dataSplitColumn: String = String()
    var _learnRateStrategy: Google_Cloud_Bigquery_V2_Model.LearnRateStrategy = .unspecified
    var _initialLearnRate: Double = 0
    var _labelClassWeights: Dictionary<String,Double> = [:]
    var _userColumn: String = String()
    var _itemColumn: String = String()
    var _distanceType: Google_Cloud_Bigquery_V2_Model.DistanceType = .unspecified
    var _numClusters: Int64 = 0
    var _modelUri: String = String()
    var _optimizationStrategy: Google_Cloud_Bigquery_V2_Model.OptimizationStrategy = .unspecified
    var _hiddenUnits: [Int64] = []
    var _batchSize: Int64 = 0
    var _dropout: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _maxTreeDepth: Int64 = 0
    var _subsample: Double = 0
    var _minSplitLoss: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _boosterType: Google_Cloud_Bigquery_V2_Model.BoostedTreeOptionEnums.BoosterType = .unspecified
    var _numParallelTree: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _dartNormalizeType: Google_Cloud_Bigquery_V2_Model.BoostedTreeOptionEnums.DartNormalizeType = .unspecified
    var _treeMethod: Google_Cloud_Bigquery_V2_Model.BoostedTreeOptionEnums.TreeMethod = .unspecified
    var _minTreeChildWeight: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _colsampleBytree: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _colsampleBylevel: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _colsampleBynode: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _numFactors: Int64 = 0
    var _feedbackType: Google_Cloud_Bigquery_V2_Model.FeedbackType = .unspecified
    var _walsAlpha: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _kmeansInitializationMethod: Google_Cloud_Bigquery_V2_Model.KmeansEnums.KmeansInitializationMethod = .unspecified
    var _kmeansInitializationColumn: String = String()
    var _timeSeriesTimestampColumn: String = String()
    var _timeSeriesDataColumn: String = String()
    var _autoArima: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _nonSeasonalOrder: Google_Cloud_Bigquery_V2_Model.ArimaOrder? = nil
    var _dataFrequency: Google_Cloud_Bigquery_V2_Model.DataFrequency = .unspecified
    var _calculatePValues: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _includeDrift: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _holidayRegion: Google_Cloud_Bigquery_V2_Model.HolidayRegion = .unspecified
    var _holidayRegions: [Google_Cloud_Bigquery_V2_Model.HolidayRegion] = []
    var _timeSeriesIDColumn: String = String()
    var _timeSeriesIDColumns: [String] = []
    var _horizon: Int64 = 0
    var _autoArimaMaxOrder: Int64 = 0
    var _autoArimaMinOrder: Int64 = 0
    var _numTrials: Int64 = 0
    var _maxParallelTrials: Int64 = 0
    var _hparamTuningObjectives: [Google_Cloud_Bigquery_V2_Model.HparamTuningEnums.HparamTuningObjective] = []
    var _decomposeTimeSeries: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _cleanSpikesAndDips: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _adjustStepChanges: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _enableGlobalExplain: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _sampledShapleyNumPaths: Int64 = 0
    var _integratedGradientsNumSteps: Int64 = 0
    var _categoryEncodingMethod: Google_Cloud_Bigquery_V2_Model.CategoryEncodingMethod.EncodingMethod = .unspecified
    var _tfVersion: String = String()
    var _colorSpace: Google_Cloud_Bigquery_V2_Model.ColorSpace = .unspecified
    var _instanceWeightColumn: String = String()
    var _trendSmoothingWindowSize: Int64 = 0
    var _timeSeriesLengthFraction: Double = 0
    var _minTimeSeriesLength: Int64 = 0
    var _maxTimeSeriesLength: Int64 = 0
    var _xgboostVersion: String = String()
    var _approxGlobalFeatureContrib: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _fitIntercept: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _numPrincipalComponents: Int64 = 0
    var _pcaExplainedVarianceRatio: Double = 0
    var _scaleFeatures: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _pcaSolver: Google_Cloud_Bigquery_V2_Model.PcaSolverOptionEnums.PcaSolver = .unspecified
    var _autoClassWeights: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _activationFn: String = String()
    var _optimizer: String = String()
    var _budgetHours: Double = 0
    var _standardizeFeatures: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _l1RegActivation: Double = 0
    var _modelRegistry: Google_Cloud_Bigquery_V2_Model.ModelRegistryOptionEnums.ModelRegistry = .unspecified
    var _vertexAiModelVersionAliases: [String] = []
    var _dimensionIDColumns: [String] = []
    var _contributionMetric: String? = nil
    var _isTestColumn: String? = nil
    var _minAprioriSupport: Double? = nil

    #if swift(>=5.10)
      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()
    #else
      static let defaultInstance = _StorageClass()
    #endif

    private init() {}

    init(copying source: _StorageClass) {
      _maxIterations = source._maxIterations
      _lossType = source._lossType
      _learnRate = source._learnRate
      _l1Regularization = source._l1Regularization
      _l2Regularization = source._l2Regularization
      _minRelativeProgress = source._minRelativeProgress
      _warmStart = source._warmStart
      _earlyStop = source._earlyStop
      _inputLabelColumns = source._inputLabelColumns
      _dataSplitMethod = source._dataSplitMethod
      _dataSplitEvalFraction = source._dataSplitEvalFraction
      _dataSplitColumn = source._dataSplitColumn
      _learnRateStrategy = source._learnRateStrategy
      _initialLearnRate = source._initialLearnRate
      _labelClassWeights = source._labelClassWeights
      _userColumn = source._userColumn
      _itemColumn = source._itemColumn
      _distanceType = source._distanceType
      _numClusters = source._numClusters
      _modelUri = source._modelUri
      _optimizationStrategy = source._optimizationStrategy
      _hiddenUnits = source._hiddenUnits
      _batchSize = source._batchSize
      _dropout = source._dropout
      _maxTreeDepth = source._maxTreeDepth
      _subsample = source._subsample
      _minSplitLoss = source._minSplitLoss
      _boosterType = source._boosterType
      _numParallelTree = source._numParallelTree
      _dartNormalizeType = source._dartNormalizeType
      _treeMethod = source._treeMethod
      _minTreeChildWeight = source._minTreeChildWeight
      _colsampleBytree = source._colsampleBytree
      _colsampleBylevel = source._colsampleBylevel
      _colsampleBynode = source._colsampleBynode
      _numFactors = source._numFactors
      _feedbackType = source._feedbackType
      _walsAlpha = source._walsAlpha
      _kmeansInitializationMethod = source._kmeansInitializationMethod
      _kmeansInitializationColumn = source._kmeansInitializationColumn
      _timeSeriesTimestampColumn = source._timeSeriesTimestampColumn
      _timeSeriesDataColumn = source._timeSeriesDataColumn
      _autoArima = source._autoArima
      _nonSeasonalOrder = source._nonSeasonalOrder
      _dataFrequency = source._dataFrequency
      _calculatePValues = source._calculatePValues
      _includeDrift = source._includeDrift
      _holidayRegion = source._holidayRegion
      _holidayRegions = source._holidayRegions
      _timeSeriesIDColumn = source._timeSeriesIDColumn
      _timeSeriesIDColumns = source._timeSeriesIDColumns
      _horizon = source._horizon
      _autoArimaMaxOrder = source._autoArimaMaxOrder
      _autoArimaMinOrder = source._autoArimaMinOrder
      _numTrials = source._numTrials
      _maxParallelTrials = source._maxParallelTrials
      _hparamTuningObjectives = source._hparamTuningObjectives
      _decomposeTimeSeries = source._decomposeTimeSeries
      _cleanSpikesAndDips = source._cleanSpikesAndDips
      _adjustStepChanges = source._adjustStepChanges
      _enableGlobalExplain = source._enableGlobalExplain
      _sampledShapleyNumPaths = source._sampledShapleyNumPaths
      _integratedGradientsNumSteps = source._integratedGradientsNumSteps
      _categoryEncodingMethod = source._categoryEncodingMethod
      _tfVersion = source._tfVersion
      _colorSpace = source._colorSpace
      _instanceWeightColumn = source._instanceWeightColumn
      _trendSmoothingWindowSize = source._trendSmoothingWindowSize
      _timeSeriesLengthFraction = source._timeSeriesLengthFraction
      _minTimeSeriesLength = source._minTimeSeriesLength
      _maxTimeSeriesLength = source._maxTimeSeriesLength
      _xgboostVersion = source._xgboostVersion
      _approxGlobalFeatureContrib = source._approxGlobalFeatureContrib
      _fitIntercept = source._fitIntercept
      _numPrincipalComponents = source._numPrincipalComponents
      _pcaExplainedVarianceRatio = source._pcaExplainedVarianceRatio
      _scaleFeatures = source._scaleFeatures
      _pcaSolver = source._pcaSolver
      _autoClassWeights = source._autoClassWeights
      _activationFn = source._activationFn
      _optimizer = source._optimizer
      _budgetHours = source._budgetHours
      _standardizeFeatures = source._standardizeFeatures
      _l1RegActivation = source._l1RegActivation
      _modelRegistry = source._modelRegistry
      _vertexAiModelVersionAliases = source._vertexAiModelVersionAliases
      _dimensionIDColumns = source._dimensionIDColumns
      _contributionMetric = source._contributionMetric
      _isTestColumn = source._isTestColumn
      _minAprioriSupport = source._minAprioriSupport
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularInt64Field(value: &_storage._maxIterations) }()
        case 2: try { try decoder.decodeSingularEnumField(value: &_storage._lossType) }()
        case 3: try { try decoder.decodeSingularDoubleField(value: &_storage._learnRate) }()
        case 4: try { try decoder.decodeSingularMessageField(value: &_storage._l1Regularization) }()
        case 5: try { try decoder.decodeSingularMessageField(value: &_storage._l2Regularization) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._minRelativeProgress) }()
        case 7: try { try decoder.decodeSingularMessageField(value: &_storage._warmStart) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._earlyStop) }()
        case 9: try { try decoder.decodeRepeatedStringField(value: &_storage._inputLabelColumns) }()
        case 10: try { try decoder.decodeSingularEnumField(value: &_storage._dataSplitMethod) }()
        case 11: try { try decoder.decodeSingularDoubleField(value: &_storage._dataSplitEvalFraction) }()
        case 12: try { try decoder.decodeSingularStringField(value: &_storage._dataSplitColumn) }()
        case 13: try { try decoder.decodeSingularEnumField(value: &_storage._learnRateStrategy) }()
        case 16: try { try decoder.decodeSingularDoubleField(value: &_storage._initialLearnRate) }()
        case 17: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufDouble>.self, value: &_storage._labelClassWeights) }()
        case 18: try { try decoder.decodeSingularStringField(value: &_storage._userColumn) }()
        case 19: try { try decoder.decodeSingularStringField(value: &_storage._itemColumn) }()
        case 20: try { try decoder.decodeSingularEnumField(value: &_storage._distanceType) }()
        case 21: try { try decoder.decodeSingularInt64Field(value: &_storage._numClusters) }()
        case 22: try { try decoder.decodeSingularStringField(value: &_storage._modelUri) }()
        case 23: try { try decoder.decodeSingularEnumField(value: &_storage._optimizationStrategy) }()
        case 24: try { try decoder.decodeRepeatedInt64Field(value: &_storage._hiddenUnits) }()
        case 25: try { try decoder.decodeSingularInt64Field(value: &_storage._batchSize) }()
        case 26: try { try decoder.decodeSingularMessageField(value: &_storage._dropout) }()
        case 27: try { try decoder.decodeSingularInt64Field(value: &_storage._maxTreeDepth) }()
        case 28: try { try decoder.decodeSingularDoubleField(value: &_storage._subsample) }()
        case 29: try { try decoder.decodeSingularMessageField(value: &_storage._minSplitLoss) }()
        case 30: try { try decoder.decodeSingularInt64Field(value: &_storage._numFactors) }()
        case 31: try { try decoder.decodeSingularEnumField(value: &_storage._feedbackType) }()
        case 32: try { try decoder.decodeSingularMessageField(value: &_storage._walsAlpha) }()
        case 33: try { try decoder.decodeSingularEnumField(value: &_storage._kmeansInitializationMethod) }()
        case 34: try { try decoder.decodeSingularStringField(value: &_storage._kmeansInitializationColumn) }()
        case 35: try { try decoder.decodeSingularStringField(value: &_storage._timeSeriesTimestampColumn) }()
        case 36: try { try decoder.decodeSingularStringField(value: &_storage._timeSeriesDataColumn) }()
        case 37: try { try decoder.decodeSingularMessageField(value: &_storage._autoArima) }()
        case 38: try { try decoder.decodeSingularMessageField(value: &_storage._nonSeasonalOrder) }()
        case 39: try { try decoder.decodeSingularEnumField(value: &_storage._dataFrequency) }()
        case 40: try { try decoder.decodeSingularMessageField(value: &_storage._calculatePValues) }()
        case 41: try { try decoder.decodeSingularMessageField(value: &_storage._includeDrift) }()
        case 42: try { try decoder.decodeSingularEnumField(value: &_storage._holidayRegion) }()
        case 43: try { try decoder.decodeSingularStringField(value: &_storage._timeSeriesIDColumn) }()
        case 44: try { try decoder.decodeSingularInt64Field(value: &_storage._horizon) }()
        case 46: try { try decoder.decodeSingularInt64Field(value: &_storage._autoArimaMaxOrder) }()
        case 47: try { try decoder.decodeSingularInt64Field(value: &_storage._numTrials) }()
        case 48: try { try decoder.decodeSingularInt64Field(value: &_storage._maxParallelTrials) }()
        case 50: try { try decoder.decodeSingularMessageField(value: &_storage._decomposeTimeSeries) }()
        case 51: try { try decoder.decodeRepeatedStringField(value: &_storage._timeSeriesIDColumns) }()
        case 52: try { try decoder.decodeSingularMessageField(value: &_storage._cleanSpikesAndDips) }()
        case 53: try { try decoder.decodeSingularMessageField(value: &_storage._adjustStepChanges) }()
        case 54: try { try decoder.decodeRepeatedEnumField(value: &_storage._hparamTuningObjectives) }()
        case 55: try { try decoder.decodeSingularMessageField(value: &_storage._enableGlobalExplain) }()
        case 56: try { try decoder.decodeSingularInt64Field(value: &_storage._sampledShapleyNumPaths) }()
        case 57: try { try decoder.decodeSingularInt64Field(value: &_storage._integratedGradientsNumSteps) }()
        case 58: try { try decoder.decodeSingularEnumField(value: &_storage._categoryEncodingMethod) }()
        case 60: try { try decoder.decodeSingularEnumField(value: &_storage._boosterType) }()
        case 61: try { try decoder.decodeSingularMessageField(value: &_storage._numParallelTree) }()
        case 62: try { try decoder.decodeSingularEnumField(value: &_storage._dartNormalizeType) }()
        case 63: try { try decoder.decodeSingularEnumField(value: &_storage._treeMethod) }()
        case 64: try { try decoder.decodeSingularMessageField(value: &_storage._minTreeChildWeight) }()
        case 65: try { try decoder.decodeSingularMessageField(value: &_storage._colsampleBytree) }()
        case 66: try { try decoder.decodeSingularMessageField(value: &_storage._colsampleBylevel) }()
        case 67: try { try decoder.decodeSingularMessageField(value: &_storage._colsampleBynode) }()
        case 70: try { try decoder.decodeSingularStringField(value: &_storage._tfVersion) }()
        case 71: try { try decoder.decodeRepeatedEnumField(value: &_storage._holidayRegions) }()
        case 72: try { try decoder.decodeSingularEnumField(value: &_storage._colorSpace) }()
        case 73: try { try decoder.decodeSingularStringField(value: &_storage._instanceWeightColumn) }()
        case 74: try { try decoder.decodeSingularInt64Field(value: &_storage._trendSmoothingWindowSize) }()
        case 75: try { try decoder.decodeSingularDoubleField(value: &_storage._timeSeriesLengthFraction) }()
        case 76: try { try decoder.decodeSingularInt64Field(value: &_storage._minTimeSeriesLength) }()
        case 77: try { try decoder.decodeSingularInt64Field(value: &_storage._maxTimeSeriesLength) }()
        case 78: try { try decoder.decodeSingularStringField(value: &_storage._xgboostVersion) }()
        case 83: try { try decoder.decodeSingularInt64Field(value: &_storage._autoArimaMinOrder) }()
        case 84: try { try decoder.decodeSingularMessageField(value: &_storage._approxGlobalFeatureContrib) }()
        case 85: try { try decoder.decodeSingularMessageField(value: &_storage._fitIntercept) }()
        case 86: try { try decoder.decodeSingularInt64Field(value: &_storage._numPrincipalComponents) }()
        case 87: try { try decoder.decodeSingularDoubleField(value: &_storage._pcaExplainedVarianceRatio) }()
        case 88: try { try decoder.decodeSingularMessageField(value: &_storage._scaleFeatures) }()
        case 89: try { try decoder.decodeSingularEnumField(value: &_storage._pcaSolver) }()
        case 90: try { try decoder.decodeSingularMessageField(value: &_storage._autoClassWeights) }()
        case 91: try { try decoder.decodeSingularStringField(value: &_storage._activationFn) }()
        case 92: try { try decoder.decodeSingularStringField(value: &_storage._optimizer) }()
        case 93: try { try decoder.decodeSingularDoubleField(value: &_storage._budgetHours) }()
        case 94: try { try decoder.decodeSingularMessageField(value: &_storage._standardizeFeatures) }()
        case 95: try { try decoder.decodeSingularDoubleField(value: &_storage._l1RegActivation) }()
        case 96: try { try decoder.decodeSingularEnumField(value: &_storage._modelRegistry) }()
        case 97: try { try decoder.decodeRepeatedStringField(value: &_storage._vertexAiModelVersionAliases) }()
        case 104: try { try decoder.decodeRepeatedStringField(value: &_storage._dimensionIDColumns) }()
        case 105: try { try decoder.decodeSingularStringField(value: &_storage._contributionMetric) }()
        case 106: try { try decoder.decodeSingularStringField(value: &_storage._isTestColumn) }()
        case 107: try { try decoder.decodeSingularDoubleField(value: &_storage._minAprioriSupport) }()
        default: break
        }
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if _storage._maxIterations != 0 {
        try visitor.visitSingularInt64Field(value: _storage._maxIterations, fieldNumber: 1)
      }
      if _storage._lossType != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._lossType, fieldNumber: 2)
      }
      if _storage._learnRate.bitPattern != 0 {
        try visitor.visitSingularDoubleField(value: _storage._learnRate, fieldNumber: 3)
      }
      try { if let v = _storage._l1Regularization {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      } }()
      try { if let v = _storage._l2Regularization {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
      } }()
      try { if let v = _storage._minRelativeProgress {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      } }()
      try { if let v = _storage._warmStart {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      } }()
      try { if let v = _storage._earlyStop {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      } }()
      if !_storage._inputLabelColumns.isEmpty {
        try visitor.visitRepeatedStringField(value: _storage._inputLabelColumns, fieldNumber: 9)
      }
      if _storage._dataSplitMethod != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._dataSplitMethod, fieldNumber: 10)
      }
      if _storage._dataSplitEvalFraction.bitPattern != 0 {
        try visitor.visitSingularDoubleField(value: _storage._dataSplitEvalFraction, fieldNumber: 11)
      }
      if !_storage._dataSplitColumn.isEmpty {
        try visitor.visitSingularStringField(value: _storage._dataSplitColumn, fieldNumber: 12)
      }
      if _storage._learnRateStrategy != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._learnRateStrategy, fieldNumber: 13)
      }
      if _storage._initialLearnRate.bitPattern != 0 {
        try visitor.visitSingularDoubleField(value: _storage._initialLearnRate, fieldNumber: 16)
      }
      if !_storage._labelClassWeights.isEmpty {
        try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufDouble>.self, value: _storage._labelClassWeights, fieldNumber: 17)
      }
      if !_storage._userColumn.isEmpty {
        try visitor.visitSingularStringField(value: _storage._userColumn, fieldNumber: 18)
      }
      if !_storage._itemColumn.isEmpty {
        try visitor.visitSingularStringField(value: _storage._itemColumn, fieldNumber: 19)
      }
      if _storage._distanceType != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._distanceType, fieldNumber: 20)
      }
      if _storage._numClusters != 0 {
        try visitor.visitSingularInt64Field(value: _storage._numClusters, fieldNumber: 21)
      }
      if !_storage._modelUri.isEmpty {
        try visitor.visitSingularStringField(value: _storage._modelUri, fieldNumber: 22)
      }
      if _storage._optimizationStrategy != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._optimizationStrategy, fieldNumber: 23)
      }
      if !_storage._hiddenUnits.isEmpty {
        try visitor.visitPackedInt64Field(value: _storage._hiddenUnits, fieldNumber: 24)
      }
      if _storage._batchSize != 0 {
        try visitor.visitSingularInt64Field(value: _storage._batchSize, fieldNumber: 25)
      }
      try { if let v = _storage._dropout {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 26)
      } }()
      if _storage._maxTreeDepth != 0 {
        try visitor.visitSingularInt64Field(value: _storage._maxTreeDepth, fieldNumber: 27)
      }
      if _storage._subsample.bitPattern != 0 {
        try visitor.visitSingularDoubleField(value: _storage._subsample, fieldNumber: 28)
      }
      try { if let v = _storage._minSplitLoss {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 29)
      } }()
      if _storage._numFactors != 0 {
        try visitor.visitSingularInt64Field(value: _storage._numFactors, fieldNumber: 30)
      }
      if _storage._feedbackType != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._feedbackType, fieldNumber: 31)
      }
      try { if let v = _storage._walsAlpha {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 32)
      } }()
      if _storage._kmeansInitializationMethod != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._kmeansInitializationMethod, fieldNumber: 33)
      }
      if !_storage._kmeansInitializationColumn.isEmpty {
        try visitor.visitSingularStringField(value: _storage._kmeansInitializationColumn, fieldNumber: 34)
      }
      if !_storage._timeSeriesTimestampColumn.isEmpty {
        try visitor.visitSingularStringField(value: _storage._timeSeriesTimestampColumn, fieldNumber: 35)
      }
      if !_storage._timeSeriesDataColumn.isEmpty {
        try visitor.visitSingularStringField(value: _storage._timeSeriesDataColumn, fieldNumber: 36)
      }
      try { if let v = _storage._autoArima {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 37)
      } }()
      try { if let v = _storage._nonSeasonalOrder {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 38)
      } }()
      if _storage._dataFrequency != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._dataFrequency, fieldNumber: 39)
      }
      try { if let v = _storage._calculatePValues {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 40)
      } }()
      try { if let v = _storage._includeDrift {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 41)
      } }()
      if _storage._holidayRegion != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._holidayRegion, fieldNumber: 42)
      }
      if !_storage._timeSeriesIDColumn.isEmpty {
        try visitor.visitSingularStringField(value: _storage._timeSeriesIDColumn, fieldNumber: 43)
      }
      if _storage._horizon != 0 {
        try visitor.visitSingularInt64Field(value: _storage._horizon, fieldNumber: 44)
      }
      if _storage._autoArimaMaxOrder != 0 {
        try visitor.visitSingularInt64Field(value: _storage._autoArimaMaxOrder, fieldNumber: 46)
      }
      if _storage._numTrials != 0 {
        try visitor.visitSingularInt64Field(value: _storage._numTrials, fieldNumber: 47)
      }
      if _storage._maxParallelTrials != 0 {
        try visitor.visitSingularInt64Field(value: _storage._maxParallelTrials, fieldNumber: 48)
      }
      try { if let v = _storage._decomposeTimeSeries {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 50)
      } }()
      if !_storage._timeSeriesIDColumns.isEmpty {
        try visitor.visitRepeatedStringField(value: _storage._timeSeriesIDColumns, fieldNumber: 51)
      }
      try { if let v = _storage._cleanSpikesAndDips {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 52)
      } }()
      try { if let v = _storage._adjustStepChanges {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 53)
      } }()
      if !_storage._hparamTuningObjectives.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._hparamTuningObjectives, fieldNumber: 54)
      }
      try { if let v = _storage._enableGlobalExplain {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 55)
      } }()
      if _storage._sampledShapleyNumPaths != 0 {
        try visitor.visitSingularInt64Field(value: _storage._sampledShapleyNumPaths, fieldNumber: 56)
      }
      if _storage._integratedGradientsNumSteps != 0 {
        try visitor.visitSingularInt64Field(value: _storage._integratedGradientsNumSteps, fieldNumber: 57)
      }
      if _storage._categoryEncodingMethod != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._categoryEncodingMethod, fieldNumber: 58)
      }
      if _storage._boosterType != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._boosterType, fieldNumber: 60)
      }
      try { if let v = _storage._numParallelTree {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 61)
      } }()
      if _storage._dartNormalizeType != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._dartNormalizeType, fieldNumber: 62)
      }
      if _storage._treeMethod != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._treeMethod, fieldNumber: 63)
      }
      try { if let v = _storage._minTreeChildWeight {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 64)
      } }()
      try { if let v = _storage._colsampleBytree {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 65)
      } }()
      try { if let v = _storage._colsampleBylevel {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 66)
      } }()
      try { if let v = _storage._colsampleBynode {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 67)
      } }()
      if !_storage._tfVersion.isEmpty {
        try visitor.visitSingularStringField(value: _storage._tfVersion, fieldNumber: 70)
      }
      if !_storage._holidayRegions.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._holidayRegions, fieldNumber: 71)
      }
      if _storage._colorSpace != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._colorSpace, fieldNumber: 72)
      }
      if !_storage._instanceWeightColumn.isEmpty {
        try visitor.visitSingularStringField(value: _storage._instanceWeightColumn, fieldNumber: 73)
      }
      if _storage._trendSmoothingWindowSize != 0 {
        try visitor.visitSingularInt64Field(value: _storage._trendSmoothingWindowSize, fieldNumber: 74)
      }
      if _storage._timeSeriesLengthFraction.bitPattern != 0 {
        try visitor.visitSingularDoubleField(value: _storage._timeSeriesLengthFraction, fieldNumber: 75)
      }
      if _storage._minTimeSeriesLength != 0 {
        try visitor.visitSingularInt64Field(value: _storage._minTimeSeriesLength, fieldNumber: 76)
      }
      if _storage._maxTimeSeriesLength != 0 {
        try visitor.visitSingularInt64Field(value: _storage._maxTimeSeriesLength, fieldNumber: 77)
      }
      if !_storage._xgboostVersion.isEmpty {
        try visitor.visitSingularStringField(value: _storage._xgboostVersion, fieldNumber: 78)
      }
      if _storage._autoArimaMinOrder != 0 {
        try visitor.visitSingularInt64Field(value: _storage._autoArimaMinOrder, fieldNumber: 83)
      }
      try { if let v = _storage._approxGlobalFeatureContrib {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 84)
      } }()
      try { if let v = _storage._fitIntercept {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 85)
      } }()
      if _storage._numPrincipalComponents != 0 {
        try visitor.visitSingularInt64Field(value: _storage._numPrincipalComponents, fieldNumber: 86)
      }
      if _storage._pcaExplainedVarianceRatio.bitPattern != 0 {
        try visitor.visitSingularDoubleField(value: _storage._pcaExplainedVarianceRatio, fieldNumber: 87)
      }
      try { if let v = _storage._scaleFeatures {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 88)
      } }()
      if _storage._pcaSolver != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._pcaSolver, fieldNumber: 89)
      }
      try { if let v = _storage._autoClassWeights {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 90)
      } }()
      if !_storage._activationFn.isEmpty {
        try visitor.visitSingularStringField(value: _storage._activationFn, fieldNumber: 91)
      }
      if !_storage._optimizer.isEmpty {
        try visitor.visitSingularStringField(value: _storage._optimizer, fieldNumber: 92)
      }
      if _storage._budgetHours.bitPattern != 0 {
        try visitor.visitSingularDoubleField(value: _storage._budgetHours, fieldNumber: 93)
      }
      try { if let v = _storage._standardizeFeatures {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 94)
      } }()
      if _storage._l1RegActivation.bitPattern != 0 {
        try visitor.visitSingularDoubleField(value: _storage._l1RegActivation, fieldNumber: 95)
      }
      if _storage._modelRegistry != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._modelRegistry, fieldNumber: 96)
      }
      if !_storage._vertexAiModelVersionAliases.isEmpty {
        try visitor.visitRepeatedStringField(value: _storage._vertexAiModelVersionAliases, fieldNumber: 97)
      }
      if !_storage._dimensionIDColumns.isEmpty {
        try visitor.visitRepeatedStringField(value: _storage._dimensionIDColumns, fieldNumber: 104)
      }
      try { if let v = _storage._contributionMetric {
        try visitor.visitSingularStringField(value: v, fieldNumber: 105)
      } }()
      try { if let v = _storage._isTestColumn {
        try visitor.visitSingularStringField(value: v, fieldNumber: 106)
      } }()
      try { if let v = _storage._minAprioriSupport {
        try visitor.visitSingularDoubleField(value: v, fieldNumber: 107)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.TrainingRun.TrainingOptions, rhs: Google_Cloud_Bigquery_V2_Model.TrainingRun.TrainingOptions) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._maxIterations != rhs_storage._maxIterations {return false}
        if _storage._lossType != rhs_storage._lossType {return false}
        if _storage._learnRate != rhs_storage._learnRate {return false}
        if _storage._l1Regularization != rhs_storage._l1Regularization {return false}
        if _storage._l2Regularization != rhs_storage._l2Regularization {return false}
        if _storage._minRelativeProgress != rhs_storage._minRelativeProgress {return false}
        if _storage._warmStart != rhs_storage._warmStart {return false}
        if _storage._earlyStop != rhs_storage._earlyStop {return false}
        if _storage._inputLabelColumns != rhs_storage._inputLabelColumns {return false}
        if _storage._dataSplitMethod != rhs_storage._dataSplitMethod {return false}
        if _storage._dataSplitEvalFraction != rhs_storage._dataSplitEvalFraction {return false}
        if _storage._dataSplitColumn != rhs_storage._dataSplitColumn {return false}
        if _storage._learnRateStrategy != rhs_storage._learnRateStrategy {return false}
        if _storage._initialLearnRate != rhs_storage._initialLearnRate {return false}
        if _storage._labelClassWeights != rhs_storage._labelClassWeights {return false}
        if _storage._userColumn != rhs_storage._userColumn {return false}
        if _storage._itemColumn != rhs_storage._itemColumn {return false}
        if _storage._distanceType != rhs_storage._distanceType {return false}
        if _storage._numClusters != rhs_storage._numClusters {return false}
        if _storage._modelUri != rhs_storage._modelUri {return false}
        if _storage._optimizationStrategy != rhs_storage._optimizationStrategy {return false}
        if _storage._hiddenUnits != rhs_storage._hiddenUnits {return false}
        if _storage._batchSize != rhs_storage._batchSize {return false}
        if _storage._dropout != rhs_storage._dropout {return false}
        if _storage._maxTreeDepth != rhs_storage._maxTreeDepth {return false}
        if _storage._subsample != rhs_storage._subsample {return false}
        if _storage._minSplitLoss != rhs_storage._minSplitLoss {return false}
        if _storage._boosterType != rhs_storage._boosterType {return false}
        if _storage._numParallelTree != rhs_storage._numParallelTree {return false}
        if _storage._dartNormalizeType != rhs_storage._dartNormalizeType {return false}
        if _storage._treeMethod != rhs_storage._treeMethod {return false}
        if _storage._minTreeChildWeight != rhs_storage._minTreeChildWeight {return false}
        if _storage._colsampleBytree != rhs_storage._colsampleBytree {return false}
        if _storage._colsampleBylevel != rhs_storage._colsampleBylevel {return false}
        if _storage._colsampleBynode != rhs_storage._colsampleBynode {return false}
        if _storage._numFactors != rhs_storage._numFactors {return false}
        if _storage._feedbackType != rhs_storage._feedbackType {return false}
        if _storage._walsAlpha != rhs_storage._walsAlpha {return false}
        if _storage._kmeansInitializationMethod != rhs_storage._kmeansInitializationMethod {return false}
        if _storage._kmeansInitializationColumn != rhs_storage._kmeansInitializationColumn {return false}
        if _storage._timeSeriesTimestampColumn != rhs_storage._timeSeriesTimestampColumn {return false}
        if _storage._timeSeriesDataColumn != rhs_storage._timeSeriesDataColumn {return false}
        if _storage._autoArima != rhs_storage._autoArima {return false}
        if _storage._nonSeasonalOrder != rhs_storage._nonSeasonalOrder {return false}
        if _storage._dataFrequency != rhs_storage._dataFrequency {return false}
        if _storage._calculatePValues != rhs_storage._calculatePValues {return false}
        if _storage._includeDrift != rhs_storage._includeDrift {return false}
        if _storage._holidayRegion != rhs_storage._holidayRegion {return false}
        if _storage._holidayRegions != rhs_storage._holidayRegions {return false}
        if _storage._timeSeriesIDColumn != rhs_storage._timeSeriesIDColumn {return false}
        if _storage._timeSeriesIDColumns != rhs_storage._timeSeriesIDColumns {return false}
        if _storage._horizon != rhs_storage._horizon {return false}
        if _storage._autoArimaMaxOrder != rhs_storage._autoArimaMaxOrder {return false}
        if _storage._autoArimaMinOrder != rhs_storage._autoArimaMinOrder {return false}
        if _storage._numTrials != rhs_storage._numTrials {return false}
        if _storage._maxParallelTrials != rhs_storage._maxParallelTrials {return false}
        if _storage._hparamTuningObjectives != rhs_storage._hparamTuningObjectives {return false}
        if _storage._decomposeTimeSeries != rhs_storage._decomposeTimeSeries {return false}
        if _storage._cleanSpikesAndDips != rhs_storage._cleanSpikesAndDips {return false}
        if _storage._adjustStepChanges != rhs_storage._adjustStepChanges {return false}
        if _storage._enableGlobalExplain != rhs_storage._enableGlobalExplain {return false}
        if _storage._sampledShapleyNumPaths != rhs_storage._sampledShapleyNumPaths {return false}
        if _storage._integratedGradientsNumSteps != rhs_storage._integratedGradientsNumSteps {return false}
        if _storage._categoryEncodingMethod != rhs_storage._categoryEncodingMethod {return false}
        if _storage._tfVersion != rhs_storage._tfVersion {return false}
        if _storage._colorSpace != rhs_storage._colorSpace {return false}
        if _storage._instanceWeightColumn != rhs_storage._instanceWeightColumn {return false}
        if _storage._trendSmoothingWindowSize != rhs_storage._trendSmoothingWindowSize {return false}
        if _storage._timeSeriesLengthFraction != rhs_storage._timeSeriesLengthFraction {return false}
        if _storage._minTimeSeriesLength != rhs_storage._minTimeSeriesLength {return false}
        if _storage._maxTimeSeriesLength != rhs_storage._maxTimeSeriesLength {return false}
        if _storage._xgboostVersion != rhs_storage._xgboostVersion {return false}
        if _storage._approxGlobalFeatureContrib != rhs_storage._approxGlobalFeatureContrib {return false}
        if _storage._fitIntercept != rhs_storage._fitIntercept {return false}
        if _storage._numPrincipalComponents != rhs_storage._numPrincipalComponents {return false}
        if _storage._pcaExplainedVarianceRatio != rhs_storage._pcaExplainedVarianceRatio {return false}
        if _storage._scaleFeatures != rhs_storage._scaleFeatures {return false}
        if _storage._pcaSolver != rhs_storage._pcaSolver {return false}
        if _storage._autoClassWeights != rhs_storage._autoClassWeights {return false}
        if _storage._activationFn != rhs_storage._activationFn {return false}
        if _storage._optimizer != rhs_storage._optimizer {return false}
        if _storage._budgetHours != rhs_storage._budgetHours {return false}
        if _storage._standardizeFeatures != rhs_storage._standardizeFeatures {return false}
        if _storage._l1RegActivation != rhs_storage._l1RegActivation {return false}
        if _storage._modelRegistry != rhs_storage._modelRegistry {return false}
        if _storage._vertexAiModelVersionAliases != rhs_storage._vertexAiModelVersionAliases {return false}
        if _storage._dimensionIDColumns != rhs_storage._dimensionIDColumns {return false}
        if _storage._contributionMetric != rhs_storage._contributionMetric {return false}
        if _storage._isTestColumn != rhs_storage._isTestColumn {return false}
        if _storage._minAprioriSupport != rhs_storage._minAprioriSupport {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.TrainingRun.protoMessageName + ".IterationResult"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "index"),
    4: .standard(proto: "duration_ms"),
    5: .standard(proto: "training_loss"),
    6: .standard(proto: "eval_loss"),
    7: .standard(proto: "learn_rate"),
    8: .standard(proto: "cluster_infos"),
    9: .standard(proto: "arima_result"),
    10: .standard(proto: "principal_component_infos"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._index) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._durationMs) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._trainingLoss) }()
      case 6: try { try decoder.decodeSingularMessageField(value: &self._evalLoss) }()
      case 7: try { try decoder.decodeSingularDoubleField(value: &self.learnRate) }()
      case 8: try { try decoder.decodeRepeatedMessageField(value: &self.clusterInfos) }()
      case 9: try { try decoder.decodeSingularMessageField(value: &self._arimaResult) }()
      case 10: try { try decoder.decodeRepeatedMessageField(value: &self.principalComponentInfos) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._index {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._durationMs {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try { if let v = self._trainingLoss {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    try { if let v = self._evalLoss {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    } }()
    if self.learnRate.bitPattern != 0 {
      try visitor.visitSingularDoubleField(value: self.learnRate, fieldNumber: 7)
    }
    if !self.clusterInfos.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.clusterInfos, fieldNumber: 8)
    }
    try { if let v = self._arimaResult {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
    } }()
    if !self.principalComponentInfos.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.principalComponentInfos, fieldNumber: 10)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult, rhs: Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult) -> Bool {
    if lhs._index != rhs._index {return false}
    if lhs._durationMs != rhs._durationMs {return false}
    if lhs._trainingLoss != rhs._trainingLoss {return false}
    if lhs._evalLoss != rhs._evalLoss {return false}
    if lhs.learnRate != rhs.learnRate {return false}
    if lhs.clusterInfos != rhs.clusterInfos {return false}
    if lhs._arimaResult != rhs._arimaResult {return false}
    if lhs.principalComponentInfos != rhs.principalComponentInfos {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ClusterInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.protoMessageName + ".ClusterInfo"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "centroid_id"),
    2: .standard(proto: "cluster_radius"),
    3: .standard(proto: "cluster_size"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.centroidID) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._clusterRadius) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._clusterSize) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.centroidID != 0 {
      try visitor.visitSingularInt64Field(value: self.centroidID, fieldNumber: 1)
    }
    try { if let v = self._clusterRadius {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._clusterSize {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ClusterInfo, rhs: Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ClusterInfo) -> Bool {
    if lhs.centroidID != rhs.centroidID {return false}
    if lhs._clusterRadius != rhs._clusterRadius {return false}
    if lhs._clusterSize != rhs._clusterSize {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ArimaResult: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.protoMessageName + ".ArimaResult"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "arima_model_info"),
    2: .standard(proto: "seasonal_periods"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.arimaModelInfo) }()
      case 2: try { try decoder.decodeRepeatedEnumField(value: &self.seasonalPeriods) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.arimaModelInfo.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.arimaModelInfo, fieldNumber: 1)
    }
    if !self.seasonalPeriods.isEmpty {
      try visitor.visitPackedEnumField(value: self.seasonalPeriods, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ArimaResult, rhs: Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ArimaResult) -> Bool {
    if lhs.arimaModelInfo != rhs.arimaModelInfo {return false}
    if lhs.seasonalPeriods != rhs.seasonalPeriods {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ArimaResult.ArimaCoefficients: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ArimaResult.protoMessageName + ".ArimaCoefficients"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "auto_regressive_coefficients"),
    2: .standard(proto: "moving_average_coefficients"),
    3: .standard(proto: "intercept_coefficient"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedDoubleField(value: &self.autoRegressiveCoefficients) }()
      case 2: try { try decoder.decodeRepeatedDoubleField(value: &self.movingAverageCoefficients) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._interceptCoefficient) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.autoRegressiveCoefficients.isEmpty {
      try visitor.visitPackedDoubleField(value: self.autoRegressiveCoefficients, fieldNumber: 1)
    }
    if !self.movingAverageCoefficients.isEmpty {
      try visitor.visitPackedDoubleField(value: self.movingAverageCoefficients, fieldNumber: 2)
    }
    try { if let v = self._interceptCoefficient {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ArimaResult.ArimaCoefficients, rhs: Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ArimaResult.ArimaCoefficients) -> Bool {
    if lhs.autoRegressiveCoefficients != rhs.autoRegressiveCoefficients {return false}
    if lhs.movingAverageCoefficients != rhs.movingAverageCoefficients {return false}
    if lhs._interceptCoefficient != rhs._interceptCoefficient {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ArimaResult.ArimaModelInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ArimaResult.protoMessageName + ".ArimaModelInfo"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "non_seasonal_order"),
    2: .standard(proto: "arima_coefficients"),
    3: .standard(proto: "arima_fitting_metrics"),
    4: .standard(proto: "has_drift"),
    5: .standard(proto: "time_series_id"),
    10: .standard(proto: "time_series_ids"),
    6: .standard(proto: "seasonal_periods"),
    7: .standard(proto: "has_holiday_effect"),
    8: .standard(proto: "has_spikes_and_dips"),
    9: .standard(proto: "has_step_changes"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._nonSeasonalOrder) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._arimaCoefficients) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._arimaFittingMetrics) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._hasDrift_p) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self.timeSeriesID) }()
      case 6: try { try decoder.decodeRepeatedEnumField(value: &self.seasonalPeriods) }()
      case 7: try { try decoder.decodeSingularMessageField(value: &self._hasHolidayEffect_p) }()
      case 8: try { try decoder.decodeSingularMessageField(value: &self._hasSpikesAndDips_p) }()
      case 9: try { try decoder.decodeSingularMessageField(value: &self._hasStepChanges_p) }()
      case 10: try { try decoder.decodeRepeatedStringField(value: &self.timeSeriesIds) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._nonSeasonalOrder {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._arimaCoefficients {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._arimaFittingMetrics {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._hasDrift_p {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    if !self.timeSeriesID.isEmpty {
      try visitor.visitSingularStringField(value: self.timeSeriesID, fieldNumber: 5)
    }
    if !self.seasonalPeriods.isEmpty {
      try visitor.visitPackedEnumField(value: self.seasonalPeriods, fieldNumber: 6)
    }
    try { if let v = self._hasHolidayEffect_p {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
    } }()
    try { if let v = self._hasSpikesAndDips_p {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
    } }()
    try { if let v = self._hasStepChanges_p {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
    } }()
    if !self.timeSeriesIds.isEmpty {
      try visitor.visitRepeatedStringField(value: self.timeSeriesIds, fieldNumber: 10)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ArimaResult.ArimaModelInfo, rhs: Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.ArimaResult.ArimaModelInfo) -> Bool {
    if lhs._nonSeasonalOrder != rhs._nonSeasonalOrder {return false}
    if lhs._arimaCoefficients != rhs._arimaCoefficients {return false}
    if lhs._arimaFittingMetrics != rhs._arimaFittingMetrics {return false}
    if lhs._hasDrift_p != rhs._hasDrift_p {return false}
    if lhs.timeSeriesID != rhs.timeSeriesID {return false}
    if lhs.timeSeriesIds != rhs.timeSeriesIds {return false}
    if lhs.seasonalPeriods != rhs.seasonalPeriods {return false}
    if lhs._hasHolidayEffect_p != rhs._hasHolidayEffect_p {return false}
    if lhs._hasSpikesAndDips_p != rhs._hasSpikesAndDips_p {return false}
    if lhs._hasStepChanges_p != rhs._hasStepChanges_p {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.PrincipalComponentInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.protoMessageName + ".PrincipalComponentInfo"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "principal_component_id"),
    2: .standard(proto: "explained_variance"),
    3: .standard(proto: "explained_variance_ratio"),
    4: .standard(proto: "cumulative_explained_variance_ratio"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._principalComponentID) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._explainedVariance) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._explainedVarianceRatio) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._cumulativeExplainedVarianceRatio) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._principalComponentID {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._explainedVariance {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._explainedVarianceRatio {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._cumulativeExplainedVarianceRatio {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.PrincipalComponentInfo, rhs: Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult.PrincipalComponentInfo) -> Bool {
    if lhs._principalComponentID != rhs._principalComponentID {return false}
    if lhs._explainedVariance != rhs._explainedVariance {return false}
    if lhs._explainedVarianceRatio != rhs._explainedVarianceRatio {return false}
    if lhs._cumulativeExplainedVarianceRatio != rhs._cumulativeExplainedVarianceRatio {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".DoubleHparamSearchSpace"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "range"),
    2: .same(proto: "candidates"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace.DoubleRange?
        var hadOneofValue = false
        if let current = self.searchSpace {
          hadOneofValue = true
          if case .range(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.searchSpace = .range(v)
        }
      }()
      case 2: try {
        var v: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace.DoubleCandidates?
        var hadOneofValue = false
        if let current = self.searchSpace {
          hadOneofValue = true
          if case .candidates(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.searchSpace = .candidates(v)
        }
      }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.searchSpace {
    case .range?: try {
      guard case .range(let v)? = self.searchSpace else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .candidates?: try {
      guard case .candidates(let v)? = self.searchSpace else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace, rhs: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace) -> Bool {
    if lhs.searchSpace != rhs.searchSpace {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace.DoubleRange: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace.protoMessageName + ".DoubleRange"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "min"),
    2: .same(proto: "max"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._min) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._max) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._min {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._max {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace.DoubleRange, rhs: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace.DoubleRange) -> Bool {
    if lhs._min != rhs._min {return false}
    if lhs._max != rhs._max {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace.DoubleCandidates: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace.protoMessageName + ".DoubleCandidates"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "candidates"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.candidates) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.candidates.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.candidates, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace.DoubleCandidates, rhs: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace.DoubleCandidates) -> Bool {
    if lhs.candidates != rhs.candidates {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".IntHparamSearchSpace"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "range"),
    2: .same(proto: "candidates"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace.IntRange?
        var hadOneofValue = false
        if let current = self.searchSpace {
          hadOneofValue = true
          if case .range(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.searchSpace = .range(v)
        }
      }()
      case 2: try {
        var v: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace.IntCandidates?
        var hadOneofValue = false
        if let current = self.searchSpace {
          hadOneofValue = true
          if case .candidates(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.searchSpace = .candidates(v)
        }
      }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.searchSpace {
    case .range?: try {
      guard case .range(let v)? = self.searchSpace else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .candidates?: try {
      guard case .candidates(let v)? = self.searchSpace else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace, rhs: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace) -> Bool {
    if lhs.searchSpace != rhs.searchSpace {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace.IntRange: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace.protoMessageName + ".IntRange"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "min"),
    2: .same(proto: "max"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._min) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._max) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._min {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._max {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace.IntRange, rhs: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace.IntRange) -> Bool {
    if lhs._min != rhs._min {return false}
    if lhs._max != rhs._max {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace.IntCandidates: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace.protoMessageName + ".IntCandidates"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "candidates"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.candidates) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.candidates.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.candidates, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace.IntCandidates, rhs: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace.IntCandidates) -> Bool {
    if lhs.candidates != rhs.candidates {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.StringHparamSearchSpace: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".StringHparamSearchSpace"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "candidates"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedStringField(value: &self.candidates) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.candidates.isEmpty {
      try visitor.visitRepeatedStringField(value: self.candidates, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.StringHparamSearchSpace, rhs: Google_Cloud_Bigquery_V2_Model.StringHparamSearchSpace) -> Bool {
    if lhs.candidates != rhs.candidates {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.IntArrayHparamSearchSpace: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".IntArrayHparamSearchSpace"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "candidates"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.candidates) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.candidates.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.candidates, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.IntArrayHparamSearchSpace, rhs: Google_Cloud_Bigquery_V2_Model.IntArrayHparamSearchSpace) -> Bool {
    if lhs.candidates != rhs.candidates {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.IntArrayHparamSearchSpace.IntArray: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.IntArrayHparamSearchSpace.protoMessageName + ".IntArray"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "elements"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedInt64Field(value: &self.elements) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.elements.isEmpty {
      try visitor.visitPackedInt64Field(value: self.elements, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.IntArrayHparamSearchSpace.IntArray, rhs: Google_Cloud_Bigquery_V2_Model.IntArrayHparamSearchSpace.IntArray) -> Bool {
    if lhs.elements != rhs.elements {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.HparamSearchSpaces: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".HparamSearchSpaces"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    2: .standard(proto: "learn_rate"),
    3: .standard(proto: "l1_reg"),
    4: .standard(proto: "l2_reg"),
    26: .standard(proto: "num_clusters"),
    31: .standard(proto: "num_factors"),
    34: .standard(proto: "hidden_units"),
    37: .standard(proto: "batch_size"),
    38: .same(proto: "dropout"),
    41: .standard(proto: "max_tree_depth"),
    42: .same(proto: "subsample"),
    43: .standard(proto: "min_split_loss"),
    49: .standard(proto: "wals_alpha"),
    56: .standard(proto: "booster_type"),
    57: .standard(proto: "num_parallel_tree"),
    58: .standard(proto: "dart_normalize_type"),
    59: .standard(proto: "tree_method"),
    60: .standard(proto: "min_tree_child_weight"),
    61: .standard(proto: "colsample_bytree"),
    62: .standard(proto: "colsample_bylevel"),
    63: .standard(proto: "colsample_bynode"),
    67: .standard(proto: "activation_fn"),
    68: .same(proto: "optimizer"),
  ]

  fileprivate class _StorageClass {
    var _learnRate: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace? = nil
    var _l1Reg: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace? = nil
    var _l2Reg: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace? = nil
    var _numClusters: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace? = nil
    var _numFactors: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace? = nil
    var _hiddenUnits: Google_Cloud_Bigquery_V2_Model.IntArrayHparamSearchSpace? = nil
    var _batchSize: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace? = nil
    var _dropout: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace? = nil
    var _maxTreeDepth: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace? = nil
    var _subsample: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace? = nil
    var _minSplitLoss: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace? = nil
    var _walsAlpha: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace? = nil
    var _boosterType: Google_Cloud_Bigquery_V2_Model.StringHparamSearchSpace? = nil
    var _numParallelTree: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace? = nil
    var _dartNormalizeType: Google_Cloud_Bigquery_V2_Model.StringHparamSearchSpace? = nil
    var _treeMethod: Google_Cloud_Bigquery_V2_Model.StringHparamSearchSpace? = nil
    var _minTreeChildWeight: Google_Cloud_Bigquery_V2_Model.IntHparamSearchSpace? = nil
    var _colsampleBytree: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace? = nil
    var _colsampleBylevel: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace? = nil
    var _colsampleBynode: Google_Cloud_Bigquery_V2_Model.DoubleHparamSearchSpace? = nil
    var _activationFn: Google_Cloud_Bigquery_V2_Model.StringHparamSearchSpace? = nil
    var _optimizer: Google_Cloud_Bigquery_V2_Model.StringHparamSearchSpace? = nil

    #if swift(>=5.10)
      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()
    #else
      static let defaultInstance = _StorageClass()
    #endif

    private init() {}

    init(copying source: _StorageClass) {
      _learnRate = source._learnRate
      _l1Reg = source._l1Reg
      _l2Reg = source._l2Reg
      _numClusters = source._numClusters
      _numFactors = source._numFactors
      _hiddenUnits = source._hiddenUnits
      _batchSize = source._batchSize
      _dropout = source._dropout
      _maxTreeDepth = source._maxTreeDepth
      _subsample = source._subsample
      _minSplitLoss = source._minSplitLoss
      _walsAlpha = source._walsAlpha
      _boosterType = source._boosterType
      _numParallelTree = source._numParallelTree
      _dartNormalizeType = source._dartNormalizeType
      _treeMethod = source._treeMethod
      _minTreeChildWeight = source._minTreeChildWeight
      _colsampleBytree = source._colsampleBytree
      _colsampleBylevel = source._colsampleBylevel
      _colsampleBynode = source._colsampleBynode
      _activationFn = source._activationFn
      _optimizer = source._optimizer
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._learnRate) }()
        case 3: try { try decoder.decodeSingularMessageField(value: &_storage._l1Reg) }()
        case 4: try { try decoder.decodeSingularMessageField(value: &_storage._l2Reg) }()
        case 26: try { try decoder.decodeSingularMessageField(value: &_storage._numClusters) }()
        case 31: try { try decoder.decodeSingularMessageField(value: &_storage._numFactors) }()
        case 34: try { try decoder.decodeSingularMessageField(value: &_storage._hiddenUnits) }()
        case 37: try { try decoder.decodeSingularMessageField(value: &_storage._batchSize) }()
        case 38: try { try decoder.decodeSingularMessageField(value: &_storage._dropout) }()
        case 41: try { try decoder.decodeSingularMessageField(value: &_storage._maxTreeDepth) }()
        case 42: try { try decoder.decodeSingularMessageField(value: &_storage._subsample) }()
        case 43: try { try decoder.decodeSingularMessageField(value: &_storage._minSplitLoss) }()
        case 49: try { try decoder.decodeSingularMessageField(value: &_storage._walsAlpha) }()
        case 56: try { try decoder.decodeSingularMessageField(value: &_storage._boosterType) }()
        case 57: try { try decoder.decodeSingularMessageField(value: &_storage._numParallelTree) }()
        case 58: try { try decoder.decodeSingularMessageField(value: &_storage._dartNormalizeType) }()
        case 59: try { try decoder.decodeSingularMessageField(value: &_storage._treeMethod) }()
        case 60: try { try decoder.decodeSingularMessageField(value: &_storage._minTreeChildWeight) }()
        case 61: try { try decoder.decodeSingularMessageField(value: &_storage._colsampleBytree) }()
        case 62: try { try decoder.decodeSingularMessageField(value: &_storage._colsampleBylevel) }()
        case 63: try { try decoder.decodeSingularMessageField(value: &_storage._colsampleBynode) }()
        case 67: try { try decoder.decodeSingularMessageField(value: &_storage._activationFn) }()
        case 68: try { try decoder.decodeSingularMessageField(value: &_storage._optimizer) }()
        default: break
        }
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      try { if let v = _storage._learnRate {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      } }()
      try { if let v = _storage._l1Reg {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      } }()
      try { if let v = _storage._l2Reg {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      } }()
      try { if let v = _storage._numClusters {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 26)
      } }()
      try { if let v = _storage._numFactors {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 31)
      } }()
      try { if let v = _storage._hiddenUnits {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 34)
      } }()
      try { if let v = _storage._batchSize {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 37)
      } }()
      try { if let v = _storage._dropout {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 38)
      } }()
      try { if let v = _storage._maxTreeDepth {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 41)
      } }()
      try { if let v = _storage._subsample {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 42)
      } }()
      try { if let v = _storage._minSplitLoss {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 43)
      } }()
      try { if let v = _storage._walsAlpha {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 49)
      } }()
      try { if let v = _storage._boosterType {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 56)
      } }()
      try { if let v = _storage._numParallelTree {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 57)
      } }()
      try { if let v = _storage._dartNormalizeType {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 58)
      } }()
      try { if let v = _storage._treeMethod {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 59)
      } }()
      try { if let v = _storage._minTreeChildWeight {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 60)
      } }()
      try { if let v = _storage._colsampleBytree {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 61)
      } }()
      try { if let v = _storage._colsampleBylevel {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 62)
      } }()
      try { if let v = _storage._colsampleBynode {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 63)
      } }()
      try { if let v = _storage._activationFn {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 67)
      } }()
      try { if let v = _storage._optimizer {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 68)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.HparamSearchSpaces, rhs: Google_Cloud_Bigquery_V2_Model.HparamSearchSpaces) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._learnRate != rhs_storage._learnRate {return false}
        if _storage._l1Reg != rhs_storage._l1Reg {return false}
        if _storage._l2Reg != rhs_storage._l2Reg {return false}
        if _storage._numClusters != rhs_storage._numClusters {return false}
        if _storage._numFactors != rhs_storage._numFactors {return false}
        if _storage._hiddenUnits != rhs_storage._hiddenUnits {return false}
        if _storage._batchSize != rhs_storage._batchSize {return false}
        if _storage._dropout != rhs_storage._dropout {return false}
        if _storage._maxTreeDepth != rhs_storage._maxTreeDepth {return false}
        if _storage._subsample != rhs_storage._subsample {return false}
        if _storage._minSplitLoss != rhs_storage._minSplitLoss {return false}
        if _storage._walsAlpha != rhs_storage._walsAlpha {return false}
        if _storage._boosterType != rhs_storage._boosterType {return false}
        if _storage._numParallelTree != rhs_storage._numParallelTree {return false}
        if _storage._dartNormalizeType != rhs_storage._dartNormalizeType {return false}
        if _storage._treeMethod != rhs_storage._treeMethod {return false}
        if _storage._minTreeChildWeight != rhs_storage._minTreeChildWeight {return false}
        if _storage._colsampleBytree != rhs_storage._colsampleBytree {return false}
        if _storage._colsampleBylevel != rhs_storage._colsampleBylevel {return false}
        if _storage._colsampleBynode != rhs_storage._colsampleBynode {return false}
        if _storage._activationFn != rhs_storage._activationFn {return false}
        if _storage._optimizer != rhs_storage._optimizer {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.HparamTuningTrial: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_Model.protoMessageName + ".HparamTuningTrial"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "trial_id"),
    2: .standard(proto: "start_time_ms"),
    3: .standard(proto: "end_time_ms"),
    4: .same(proto: "hparams"),
    5: .standard(proto: "evaluation_metrics"),
    6: .same(proto: "status"),
    7: .standard(proto: "error_message"),
    8: .standard(proto: "training_loss"),
    9: .standard(proto: "eval_loss"),
    10: .standard(proto: "hparam_tuning_evaluation_metrics"),
  ]

  fileprivate class _StorageClass {
    var _trialID: Int64 = 0
    var _startTimeMs: Int64 = 0
    var _endTimeMs: Int64 = 0
    var _hparams: Google_Cloud_Bigquery_V2_Model.TrainingRun.TrainingOptions? = nil
    var _evaluationMetrics: Google_Cloud_Bigquery_V2_Model.EvaluationMetrics? = nil
    var _status: Google_Cloud_Bigquery_V2_Model.HparamTuningTrial.TrialStatus = .unspecified
    var _errorMessage: String = String()
    var _trainingLoss: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _evalLoss: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _hparamTuningEvaluationMetrics: Google_Cloud_Bigquery_V2_Model.EvaluationMetrics? = nil

    #if swift(>=5.10)
      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()
    #else
      static let defaultInstance = _StorageClass()
    #endif

    private init() {}

    init(copying source: _StorageClass) {
      _trialID = source._trialID
      _startTimeMs = source._startTimeMs
      _endTimeMs = source._endTimeMs
      _hparams = source._hparams
      _evaluationMetrics = source._evaluationMetrics
      _status = source._status
      _errorMessage = source._errorMessage
      _trainingLoss = source._trainingLoss
      _evalLoss = source._evalLoss
      _hparamTuningEvaluationMetrics = source._hparamTuningEvaluationMetrics
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularInt64Field(value: &_storage._trialID) }()
        case 2: try { try decoder.decodeSingularInt64Field(value: &_storage._startTimeMs) }()
        case 3: try { try decoder.decodeSingularInt64Field(value: &_storage._endTimeMs) }()
        case 4: try { try decoder.decodeSingularMessageField(value: &_storage._hparams) }()
        case 5: try { try decoder.decodeSingularMessageField(value: &_storage._evaluationMetrics) }()
        case 6: try { try decoder.decodeSingularEnumField(value: &_storage._status) }()
        case 7: try { try decoder.decodeSingularStringField(value: &_storage._errorMessage) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._trainingLoss) }()
        case 9: try { try decoder.decodeSingularMessageField(value: &_storage._evalLoss) }()
        case 10: try { try decoder.decodeSingularMessageField(value: &_storage._hparamTuningEvaluationMetrics) }()
        default: break
        }
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if _storage._trialID != 0 {
        try visitor.visitSingularInt64Field(value: _storage._trialID, fieldNumber: 1)
      }
      if _storage._startTimeMs != 0 {
        try visitor.visitSingularInt64Field(value: _storage._startTimeMs, fieldNumber: 2)
      }
      if _storage._endTimeMs != 0 {
        try visitor.visitSingularInt64Field(value: _storage._endTimeMs, fieldNumber: 3)
      }
      try { if let v = _storage._hparams {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      } }()
      try { if let v = _storage._evaluationMetrics {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
      } }()
      if _storage._status != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._status, fieldNumber: 6)
      }
      if !_storage._errorMessage.isEmpty {
        try visitor.visitSingularStringField(value: _storage._errorMessage, fieldNumber: 7)
      }
      try { if let v = _storage._trainingLoss {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      } }()
      try { if let v = _storage._evalLoss {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      } }()
      try { if let v = _storage._hparamTuningEvaluationMetrics {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Model.HparamTuningTrial, rhs: Google_Cloud_Bigquery_V2_Model.HparamTuningTrial) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._trialID != rhs_storage._trialID {return false}
        if _storage._startTimeMs != rhs_storage._startTimeMs {return false}
        if _storage._endTimeMs != rhs_storage._endTimeMs {return false}
        if _storage._hparams != rhs_storage._hparams {return false}
        if _storage._evaluationMetrics != rhs_storage._evaluationMetrics {return false}
        if _storage._status != rhs_storage._status {return false}
        if _storage._errorMessage != rhs_storage._errorMessage {return false}
        if _storage._trainingLoss != rhs_storage._trainingLoss {return false}
        if _storage._evalLoss != rhs_storage._evalLoss {return false}
        if _storage._hparamTuningEvaluationMetrics != rhs_storage._hparamTuningEvaluationMetrics {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Model.HparamTuningTrial.TrialStatus: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "TRIAL_STATUS_UNSPECIFIED"),
    1: .same(proto: "NOT_STARTED"),
    2: .same(proto: "RUNNING"),
    3: .same(proto: "SUCCEEDED"),
    4: .same(proto: "FAILED"),
    5: .same(proto: "INFEASIBLE"),
    6: .same(proto: "STOPPED_EARLY"),
  ]
}

extension Google_Cloud_Bigquery_V2_GetModelRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".GetModelRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "dataset_id"),
    3: .standard(proto: "model_id"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.datasetID) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.modelID) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.datasetID.isEmpty {
      try visitor.visitSingularStringField(value: self.datasetID, fieldNumber: 2)
    }
    if !self.modelID.isEmpty {
      try visitor.visitSingularStringField(value: self.modelID, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_GetModelRequest, rhs: Google_Cloud_Bigquery_V2_GetModelRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.datasetID != rhs.datasetID {return false}
    if lhs.modelID != rhs.modelID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_PatchModelRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".PatchModelRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "dataset_id"),
    3: .standard(proto: "model_id"),
    4: .same(proto: "model"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.datasetID) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.modelID) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._model) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.datasetID.isEmpty {
      try visitor.visitSingularStringField(value: self.datasetID, fieldNumber: 2)
    }
    if !self.modelID.isEmpty {
      try visitor.visitSingularStringField(value: self.modelID, fieldNumber: 3)
    }
    try { if let v = self._model {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_PatchModelRequest, rhs: Google_Cloud_Bigquery_V2_PatchModelRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.datasetID != rhs.datasetID {return false}
    if lhs.modelID != rhs.modelID {return false}
    if lhs._model != rhs._model {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_DeleteModelRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".DeleteModelRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "dataset_id"),
    3: .standard(proto: "model_id"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.datasetID) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.modelID) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.datasetID.isEmpty {
      try visitor.visitSingularStringField(value: self.datasetID, fieldNumber: 2)
    }
    if !self.modelID.isEmpty {
      try visitor.visitSingularStringField(value: self.modelID, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_DeleteModelRequest, rhs: Google_Cloud_Bigquery_V2_DeleteModelRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.datasetID != rhs.datasetID {return false}
    if lhs.modelID != rhs.modelID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_ListModelsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".ListModelsRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "dataset_id"),
    3: .standard(proto: "max_results"),
    4: .standard(proto: "page_token"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.datasetID) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._maxResults) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.pageToken) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.datasetID.isEmpty {
      try visitor.visitSingularStringField(value: self.datasetID, fieldNumber: 2)
    }
    try { if let v = self._maxResults {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    if !self.pageToken.isEmpty {
      try visitor.visitSingularStringField(value: self.pageToken, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_ListModelsRequest, rhs: Google_Cloud_Bigquery_V2_ListModelsRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.datasetID != rhs.datasetID {return false}
    if lhs._maxResults != rhs._maxResults {return false}
    if lhs.pageToken != rhs.pageToken {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_ListModelsResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".ListModelsResponse"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "models"),
    2: .standard(proto: "next_page_token"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.models) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.nextPageToken) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.models.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.models, fieldNumber: 1)
    }
    if !self.nextPageToken.isEmpty {
      try visitor.visitSingularStringField(value: self.nextPageToken, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_ListModelsResponse, rhs: Google_Cloud_Bigquery_V2_ListModelsResponse) -> Bool {
    if lhs.models != rhs.models {return false}
    if lhs.nextPageToken != rhs.nextPageToken {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
