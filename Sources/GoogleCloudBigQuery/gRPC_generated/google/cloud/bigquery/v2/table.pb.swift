// DO NOT EDIT.
// swift-format-ignore-file
// swiftlint:disable all
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/bigquery/v2/table.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Replication info of a table created using `AS REPLICA` DDL like:
/// `CREATE MATERIALIZED VIEW mv1 AS REPLICA OF src_mv`
package struct Google_Cloud_Bigquery_V2_TableReplicationInfo: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Source table reference that is replicated.
  package var sourceTable: Google_Cloud_Bigquery_V2_TableReference {
    get {return _sourceTable ?? Google_Cloud_Bigquery_V2_TableReference()}
    set {_sourceTable = newValue}
  }
  /// Returns true if `sourceTable` has been explicitly set.
  package var hasSourceTable: Bool {return self._sourceTable != nil}
  /// Clears the value of `sourceTable`. Subsequent reads from it will return its default value.
  package mutating func clearSourceTable() {self._sourceTable = nil}

  /// Optional. Specifies the interval at which the source table is polled for
  /// updates.
  /// It's Optional. If not specified, default replication interval would be
  /// applied.
  package var replicationIntervalMs: Int64 = 0

  /// Optional. Output only. If source is a materialized view, this field
  /// signifies the last refresh time of the source.
  package var replicatedSourceLastRefreshTime: Int64 = 0

  /// Optional. Output only. Replication status of configured replication.
  package var replicationStatus: Google_Cloud_Bigquery_V2_TableReplicationInfo.ReplicationStatus = .unspecified

  /// Optional. Output only. Replication error that will permanently stopped
  /// table replication.
  package var replicationError: Google_Cloud_Bigquery_V2_ErrorProto {
    get {return _replicationError ?? Google_Cloud_Bigquery_V2_ErrorProto()}
    set {_replicationError = newValue}
  }
  /// Returns true if `replicationError` has been explicitly set.
  package var hasReplicationError: Bool {return self._replicationError != nil}
  /// Clears the value of `replicationError`. Subsequent reads from it will return its default value.
  package mutating func clearReplicationError() {self._replicationError = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Replication status of the table created using `AS REPLICA` like:
  /// `CREATE MATERIALIZED VIEW mv1 AS REPLICA OF src_mv`
  package enum ReplicationStatus: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Default value.
    case unspecified // = 0

    /// Replication is Active with no errors.
    case active // = 1

    /// Source object is deleted.
    case sourceDeleted // = 2

    /// Source revoked replication permissions.
    case permissionDenied // = 3

    /// Source configuration doesnâ€™t allow replication.
    case unsupportedConfiguration // = 4
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .active
      case 2: self = .sourceDeleted
      case 3: self = .permissionDenied
      case 4: self = .unsupportedConfiguration
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .active: return 1
      case .sourceDeleted: return 2
      case .permissionDenied: return 3
      case .unsupportedConfiguration: return 4
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_TableReplicationInfo.ReplicationStatus] = [
      .unspecified,
      .active,
      .sourceDeleted,
      .permissionDenied,
      .unsupportedConfiguration,
    ]

  }

  package init() {}

  fileprivate var _sourceTable: Google_Cloud_Bigquery_V2_TableReference? = nil
  fileprivate var _replicationError: Google_Cloud_Bigquery_V2_ErrorProto? = nil
}

/// Describes the definition of a logical view.
package struct Google_Cloud_Bigquery_V2_ViewDefinition: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. A query that BigQuery executes when the view is referenced.
  package var query: String = String()

  /// Describes user-defined function resources used in the query.
  package var userDefinedFunctionResources: [Google_Cloud_Bigquery_V2_UserDefinedFunctionResource] = []

  /// Specifies whether to use BigQuery's legacy SQL for this view.
  /// The default value is true. If set to false, the view will use
  /// BigQuery's GoogleSQL:
  /// https://cloud.google.com/bigquery/sql-reference/
  ///
  /// Queries and views that reference this view must use the same flag value.
  /// A wrapper is used here because the default value is True.
  package var useLegacySql: SwiftProtobuf.Google_Protobuf_BoolValue {
    get {return _useLegacySql ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
    set {_useLegacySql = newValue}
  }
  /// Returns true if `useLegacySql` has been explicitly set.
  package var hasUseLegacySql: Bool {return self._useLegacySql != nil}
  /// Clears the value of `useLegacySql`. Subsequent reads from it will return its default value.
  package mutating func clearUseLegacySql() {self._useLegacySql = nil}

  /// True if the column names are explicitly specified. For example by using the
  /// 'CREATE VIEW v(c1, c2) AS ...' syntax.
  /// Can only be set for GoogleSQL views.
  package var useExplicitColumnNames: Bool = false

  /// Optional. Specifices the privacy policy for the view.
  package var privacyPolicy: Google_Cloud_Bigquery_V2_PrivacyPolicy {
    get {return _privacyPolicy ?? Google_Cloud_Bigquery_V2_PrivacyPolicy()}
    set {_privacyPolicy = newValue}
  }
  /// Returns true if `privacyPolicy` has been explicitly set.
  package var hasPrivacyPolicy: Bool {return self._privacyPolicy != nil}
  /// Clears the value of `privacyPolicy`. Subsequent reads from it will return its default value.
  package mutating func clearPrivacyPolicy() {self._privacyPolicy = nil}

  /// Optional. Foreign view representations.
  package var foreignDefinitions: [Google_Cloud_Bigquery_V2_ForeignViewDefinition] = []

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _useLegacySql: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
  fileprivate var _privacyPolicy: Google_Cloud_Bigquery_V2_PrivacyPolicy? = nil
}

/// A view can be represented in multiple ways. Each representation has its own
/// dialect. This message stores the metadata required for these representations.
package struct Google_Cloud_Bigquery_V2_ForeignViewDefinition: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The query that defines the view.
  package var query: String = String()

  /// Optional. Represents the dialect of the query.
  package var dialect: String = String()

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

/// Definition and configuration of a materialized view.
package struct Google_Cloud_Bigquery_V2_MaterializedViewDefinition: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. A query whose results are persisted.
  package var query: String = String()

  /// Output only. The time when this materialized view was last refreshed, in
  /// milliseconds since the epoch.
  package var lastRefreshTime: Int64 = 0

  /// Optional. Enable automatic refresh of the materialized view when the base
  /// table is updated. The default value is "true".
  package var enableRefresh: SwiftProtobuf.Google_Protobuf_BoolValue {
    get {return _enableRefresh ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
    set {_enableRefresh = newValue}
  }
  /// Returns true if `enableRefresh` has been explicitly set.
  package var hasEnableRefresh: Bool {return self._enableRefresh != nil}
  /// Clears the value of `enableRefresh`. Subsequent reads from it will return its default value.
  package mutating func clearEnableRefresh() {self._enableRefresh = nil}

  /// Optional. The maximum frequency at which this materialized view will be
  /// refreshed. The default value is "1800000" (30 minutes).
  package var refreshIntervalMs: SwiftProtobuf.Google_Protobuf_UInt64Value {
    get {return _refreshIntervalMs ?? SwiftProtobuf.Google_Protobuf_UInt64Value()}
    set {_refreshIntervalMs = newValue}
  }
  /// Returns true if `refreshIntervalMs` has been explicitly set.
  package var hasRefreshIntervalMs: Bool {return self._refreshIntervalMs != nil}
  /// Clears the value of `refreshIntervalMs`. Subsequent reads from it will return its default value.
  package mutating func clearRefreshIntervalMs() {self._refreshIntervalMs = nil}

  /// Optional. This option declares the intention to construct a materialized
  /// view that isn't refreshed incrementally.
  package var allowNonIncrementalDefinition: SwiftProtobuf.Google_Protobuf_BoolValue {
    get {return _allowNonIncrementalDefinition ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
    set {_allowNonIncrementalDefinition = newValue}
  }
  /// Returns true if `allowNonIncrementalDefinition` has been explicitly set.
  package var hasAllowNonIncrementalDefinition: Bool {return self._allowNonIncrementalDefinition != nil}
  /// Clears the value of `allowNonIncrementalDefinition`. Subsequent reads from it will return its default value.
  package mutating func clearAllowNonIncrementalDefinition() {self._allowNonIncrementalDefinition = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _enableRefresh: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
  fileprivate var _refreshIntervalMs: SwiftProtobuf.Google_Protobuf_UInt64Value? = nil
  fileprivate var _allowNonIncrementalDefinition: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
}

/// Status of a materialized view.
/// The last refresh timestamp status is omitted here, but is present in the
/// MaterializedViewDefinition message.
package struct Google_Cloud_Bigquery_V2_MaterializedViewStatus: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Refresh watermark of materialized view. The base tables' data
  /// were collected into the materialized view cache until this time.
  package var refreshWatermark: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _refreshWatermark ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_refreshWatermark = newValue}
  }
  /// Returns true if `refreshWatermark` has been explicitly set.
  package var hasRefreshWatermark: Bool {return self._refreshWatermark != nil}
  /// Clears the value of `refreshWatermark`. Subsequent reads from it will return its default value.
  package mutating func clearRefreshWatermark() {self._refreshWatermark = nil}

  /// Output only. Error result of the last automatic refresh. If present,
  /// indicates that the last automatic refresh was unsuccessful.
  package var lastRefreshStatus: Google_Cloud_Bigquery_V2_ErrorProto {
    get {return _lastRefreshStatus ?? Google_Cloud_Bigquery_V2_ErrorProto()}
    set {_lastRefreshStatus = newValue}
  }
  /// Returns true if `lastRefreshStatus` has been explicitly set.
  package var hasLastRefreshStatus: Bool {return self._lastRefreshStatus != nil}
  /// Clears the value of `lastRefreshStatus`. Subsequent reads from it will return its default value.
  package mutating func clearLastRefreshStatus() {self._lastRefreshStatus = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _refreshWatermark: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
  fileprivate var _lastRefreshStatus: Google_Cloud_Bigquery_V2_ErrorProto? = nil
}

/// Information about base table and snapshot time of the snapshot.
package struct Google_Cloud_Bigquery_V2_SnapshotDefinition: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Reference describing the ID of the table that was snapshot.
  package var baseTableReference: Google_Cloud_Bigquery_V2_TableReference {
    get {return _baseTableReference ?? Google_Cloud_Bigquery_V2_TableReference()}
    set {_baseTableReference = newValue}
  }
  /// Returns true if `baseTableReference` has been explicitly set.
  package var hasBaseTableReference: Bool {return self._baseTableReference != nil}
  /// Clears the value of `baseTableReference`. Subsequent reads from it will return its default value.
  package mutating func clearBaseTableReference() {self._baseTableReference = nil}

  /// Required. The time at which the base table was snapshot. This value is
  /// reported in the JSON response using RFC3339 format.
  package var snapshotTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _snapshotTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_snapshotTime = newValue}
  }
  /// Returns true if `snapshotTime` has been explicitly set.
  package var hasSnapshotTime: Bool {return self._snapshotTime != nil}
  /// Clears the value of `snapshotTime`. Subsequent reads from it will return its default value.
  package mutating func clearSnapshotTime() {self._snapshotTime = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _baseTableReference: Google_Cloud_Bigquery_V2_TableReference? = nil
  fileprivate var _snapshotTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
}

/// Information about base table and clone time of a table clone.
package struct Google_Cloud_Bigquery_V2_CloneDefinition: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Reference describing the ID of the table that was cloned.
  package var baseTableReference: Google_Cloud_Bigquery_V2_TableReference {
    get {return _baseTableReference ?? Google_Cloud_Bigquery_V2_TableReference()}
    set {_baseTableReference = newValue}
  }
  /// Returns true if `baseTableReference` has been explicitly set.
  package var hasBaseTableReference: Bool {return self._baseTableReference != nil}
  /// Clears the value of `baseTableReference`. Subsequent reads from it will return its default value.
  package mutating func clearBaseTableReference() {self._baseTableReference = nil}

  /// Required. The time at which the base table was cloned. This value is
  /// reported in the JSON response using RFC3339 format.
  package var cloneTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _cloneTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_cloneTime = newValue}
  }
  /// Returns true if `cloneTime` has been explicitly set.
  package var hasCloneTime: Bool {return self._cloneTime != nil}
  /// Clears the value of `cloneTime`. Subsequent reads from it will return its default value.
  package mutating func clearCloneTime() {self._cloneTime = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _baseTableReference: Google_Cloud_Bigquery_V2_TableReference? = nil
  fileprivate var _cloneTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
}

package struct Google_Cloud_Bigquery_V2_Streamingbuffer: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. A lower-bound estimate of the number of bytes currently in
  /// the streaming buffer.
  package var estimatedBytes: UInt64 = 0

  /// Output only. A lower-bound estimate of the number of rows currently in the
  /// streaming buffer.
  package var estimatedRows: UInt64 = 0

  /// Output only. Contains the timestamp of the oldest entry in the streaming
  /// buffer, in milliseconds since the epoch, if the streaming buffer is
  /// available.
  package var oldestEntryTime: UInt64 = 0

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

package struct Google_Cloud_Bigquery_V2_Table: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The type of resource ID.
  package var kind: String {
    get {return _storage._kind}
    set {_uniqueStorage()._kind = newValue}
  }

  /// Output only. A hash of this resource.
  package var etag: String {
    get {return _storage._etag}
    set {_uniqueStorage()._etag = newValue}
  }

  /// Output only. An opaque ID uniquely identifying the table.
  package var id: String {
    get {return _storage._id}
    set {_uniqueStorage()._id = newValue}
  }

  /// Output only. A URL that can be used to access this resource again.
  package var selfLink: String {
    get {return _storage._selfLink}
    set {_uniqueStorage()._selfLink = newValue}
  }

  /// Required. Reference describing the ID of this table.
  package var tableReference: Google_Cloud_Bigquery_V2_TableReference {
    get {return _storage._tableReference ?? Google_Cloud_Bigquery_V2_TableReference()}
    set {_uniqueStorage()._tableReference = newValue}
  }
  /// Returns true if `tableReference` has been explicitly set.
  package var hasTableReference: Bool {return _storage._tableReference != nil}
  /// Clears the value of `tableReference`. Subsequent reads from it will return its default value.
  package mutating func clearTableReference() {_uniqueStorage()._tableReference = nil}

  /// Optional. A descriptive name for this table.
  package var friendlyName: SwiftProtobuf.Google_Protobuf_StringValue {
    get {return _storage._friendlyName ?? SwiftProtobuf.Google_Protobuf_StringValue()}
    set {_uniqueStorage()._friendlyName = newValue}
  }
  /// Returns true if `friendlyName` has been explicitly set.
  package var hasFriendlyName: Bool {return _storage._friendlyName != nil}
  /// Clears the value of `friendlyName`. Subsequent reads from it will return its default value.
  package mutating func clearFriendlyName() {_uniqueStorage()._friendlyName = nil}

  /// Optional. A user-friendly description of this table.
  package var description_p: SwiftProtobuf.Google_Protobuf_StringValue {
    get {return _storage._description_p ?? SwiftProtobuf.Google_Protobuf_StringValue()}
    set {_uniqueStorage()._description_p = newValue}
  }
  /// Returns true if `description_p` has been explicitly set.
  package var hasDescription_p: Bool {return _storage._description_p != nil}
  /// Clears the value of `description_p`. Subsequent reads from it will return its default value.
  package mutating func clearDescription_p() {_uniqueStorage()._description_p = nil}

  /// The labels associated with this table. You can use these to organize and
  /// group your tables. Label keys and values can be no longer than 63
  /// characters, can only contain lowercase letters, numeric characters,
  /// underscores and dashes. International characters are allowed. Label values
  /// are optional. Label keys must start with a letter and each label in the
  /// list must have a different key.
  package var labels: Dictionary<String,String> {
    get {return _storage._labels}
    set {_uniqueStorage()._labels = newValue}
  }

  /// Optional. Describes the schema of this table.
  package var schema: Google_Cloud_Bigquery_V2_TableSchema {
    get {return _storage._schema ?? Google_Cloud_Bigquery_V2_TableSchema()}
    set {_uniqueStorage()._schema = newValue}
  }
  /// Returns true if `schema` has been explicitly set.
  package var hasSchema: Bool {return _storage._schema != nil}
  /// Clears the value of `schema`. Subsequent reads from it will return its default value.
  package mutating func clearSchema() {_uniqueStorage()._schema = nil}

  /// If specified, configures time-based partitioning for this table.
  package var timePartitioning: Google_Cloud_Bigquery_V2_TimePartitioning {
    get {return _storage._timePartitioning ?? Google_Cloud_Bigquery_V2_TimePartitioning()}
    set {_uniqueStorage()._timePartitioning = newValue}
  }
  /// Returns true if `timePartitioning` has been explicitly set.
  package var hasTimePartitioning: Bool {return _storage._timePartitioning != nil}
  /// Clears the value of `timePartitioning`. Subsequent reads from it will return its default value.
  package mutating func clearTimePartitioning() {_uniqueStorage()._timePartitioning = nil}

  /// If specified, configures range partitioning for this table.
  package var rangePartitioning: Google_Cloud_Bigquery_V2_RangePartitioning {
    get {return _storage._rangePartitioning ?? Google_Cloud_Bigquery_V2_RangePartitioning()}
    set {_uniqueStorage()._rangePartitioning = newValue}
  }
  /// Returns true if `rangePartitioning` has been explicitly set.
  package var hasRangePartitioning: Bool {return _storage._rangePartitioning != nil}
  /// Clears the value of `rangePartitioning`. Subsequent reads from it will return its default value.
  package mutating func clearRangePartitioning() {_uniqueStorage()._rangePartitioning = nil}

  /// Clustering specification for the table. Must be specified with time-based
  /// partitioning, data in the table will be first partitioned and subsequently
  /// clustered.
  package var clustering: Google_Cloud_Bigquery_V2_Clustering {
    get {return _storage._clustering ?? Google_Cloud_Bigquery_V2_Clustering()}
    set {_uniqueStorage()._clustering = newValue}
  }
  /// Returns true if `clustering` has been explicitly set.
  package var hasClustering: Bool {return _storage._clustering != nil}
  /// Clears the value of `clustering`. Subsequent reads from it will return its default value.
  package mutating func clearClustering() {_uniqueStorage()._clustering = nil}

  /// Optional. If set to true, queries over this table require
  /// a partition filter that can be used for partition elimination to be
  /// specified.
  package var requirePartitionFilter: SwiftProtobuf.Google_Protobuf_BoolValue {
    get {return _storage._requirePartitionFilter ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
    set {_uniqueStorage()._requirePartitionFilter = newValue}
  }
  /// Returns true if `requirePartitionFilter` has been explicitly set.
  package var hasRequirePartitionFilter: Bool {return _storage._requirePartitionFilter != nil}
  /// Clears the value of `requirePartitionFilter`. Subsequent reads from it will return its default value.
  package mutating func clearRequirePartitionFilter() {_uniqueStorage()._requirePartitionFilter = nil}

  /// Optional. The partition information for all table formats, including
  /// managed partitioned tables, hive partitioned tables, iceberg partitioned,
  /// and metastore partitioned tables. This field is only populated for
  /// metastore partitioned tables. For other table formats, this is an output
  /// only field.
  package var partitionDefinition: Google_Cloud_Bigquery_V2_PartitioningDefinition {
    get {return _storage._partitionDefinition ?? Google_Cloud_Bigquery_V2_PartitioningDefinition()}
    set {_uniqueStorage()._partitionDefinition = newValue}
  }
  /// Returns true if `partitionDefinition` has been explicitly set.
  package var hasPartitionDefinition: Bool {return _storage._partitionDefinition != nil}
  /// Clears the value of `partitionDefinition`. Subsequent reads from it will return its default value.
  package mutating func clearPartitionDefinition() {_uniqueStorage()._partitionDefinition = nil}

  /// Output only. The size of this table in logical bytes, excluding any data in
  /// the streaming buffer.
  package var numBytes: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._numBytes ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._numBytes = newValue}
  }
  /// Returns true if `numBytes` has been explicitly set.
  package var hasNumBytes: Bool {return _storage._numBytes != nil}
  /// Clears the value of `numBytes`. Subsequent reads from it will return its default value.
  package mutating func clearNumBytes() {_uniqueStorage()._numBytes = nil}

  /// Output only. The physical size of this table in bytes. This includes
  /// storage used for time travel.
  package var numPhysicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._numPhysicalBytes ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._numPhysicalBytes = newValue}
  }
  /// Returns true if `numPhysicalBytes` has been explicitly set.
  package var hasNumPhysicalBytes: Bool {return _storage._numPhysicalBytes != nil}
  /// Clears the value of `numPhysicalBytes`. Subsequent reads from it will return its default value.
  package mutating func clearNumPhysicalBytes() {_uniqueStorage()._numPhysicalBytes = nil}

  /// Output only. The number of logical bytes in the table that are considered
  /// "long-term storage".
  package var numLongTermBytes: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._numLongTermBytes ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._numLongTermBytes = newValue}
  }
  /// Returns true if `numLongTermBytes` has been explicitly set.
  package var hasNumLongTermBytes: Bool {return _storage._numLongTermBytes != nil}
  /// Clears the value of `numLongTermBytes`. Subsequent reads from it will return its default value.
  package mutating func clearNumLongTermBytes() {_uniqueStorage()._numLongTermBytes = nil}

  /// Output only. The number of rows of data in this table, excluding any data
  /// in the streaming buffer.
  package var numRows: SwiftProtobuf.Google_Protobuf_UInt64Value {
    get {return _storage._numRows ?? SwiftProtobuf.Google_Protobuf_UInt64Value()}
    set {_uniqueStorage()._numRows = newValue}
  }
  /// Returns true if `numRows` has been explicitly set.
  package var hasNumRows: Bool {return _storage._numRows != nil}
  /// Clears the value of `numRows`. Subsequent reads from it will return its default value.
  package mutating func clearNumRows() {_uniqueStorage()._numRows = nil}

  /// Output only. The time when this table was created, in milliseconds since
  /// the epoch.
  package var creationTime: Int64 {
    get {return _storage._creationTime}
    set {_uniqueStorage()._creationTime = newValue}
  }

  /// Optional. The time when this table expires, in milliseconds since the
  /// epoch. If not present, the table will persist indefinitely. Expired tables
  /// will be deleted and their storage reclaimed.  The defaultTableExpirationMs
  /// property of the encapsulating dataset can be used to set a default
  /// expirationTime on newly created tables.
  package var expirationTime: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._expirationTime ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._expirationTime = newValue}
  }
  /// Returns true if `expirationTime` has been explicitly set.
  package var hasExpirationTime: Bool {return _storage._expirationTime != nil}
  /// Clears the value of `expirationTime`. Subsequent reads from it will return its default value.
  package mutating func clearExpirationTime() {_uniqueStorage()._expirationTime = nil}

  /// Output only. The time when this table was last modified, in milliseconds
  /// since the epoch.
  package var lastModifiedTime: UInt64 {
    get {return _storage._lastModifiedTime}
    set {_uniqueStorage()._lastModifiedTime = newValue}
  }

  /// Output only. Describes the table type. The following values are supported:
  ///
  /// * `TABLE`: A normal BigQuery table.
  /// * `VIEW`: A virtual table defined by a SQL query.
  /// * `EXTERNAL`: A table that references data stored in an external storage
  ///   system, such as Google Cloud Storage.
  /// * `MATERIALIZED_VIEW`: A precomputed view defined by a SQL query.
  /// * `SNAPSHOT`: An immutable BigQuery table that preserves the contents of a
  ///   base table at a particular time. See additional information on
  ///   [table
  ///   snapshots](https://cloud.google.com/bigquery/docs/table-snapshots-intro).
  ///
  /// The default value is `TABLE`.
  package var type: String {
    get {return _storage._type}
    set {_uniqueStorage()._type = newValue}
  }

  /// Optional. The view definition.
  package var view: Google_Cloud_Bigquery_V2_ViewDefinition {
    get {return _storage._view ?? Google_Cloud_Bigquery_V2_ViewDefinition()}
    set {_uniqueStorage()._view = newValue}
  }
  /// Returns true if `view` has been explicitly set.
  package var hasView: Bool {return _storage._view != nil}
  /// Clears the value of `view`. Subsequent reads from it will return its default value.
  package mutating func clearView() {_uniqueStorage()._view = nil}

  /// Optional. The materialized view definition.
  package var materializedView: Google_Cloud_Bigquery_V2_MaterializedViewDefinition {
    get {return _storage._materializedView ?? Google_Cloud_Bigquery_V2_MaterializedViewDefinition()}
    set {_uniqueStorage()._materializedView = newValue}
  }
  /// Returns true if `materializedView` has been explicitly set.
  package var hasMaterializedView: Bool {return _storage._materializedView != nil}
  /// Clears the value of `materializedView`. Subsequent reads from it will return its default value.
  package mutating func clearMaterializedView() {_uniqueStorage()._materializedView = nil}

  /// Output only. The materialized view status.
  package var materializedViewStatus: Google_Cloud_Bigquery_V2_MaterializedViewStatus {
    get {return _storage._materializedViewStatus ?? Google_Cloud_Bigquery_V2_MaterializedViewStatus()}
    set {_uniqueStorage()._materializedViewStatus = newValue}
  }
  /// Returns true if `materializedViewStatus` has been explicitly set.
  package var hasMaterializedViewStatus: Bool {return _storage._materializedViewStatus != nil}
  /// Clears the value of `materializedViewStatus`. Subsequent reads from it will return its default value.
  package mutating func clearMaterializedViewStatus() {_uniqueStorage()._materializedViewStatus = nil}

  /// Optional. Describes the data format, location, and other properties of
  /// a table stored outside of BigQuery. By defining these properties, the data
  /// source can then be queried as if it were a standard BigQuery table.
  package var externalDataConfiguration: Google_Cloud_Bigquery_V2_ExternalDataConfiguration {
    get {return _storage._externalDataConfiguration ?? Google_Cloud_Bigquery_V2_ExternalDataConfiguration()}
    set {_uniqueStorage()._externalDataConfiguration = newValue}
  }
  /// Returns true if `externalDataConfiguration` has been explicitly set.
  package var hasExternalDataConfiguration: Bool {return _storage._externalDataConfiguration != nil}
  /// Clears the value of `externalDataConfiguration`. Subsequent reads from it will return its default value.
  package mutating func clearExternalDataConfiguration() {_uniqueStorage()._externalDataConfiguration = nil}

  /// Optional. Specifies the configuration of a BigLake managed table.
  package var biglakeConfiguration: Google_Cloud_Bigquery_V2_BigLakeConfiguration {
    get {return _storage._biglakeConfiguration ?? Google_Cloud_Bigquery_V2_BigLakeConfiguration()}
    set {_uniqueStorage()._biglakeConfiguration = newValue}
  }
  /// Returns true if `biglakeConfiguration` has been explicitly set.
  package var hasBiglakeConfiguration: Bool {return _storage._biglakeConfiguration != nil}
  /// Clears the value of `biglakeConfiguration`. Subsequent reads from it will return its default value.
  package mutating func clearBiglakeConfiguration() {_uniqueStorage()._biglakeConfiguration = nil}

  /// Output only. The geographic location where the table resides. This value
  /// is inherited from the dataset.
  package var location: String {
    get {return _storage._location}
    set {_uniqueStorage()._location = newValue}
  }

  /// Output only. Contains information regarding this table's streaming buffer,
  /// if one is present. This field will be absent if the table is not being
  /// streamed to or if there is no data in the streaming buffer.
  package var streamingBuffer: Google_Cloud_Bigquery_V2_Streamingbuffer {
    get {return _storage._streamingBuffer ?? Google_Cloud_Bigquery_V2_Streamingbuffer()}
    set {_uniqueStorage()._streamingBuffer = newValue}
  }
  /// Returns true if `streamingBuffer` has been explicitly set.
  package var hasStreamingBuffer: Bool {return _storage._streamingBuffer != nil}
  /// Clears the value of `streamingBuffer`. Subsequent reads from it will return its default value.
  package mutating func clearStreamingBuffer() {_uniqueStorage()._streamingBuffer = nil}

  /// Custom encryption configuration (e.g., Cloud KMS keys).
  package var encryptionConfiguration: Google_Cloud_Bigquery_V2_EncryptionConfiguration {
    get {return _storage._encryptionConfiguration ?? Google_Cloud_Bigquery_V2_EncryptionConfiguration()}
    set {_uniqueStorage()._encryptionConfiguration = newValue}
  }
  /// Returns true if `encryptionConfiguration` has been explicitly set.
  package var hasEncryptionConfiguration: Bool {return _storage._encryptionConfiguration != nil}
  /// Clears the value of `encryptionConfiguration`. Subsequent reads from it will return its default value.
  package mutating func clearEncryptionConfiguration() {_uniqueStorage()._encryptionConfiguration = nil}

  /// Output only. Contains information about the snapshot. This value is set via
  /// snapshot creation.
  package var snapshotDefinition: Google_Cloud_Bigquery_V2_SnapshotDefinition {
    get {return _storage._snapshotDefinition ?? Google_Cloud_Bigquery_V2_SnapshotDefinition()}
    set {_uniqueStorage()._snapshotDefinition = newValue}
  }
  /// Returns true if `snapshotDefinition` has been explicitly set.
  package var hasSnapshotDefinition: Bool {return _storage._snapshotDefinition != nil}
  /// Clears the value of `snapshotDefinition`. Subsequent reads from it will return its default value.
  package mutating func clearSnapshotDefinition() {_uniqueStorage()._snapshotDefinition = nil}

  /// Optional. Defines the default collation specification of new STRING fields
  /// in the table. During table creation or update, if a STRING field is added
  /// to this table without explicit collation specified, then the table inherits
  /// the table default collation. A change to this field affects only fields
  /// added afterwards, and does not alter the existing fields.
  /// The following values are supported:
  ///
  /// * 'und:ci': undetermined locale, case insensitive.
  /// * '': empty string. Default to case-sensitive behavior.
  package var defaultCollation: SwiftProtobuf.Google_Protobuf_StringValue {
    get {return _storage._defaultCollation ?? SwiftProtobuf.Google_Protobuf_StringValue()}
    set {_uniqueStorage()._defaultCollation = newValue}
  }
  /// Returns true if `defaultCollation` has been explicitly set.
  package var hasDefaultCollation: Bool {return _storage._defaultCollation != nil}
  /// Clears the value of `defaultCollation`. Subsequent reads from it will return its default value.
  package mutating func clearDefaultCollation() {_uniqueStorage()._defaultCollation = nil}

  /// Optional. Defines the default rounding mode specification of new decimal
  /// fields (NUMERIC OR BIGNUMERIC) in the table. During table creation or
  /// update, if a decimal field is added to this table without an explicit
  /// rounding mode specified, then the field inherits the table default
  /// rounding mode. Changing this field doesn't affect existing fields.
  package var defaultRoundingMode: Google_Cloud_Bigquery_V2_TableFieldSchema.RoundingMode {
    get {return _storage._defaultRoundingMode}
    set {_uniqueStorage()._defaultRoundingMode = newValue}
  }

  /// Output only. Contains information about the clone. This value is set via
  /// the clone operation.
  package var cloneDefinition: Google_Cloud_Bigquery_V2_CloneDefinition {
    get {return _storage._cloneDefinition ?? Google_Cloud_Bigquery_V2_CloneDefinition()}
    set {_uniqueStorage()._cloneDefinition = newValue}
  }
  /// Returns true if `cloneDefinition` has been explicitly set.
  package var hasCloneDefinition: Bool {return _storage._cloneDefinition != nil}
  /// Clears the value of `cloneDefinition`. Subsequent reads from it will return its default value.
  package mutating func clearCloneDefinition() {_uniqueStorage()._cloneDefinition = nil}

  /// Output only. Number of physical bytes used by time travel storage (deleted
  /// or changed data). This data is not kept in real time, and might be delayed
  /// by a few seconds to a few minutes.
  package var numTimeTravelPhysicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._numTimeTravelPhysicalBytes ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._numTimeTravelPhysicalBytes = newValue}
  }
  /// Returns true if `numTimeTravelPhysicalBytes` has been explicitly set.
  package var hasNumTimeTravelPhysicalBytes: Bool {return _storage._numTimeTravelPhysicalBytes != nil}
  /// Clears the value of `numTimeTravelPhysicalBytes`. Subsequent reads from it will return its default value.
  package mutating func clearNumTimeTravelPhysicalBytes() {_uniqueStorage()._numTimeTravelPhysicalBytes = nil}

  /// Output only. Total number of logical bytes in the table or materialized
  /// view.
  package var numTotalLogicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._numTotalLogicalBytes ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._numTotalLogicalBytes = newValue}
  }
  /// Returns true if `numTotalLogicalBytes` has been explicitly set.
  package var hasNumTotalLogicalBytes: Bool {return _storage._numTotalLogicalBytes != nil}
  /// Clears the value of `numTotalLogicalBytes`. Subsequent reads from it will return its default value.
  package mutating func clearNumTotalLogicalBytes() {_uniqueStorage()._numTotalLogicalBytes = nil}

  /// Output only. Number of logical bytes that are less than 90 days old.
  package var numActiveLogicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._numActiveLogicalBytes ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._numActiveLogicalBytes = newValue}
  }
  /// Returns true if `numActiveLogicalBytes` has been explicitly set.
  package var hasNumActiveLogicalBytes: Bool {return _storage._numActiveLogicalBytes != nil}
  /// Clears the value of `numActiveLogicalBytes`. Subsequent reads from it will return its default value.
  package mutating func clearNumActiveLogicalBytes() {_uniqueStorage()._numActiveLogicalBytes = nil}

  /// Output only. Number of logical bytes that are more than 90 days old.
  package var numLongTermLogicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._numLongTermLogicalBytes ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._numLongTermLogicalBytes = newValue}
  }
  /// Returns true if `numLongTermLogicalBytes` has been explicitly set.
  package var hasNumLongTermLogicalBytes: Bool {return _storage._numLongTermLogicalBytes != nil}
  /// Clears the value of `numLongTermLogicalBytes`. Subsequent reads from it will return its default value.
  package mutating func clearNumLongTermLogicalBytes() {_uniqueStorage()._numLongTermLogicalBytes = nil}

  /// Output only. Number of physical bytes used by current live data storage.
  /// This data is not kept in real time, and might be delayed by a few seconds
  /// to a few minutes.
  package var numCurrentPhysicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._numCurrentPhysicalBytes ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._numCurrentPhysicalBytes = newValue}
  }
  /// Returns true if `numCurrentPhysicalBytes` has been explicitly set.
  package var hasNumCurrentPhysicalBytes: Bool {return _storage._numCurrentPhysicalBytes != nil}
  /// Clears the value of `numCurrentPhysicalBytes`. Subsequent reads from it will return its default value.
  package mutating func clearNumCurrentPhysicalBytes() {_uniqueStorage()._numCurrentPhysicalBytes = nil}

  /// Output only. The physical size of this table in bytes. This also includes
  /// storage used for time travel. This data is not kept in real time, and might
  /// be delayed by a few seconds to a few minutes.
  package var numTotalPhysicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._numTotalPhysicalBytes ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._numTotalPhysicalBytes = newValue}
  }
  /// Returns true if `numTotalPhysicalBytes` has been explicitly set.
  package var hasNumTotalPhysicalBytes: Bool {return _storage._numTotalPhysicalBytes != nil}
  /// Clears the value of `numTotalPhysicalBytes`. Subsequent reads from it will return its default value.
  package mutating func clearNumTotalPhysicalBytes() {_uniqueStorage()._numTotalPhysicalBytes = nil}

  /// Output only. Number of physical bytes less than 90 days old. This data is
  /// not kept in real time, and might be delayed by a few seconds to a few
  /// minutes.
  package var numActivePhysicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._numActivePhysicalBytes ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._numActivePhysicalBytes = newValue}
  }
  /// Returns true if `numActivePhysicalBytes` has been explicitly set.
  package var hasNumActivePhysicalBytes: Bool {return _storage._numActivePhysicalBytes != nil}
  /// Clears the value of `numActivePhysicalBytes`. Subsequent reads from it will return its default value.
  package mutating func clearNumActivePhysicalBytes() {_uniqueStorage()._numActivePhysicalBytes = nil}

  /// Output only. Number of physical bytes more than 90 days old.
  /// This data is not kept in real time, and might be delayed by a few seconds
  /// to a few minutes.
  package var numLongTermPhysicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._numLongTermPhysicalBytes ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._numLongTermPhysicalBytes = newValue}
  }
  /// Returns true if `numLongTermPhysicalBytes` has been explicitly set.
  package var hasNumLongTermPhysicalBytes: Bool {return _storage._numLongTermPhysicalBytes != nil}
  /// Clears the value of `numLongTermPhysicalBytes`. Subsequent reads from it will return its default value.
  package mutating func clearNumLongTermPhysicalBytes() {_uniqueStorage()._numLongTermPhysicalBytes = nil}

  /// Output only. The number of partitions present in the table or materialized
  /// view. This data is not kept in real time, and might be delayed by a few
  /// seconds to a few minutes.
  package var numPartitions: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._numPartitions ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._numPartitions = newValue}
  }
  /// Returns true if `numPartitions` has been explicitly set.
  package var hasNumPartitions: Bool {return _storage._numPartitions != nil}
  /// Clears the value of `numPartitions`. Subsequent reads from it will return its default value.
  package mutating func clearNumPartitions() {_uniqueStorage()._numPartitions = nil}

  /// Optional. The maximum staleness of data that could be returned when the
  /// table (or stale MV) is queried. Staleness encoded as a string encoding
  /// of sql IntervalValue type.
  package var maxStaleness: String {
    get {return _storage._maxStaleness}
    set {_uniqueStorage()._maxStaleness = newValue}
  }

  /// Optional. Output only. Restriction config for table. If set, restrict
  /// certain accesses on the table based on the config. See [Data
  /// egress](https://cloud.google.com/bigquery/docs/analytics-hub-introduction#data_egress)
  /// for more details.
  package var restrictions: Google_Cloud_Bigquery_V2_RestrictionConfig {
    get {return _storage._restrictions ?? Google_Cloud_Bigquery_V2_RestrictionConfig()}
    set {_uniqueStorage()._restrictions = newValue}
  }
  /// Returns true if `restrictions` has been explicitly set.
  package var hasRestrictions: Bool {return _storage._restrictions != nil}
  /// Clears the value of `restrictions`. Subsequent reads from it will return its default value.
  package mutating func clearRestrictions() {_uniqueStorage()._restrictions = nil}

  /// Optional. Tables Primary Key and Foreign Key information
  package var tableConstraints: Google_Cloud_Bigquery_V2_TableConstraints {
    get {return _storage._tableConstraints ?? Google_Cloud_Bigquery_V2_TableConstraints()}
    set {_uniqueStorage()._tableConstraints = newValue}
  }
  /// Returns true if `tableConstraints` has been explicitly set.
  package var hasTableConstraints: Bool {return _storage._tableConstraints != nil}
  /// Clears the value of `tableConstraints`. Subsequent reads from it will return its default value.
  package mutating func clearTableConstraints() {_uniqueStorage()._tableConstraints = nil}

  /// Optional. The [tags](https://cloud.google.com/bigquery/docs/tags) attached
  /// to this table. Tag keys are globally unique. Tag key is expected to be in
  /// the namespaced format, for example "123456789012/environment" where
  /// 123456789012 is the ID of the parent organization or project resource for
  /// this tag key. Tag value is expected to be the short name, for example
  /// "Production". See [Tag
  /// definitions](https://cloud.google.com/iam/docs/tags-access-control#definitions)
  /// for more details.
  package var resourceTags: Dictionary<String,String> {
    get {return _storage._resourceTags}
    set {_uniqueStorage()._resourceTags = newValue}
  }

  /// Optional. Table replication info for table created `AS REPLICA` DDL like:
  /// `CREATE MATERIALIZED VIEW mv1 AS REPLICA OF src_mv`
  package var tableReplicationInfo: Google_Cloud_Bigquery_V2_TableReplicationInfo {
    get {return _storage._tableReplicationInfo ?? Google_Cloud_Bigquery_V2_TableReplicationInfo()}
    set {_uniqueStorage()._tableReplicationInfo = newValue}
  }
  /// Returns true if `tableReplicationInfo` has been explicitly set.
  package var hasTableReplicationInfo: Bool {return _storage._tableReplicationInfo != nil}
  /// Clears the value of `tableReplicationInfo`. Subsequent reads from it will return its default value.
  package mutating func clearTableReplicationInfo() {_uniqueStorage()._tableReplicationInfo = nil}

  /// Optional. Output only. Table references of all replicas currently active on
  /// the table.
  package var replicas: [Google_Cloud_Bigquery_V2_TableReference] {
    get {return _storage._replicas}
    set {_uniqueStorage()._replicas = newValue}
  }

  /// Optional. Options defining open source compatible table.
  package var externalCatalogTableOptions: Google_Cloud_Bigquery_V2_ExternalCatalogTableOptions {
    get {return _storage._externalCatalogTableOptions ?? Google_Cloud_Bigquery_V2_ExternalCatalogTableOptions()}
    set {_uniqueStorage()._externalCatalogTableOptions = newValue}
  }
  /// Returns true if `externalCatalogTableOptions` has been explicitly set.
  package var hasExternalCatalogTableOptions: Bool {return _storage._externalCatalogTableOptions != nil}
  /// Clears the value of `externalCatalogTableOptions`. Subsequent reads from it will return its default value.
  package mutating func clearExternalCatalogTableOptions() {_uniqueStorage()._externalCatalogTableOptions = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Request format for getting table metadata.
package struct Google_Cloud_Bigquery_V2_GetTableRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the requested table
  package var projectID: String = String()

  /// Required. Dataset ID of the requested table
  package var datasetID: String = String()

  /// Required. Table ID of the requested table
  package var tableID: String = String()

  /// List of table schema fields to return (comma-separated).
  /// If unspecified, all fields are returned.
  /// A fieldMask cannot be used here because the fields will automatically be
  /// converted from camelCase to snake_case and the conversion will fail if
  /// there are underscores. Since these are fields in BigQuery table schemas,
  /// underscores are allowed.
  package var selectedFields: String = String()

  /// Optional. Specifies the view that determines which table information is
  /// returned. By default, basic table information and storage statistics
  /// (STORAGE_STATS) are returned.
  package var view: Google_Cloud_Bigquery_V2_GetTableRequest.TableMetadataView = .unspecified

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// TableMetadataView specifies which table information is returned.
  package enum TableMetadataView: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// The default value.
    /// Default to the STORAGE_STATS view.
    case unspecified // = 0

    /// Includes basic table information including schema and
    /// partitioning specification. This view does not include storage statistics
    /// such as numRows or numBytes. This view is significantly more efficient
    /// and should be used to support high query rates.
    case basic // = 1

    /// Includes all information in the BASIC view as well as storage statistics
    /// (numBytes, numLongTermBytes, numRows and lastModifiedTime).
    case storageStats // = 2

    /// Includes all table information, including storage statistics.
    /// It returns same information as STORAGE_STATS view, but may contain
    /// additional information in the future.
    case full // = 3
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .basic
      case 2: self = .storageStats
      case 3: self = .full
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .basic: return 1
      case .storageStats: return 2
      case .full: return 3
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_GetTableRequest.TableMetadataView] = [
      .unspecified,
      .basic,
      .storageStats,
      .full,
    ]

  }

  package init() {}
}

/// Request format for inserting table metadata.
package struct Google_Cloud_Bigquery_V2_InsertTableRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the new table
  package var projectID: String = String()

  /// Required. Dataset ID of the new table
  package var datasetID: String = String()

  /// Required. A tables resource to insert
  package var table: Google_Cloud_Bigquery_V2_Table {
    get {return _table ?? Google_Cloud_Bigquery_V2_Table()}
    set {_table = newValue}
  }
  /// Returns true if `table` has been explicitly set.
  package var hasTable: Bool {return self._table != nil}
  /// Clears the value of `table`. Subsequent reads from it will return its default value.
  package mutating func clearTable() {self._table = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _table: Google_Cloud_Bigquery_V2_Table? = nil
}

package struct Google_Cloud_Bigquery_V2_UpdateOrPatchTableRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the table to update
  package var projectID: String = String()

  /// Required. Dataset ID of the table to update
  package var datasetID: String = String()

  /// Required. Table ID of the table to update
  package var tableID: String = String()

  /// Required. A tables resource which will replace or patch the specified table
  package var table: Google_Cloud_Bigquery_V2_Table {
    get {return _table ?? Google_Cloud_Bigquery_V2_Table()}
    set {_table = newValue}
  }
  /// Returns true if `table` has been explicitly set.
  package var hasTable: Bool {return self._table != nil}
  /// Clears the value of `table`. Subsequent reads from it will return its default value.
  package mutating func clearTable() {self._table = nil}

  /// Optional. When true will autodetect schema, else will keep original schema.
  package var autodetectSchema: Bool = false

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _table: Google_Cloud_Bigquery_V2_Table? = nil
}

/// Request format for deleting a table.
package struct Google_Cloud_Bigquery_V2_DeleteTableRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the table to delete
  package var projectID: String = String()

  /// Required. Dataset ID of the table to delete
  package var datasetID: String = String()

  /// Required. Table ID of the table to delete
  package var tableID: String = String()

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

/// Request format for enumerating tables.
package struct Google_Cloud_Bigquery_V2_ListTablesRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the tables to list
  package var projectID: String = String()

  /// Required. Dataset ID of the tables to list
  package var datasetID: String = String()

  /// The maximum number of results to return in a single response page.
  /// Leverage the page tokens to iterate through the entire collection.
  package var maxResults: SwiftProtobuf.Google_Protobuf_UInt32Value {
    get {return _maxResults ?? SwiftProtobuf.Google_Protobuf_UInt32Value()}
    set {_maxResults = newValue}
  }
  /// Returns true if `maxResults` has been explicitly set.
  package var hasMaxResults: Bool {return self._maxResults != nil}
  /// Clears the value of `maxResults`. Subsequent reads from it will return its default value.
  package mutating func clearMaxResults() {self._maxResults = nil}

  /// Page token, returned by a previous call, to request the next page of
  /// results
  package var pageToken: String = String()

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _maxResults: SwiftProtobuf.Google_Protobuf_UInt32Value? = nil
}

/// Information about a logical view.
package struct Google_Cloud_Bigquery_V2_ListFormatView: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// True if view is defined in legacy SQL dialect,
  /// false if in GoogleSQL.
  package var useLegacySql: SwiftProtobuf.Google_Protobuf_BoolValue {
    get {return _useLegacySql ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
    set {_useLegacySql = newValue}
  }
  /// Returns true if `useLegacySql` has been explicitly set.
  package var hasUseLegacySql: Bool {return self._useLegacySql != nil}
  /// Clears the value of `useLegacySql`. Subsequent reads from it will return its default value.
  package mutating func clearUseLegacySql() {self._useLegacySql = nil}

  /// Specifices the privacy policy for the view.
  package var privacyPolicy: Google_Cloud_Bigquery_V2_PrivacyPolicy {
    get {return _privacyPolicy ?? Google_Cloud_Bigquery_V2_PrivacyPolicy()}
    set {_privacyPolicy = newValue}
  }
  /// Returns true if `privacyPolicy` has been explicitly set.
  package var hasPrivacyPolicy: Bool {return self._privacyPolicy != nil}
  /// Clears the value of `privacyPolicy`. Subsequent reads from it will return its default value.
  package mutating func clearPrivacyPolicy() {self._privacyPolicy = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _useLegacySql: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
  fileprivate var _privacyPolicy: Google_Cloud_Bigquery_V2_PrivacyPolicy? = nil
}

package struct Google_Cloud_Bigquery_V2_ListFormatTable: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The resource type.
  package var kind: String {
    get {return _storage._kind}
    set {_uniqueStorage()._kind = newValue}
  }

  /// An opaque ID of the table.
  package var id: String {
    get {return _storage._id}
    set {_uniqueStorage()._id = newValue}
  }

  /// A reference uniquely identifying table.
  package var tableReference: Google_Cloud_Bigquery_V2_TableReference {
    get {return _storage._tableReference ?? Google_Cloud_Bigquery_V2_TableReference()}
    set {_uniqueStorage()._tableReference = newValue}
  }
  /// Returns true if `tableReference` has been explicitly set.
  package var hasTableReference: Bool {return _storage._tableReference != nil}
  /// Clears the value of `tableReference`. Subsequent reads from it will return its default value.
  package mutating func clearTableReference() {_uniqueStorage()._tableReference = nil}

  /// The user-friendly name for this table.
  package var friendlyName: SwiftProtobuf.Google_Protobuf_StringValue {
    get {return _storage._friendlyName ?? SwiftProtobuf.Google_Protobuf_StringValue()}
    set {_uniqueStorage()._friendlyName = newValue}
  }
  /// Returns true if `friendlyName` has been explicitly set.
  package var hasFriendlyName: Bool {return _storage._friendlyName != nil}
  /// Clears the value of `friendlyName`. Subsequent reads from it will return its default value.
  package mutating func clearFriendlyName() {_uniqueStorage()._friendlyName = nil}

  /// The type of table.
  package var type: String {
    get {return _storage._type}
    set {_uniqueStorage()._type = newValue}
  }

  /// The time-based partitioning for this table.
  package var timePartitioning: Google_Cloud_Bigquery_V2_TimePartitioning {
    get {return _storage._timePartitioning ?? Google_Cloud_Bigquery_V2_TimePartitioning()}
    set {_uniqueStorage()._timePartitioning = newValue}
  }
  /// Returns true if `timePartitioning` has been explicitly set.
  package var hasTimePartitioning: Bool {return _storage._timePartitioning != nil}
  /// Clears the value of `timePartitioning`. Subsequent reads from it will return its default value.
  package mutating func clearTimePartitioning() {_uniqueStorage()._timePartitioning = nil}

  /// The range partitioning for this table.
  package var rangePartitioning: Google_Cloud_Bigquery_V2_RangePartitioning {
    get {return _storage._rangePartitioning ?? Google_Cloud_Bigquery_V2_RangePartitioning()}
    set {_uniqueStorage()._rangePartitioning = newValue}
  }
  /// Returns true if `rangePartitioning` has been explicitly set.
  package var hasRangePartitioning: Bool {return _storage._rangePartitioning != nil}
  /// Clears the value of `rangePartitioning`. Subsequent reads from it will return its default value.
  package mutating func clearRangePartitioning() {_uniqueStorage()._rangePartitioning = nil}

  /// Clustering specification for this table, if configured.
  package var clustering: Google_Cloud_Bigquery_V2_Clustering {
    get {return _storage._clustering ?? Google_Cloud_Bigquery_V2_Clustering()}
    set {_uniqueStorage()._clustering = newValue}
  }
  /// Returns true if `clustering` has been explicitly set.
  package var hasClustering: Bool {return _storage._clustering != nil}
  /// Clears the value of `clustering`. Subsequent reads from it will return its default value.
  package mutating func clearClustering() {_uniqueStorage()._clustering = nil}

  /// The labels associated with this table. You can use these to organize
  /// and group your tables.
  package var labels: Dictionary<String,String> {
    get {return _storage._labels}
    set {_uniqueStorage()._labels = newValue}
  }

  /// Additional details for a view.
  package var view: Google_Cloud_Bigquery_V2_ListFormatView {
    get {return _storage._view ?? Google_Cloud_Bigquery_V2_ListFormatView()}
    set {_uniqueStorage()._view = newValue}
  }
  /// Returns true if `view` has been explicitly set.
  package var hasView: Bool {return _storage._view != nil}
  /// Clears the value of `view`. Subsequent reads from it will return its default value.
  package mutating func clearView() {_uniqueStorage()._view = nil}

  /// Output only. The time when this table was created, in milliseconds since
  /// the epoch.
  package var creationTime: Int64 {
    get {return _storage._creationTime}
    set {_uniqueStorage()._creationTime = newValue}
  }

  /// The time when this table expires, in milliseconds since the
  /// epoch. If not present, the table will persist indefinitely. Expired tables
  /// will be deleted and their storage reclaimed.
  package var expirationTime: Int64 {
    get {return _storage._expirationTime}
    set {_uniqueStorage()._expirationTime = newValue}
  }

  /// Optional. If set to true, queries including this table must specify a
  /// partition filter. This filter is used for partition elimination.
  package var requirePartitionFilter: SwiftProtobuf.Google_Protobuf_BoolValue {
    get {return _storage._requirePartitionFilter ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
    set {_uniqueStorage()._requirePartitionFilter = newValue}
  }
  /// Returns true if `requirePartitionFilter` has been explicitly set.
  package var hasRequirePartitionFilter: Bool {return _storage._requirePartitionFilter != nil}
  /// Clears the value of `requirePartitionFilter`. Subsequent reads from it will return its default value.
  package mutating func clearRequirePartitionFilter() {_uniqueStorage()._requirePartitionFilter = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Partial projection of the metadata for a given table in a list response.
package struct Google_Cloud_Bigquery_V2_TableList: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The type of list.
  package var kind: String = String()

  /// A hash of this page of results.
  package var etag: String = String()

  /// A token to request the next page of results.
  package var nextPageToken: String = String()

  /// Tables in the requested dataset.
  package var tables: [Google_Cloud_Bigquery_V2_ListFormatTable] = []

  /// The total number of tables in the dataset.
  package var totalItems: SwiftProtobuf.Google_Protobuf_Int32Value {
    get {return _totalItems ?? SwiftProtobuf.Google_Protobuf_Int32Value()}
    set {_totalItems = newValue}
  }
  /// Returns true if `totalItems` has been explicitly set.
  package var hasTotalItems: Bool {return self._totalItems != nil}
  /// Clears the value of `totalItems`. Subsequent reads from it will return its default value.
  package mutating func clearTotalItems() {self._totalItems = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _totalItems: SwiftProtobuf.Google_Protobuf_Int32Value? = nil
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.bigquery.v2"

extension Google_Cloud_Bigquery_V2_TableReplicationInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".TableReplicationInfo"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "source_table"),
    2: .standard(proto: "replication_interval_ms"),
    3: .standard(proto: "replicated_source_last_refresh_time"),
    4: .standard(proto: "replication_status"),
    5: .standard(proto: "replication_error"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._sourceTable) }()
      case 2: try { try decoder.decodeSingularInt64Field(value: &self.replicationIntervalMs) }()
      case 3: try { try decoder.decodeSingularInt64Field(value: &self.replicatedSourceLastRefreshTime) }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self.replicationStatus) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._replicationError) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._sourceTable {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if self.replicationIntervalMs != 0 {
      try visitor.visitSingularInt64Field(value: self.replicationIntervalMs, fieldNumber: 2)
    }
    if self.replicatedSourceLastRefreshTime != 0 {
      try visitor.visitSingularInt64Field(value: self.replicatedSourceLastRefreshTime, fieldNumber: 3)
    }
    if self.replicationStatus != .unspecified {
      try visitor.visitSingularEnumField(value: self.replicationStatus, fieldNumber: 4)
    }
    try { if let v = self._replicationError {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_TableReplicationInfo, rhs: Google_Cloud_Bigquery_V2_TableReplicationInfo) -> Bool {
    if lhs._sourceTable != rhs._sourceTable {return false}
    if lhs.replicationIntervalMs != rhs.replicationIntervalMs {return false}
    if lhs.replicatedSourceLastRefreshTime != rhs.replicatedSourceLastRefreshTime {return false}
    if lhs.replicationStatus != rhs.replicationStatus {return false}
    if lhs._replicationError != rhs._replicationError {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_TableReplicationInfo.ReplicationStatus: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "REPLICATION_STATUS_UNSPECIFIED"),
    1: .same(proto: "ACTIVE"),
    2: .same(proto: "SOURCE_DELETED"),
    3: .same(proto: "PERMISSION_DENIED"),
    4: .same(proto: "UNSUPPORTED_CONFIGURATION"),
  ]
}

extension Google_Cloud_Bigquery_V2_ViewDefinition: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".ViewDefinition"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "query"),
    2: .standard(proto: "user_defined_function_resources"),
    3: .standard(proto: "use_legacy_sql"),
    4: .standard(proto: "use_explicit_column_names"),
    5: .standard(proto: "privacy_policy"),
    6: .standard(proto: "foreign_definitions"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.query) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.userDefinedFunctionResources) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._useLegacySql) }()
      case 4: try { try decoder.decodeSingularBoolField(value: &self.useExplicitColumnNames) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._privacyPolicy) }()
      case 6: try { try decoder.decodeRepeatedMessageField(value: &self.foreignDefinitions) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.query.isEmpty {
      try visitor.visitSingularStringField(value: self.query, fieldNumber: 1)
    }
    if !self.userDefinedFunctionResources.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.userDefinedFunctionResources, fieldNumber: 2)
    }
    try { if let v = self._useLegacySql {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    if self.useExplicitColumnNames != false {
      try visitor.visitSingularBoolField(value: self.useExplicitColumnNames, fieldNumber: 4)
    }
    try { if let v = self._privacyPolicy {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    if !self.foreignDefinitions.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.foreignDefinitions, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_ViewDefinition, rhs: Google_Cloud_Bigquery_V2_ViewDefinition) -> Bool {
    if lhs.query != rhs.query {return false}
    if lhs.userDefinedFunctionResources != rhs.userDefinedFunctionResources {return false}
    if lhs._useLegacySql != rhs._useLegacySql {return false}
    if lhs.useExplicitColumnNames != rhs.useExplicitColumnNames {return false}
    if lhs._privacyPolicy != rhs._privacyPolicy {return false}
    if lhs.foreignDefinitions != rhs.foreignDefinitions {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_ForeignViewDefinition: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".ForeignViewDefinition"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "query"),
    7: .same(proto: "dialect"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.query) }()
      case 7: try { try decoder.decodeSingularStringField(value: &self.dialect) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.query.isEmpty {
      try visitor.visitSingularStringField(value: self.query, fieldNumber: 1)
    }
    if !self.dialect.isEmpty {
      try visitor.visitSingularStringField(value: self.dialect, fieldNumber: 7)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_ForeignViewDefinition, rhs: Google_Cloud_Bigquery_V2_ForeignViewDefinition) -> Bool {
    if lhs.query != rhs.query {return false}
    if lhs.dialect != rhs.dialect {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_MaterializedViewDefinition: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".MaterializedViewDefinition"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "query"),
    2: .standard(proto: "last_refresh_time"),
    3: .standard(proto: "enable_refresh"),
    4: .standard(proto: "refresh_interval_ms"),
    6: .standard(proto: "allow_non_incremental_definition"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.query) }()
      case 2: try { try decoder.decodeSingularInt64Field(value: &self.lastRefreshTime) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._enableRefresh) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._refreshIntervalMs) }()
      case 6: try { try decoder.decodeSingularMessageField(value: &self._allowNonIncrementalDefinition) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.query.isEmpty {
      try visitor.visitSingularStringField(value: self.query, fieldNumber: 1)
    }
    if self.lastRefreshTime != 0 {
      try visitor.visitSingularInt64Field(value: self.lastRefreshTime, fieldNumber: 2)
    }
    try { if let v = self._enableRefresh {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._refreshIntervalMs {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try { if let v = self._allowNonIncrementalDefinition {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_MaterializedViewDefinition, rhs: Google_Cloud_Bigquery_V2_MaterializedViewDefinition) -> Bool {
    if lhs.query != rhs.query {return false}
    if lhs.lastRefreshTime != rhs.lastRefreshTime {return false}
    if lhs._enableRefresh != rhs._enableRefresh {return false}
    if lhs._refreshIntervalMs != rhs._refreshIntervalMs {return false}
    if lhs._allowNonIncrementalDefinition != rhs._allowNonIncrementalDefinition {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_MaterializedViewStatus: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".MaterializedViewStatus"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "refresh_watermark"),
    2: .standard(proto: "last_refresh_status"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._refreshWatermark) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._lastRefreshStatus) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._refreshWatermark {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._lastRefreshStatus {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_MaterializedViewStatus, rhs: Google_Cloud_Bigquery_V2_MaterializedViewStatus) -> Bool {
    if lhs._refreshWatermark != rhs._refreshWatermark {return false}
    if lhs._lastRefreshStatus != rhs._lastRefreshStatus {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_SnapshotDefinition: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".SnapshotDefinition"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "base_table_reference"),
    2: .standard(proto: "snapshot_time"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._baseTableReference) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._snapshotTime) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._baseTableReference {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._snapshotTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_SnapshotDefinition, rhs: Google_Cloud_Bigquery_V2_SnapshotDefinition) -> Bool {
    if lhs._baseTableReference != rhs._baseTableReference {return false}
    if lhs._snapshotTime != rhs._snapshotTime {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_CloneDefinition: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".CloneDefinition"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "base_table_reference"),
    2: .standard(proto: "clone_time"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._baseTableReference) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._cloneTime) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._baseTableReference {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._cloneTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_CloneDefinition, rhs: Google_Cloud_Bigquery_V2_CloneDefinition) -> Bool {
    if lhs._baseTableReference != rhs._baseTableReference {return false}
    if lhs._cloneTime != rhs._cloneTime {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Streamingbuffer: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".Streamingbuffer"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "estimated_bytes"),
    2: .standard(proto: "estimated_rows"),
    3: .standard(proto: "oldest_entry_time"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.estimatedBytes) }()
      case 2: try { try decoder.decodeSingularUInt64Field(value: &self.estimatedRows) }()
      case 3: try { try decoder.decodeSingularFixed64Field(value: &self.oldestEntryTime) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.estimatedBytes != 0 {
      try visitor.visitSingularUInt64Field(value: self.estimatedBytes, fieldNumber: 1)
    }
    if self.estimatedRows != 0 {
      try visitor.visitSingularUInt64Field(value: self.estimatedRows, fieldNumber: 2)
    }
    if self.oldestEntryTime != 0 {
      try visitor.visitSingularFixed64Field(value: self.oldestEntryTime, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Streamingbuffer, rhs: Google_Cloud_Bigquery_V2_Streamingbuffer) -> Bool {
    if lhs.estimatedBytes != rhs.estimatedBytes {return false}
    if lhs.estimatedRows != rhs.estimatedRows {return false}
    if lhs.oldestEntryTime != rhs.oldestEntryTime {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Table: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".Table"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "kind"),
    2: .same(proto: "etag"),
    3: .same(proto: "id"),
    4: .standard(proto: "self_link"),
    5: .standard(proto: "table_reference"),
    6: .standard(proto: "friendly_name"),
    7: .same(proto: "description"),
    8: .same(proto: "labels"),
    9: .same(proto: "schema"),
    10: .standard(proto: "time_partitioning"),
    27: .standard(proto: "range_partitioning"),
    23: .same(proto: "clustering"),
    28: .standard(proto: "require_partition_filter"),
    51: .standard(proto: "partition_definition"),
    11: .standard(proto: "num_bytes"),
    26: .standard(proto: "num_physical_bytes"),
    12: .standard(proto: "num_long_term_bytes"),
    13: .standard(proto: "num_rows"),
    14: .standard(proto: "creation_time"),
    15: .standard(proto: "expiration_time"),
    16: .standard(proto: "last_modified_time"),
    17: .same(proto: "type"),
    18: .same(proto: "view"),
    25: .standard(proto: "materialized_view"),
    42: .standard(proto: "materialized_view_status"),
    19: .standard(proto: "external_data_configuration"),
    45: .standard(proto: "biglake_configuration"),
    20: .same(proto: "location"),
    21: .standard(proto: "streaming_buffer"),
    22: .standard(proto: "encryption_configuration"),
    29: .standard(proto: "snapshot_definition"),
    30: .standard(proto: "default_collation"),
    44: .standard(proto: "default_rounding_mode"),
    31: .standard(proto: "clone_definition"),
    33: .standard(proto: "num_time_travel_physical_bytes"),
    34: .standard(proto: "num_total_logical_bytes"),
    35: .standard(proto: "num_active_logical_bytes"),
    36: .standard(proto: "num_long_term_logical_bytes"),
    53: .standard(proto: "num_current_physical_bytes"),
    37: .standard(proto: "num_total_physical_bytes"),
    38: .standard(proto: "num_active_physical_bytes"),
    39: .standard(proto: "num_long_term_physical_bytes"),
    40: .standard(proto: "num_partitions"),
    41: .standard(proto: "max_staleness"),
    46: .same(proto: "restrictions"),
    47: .standard(proto: "table_constraints"),
    48: .standard(proto: "resource_tags"),
    49: .standard(proto: "table_replication_info"),
    50: .same(proto: "replicas"),
    54: .standard(proto: "external_catalog_table_options"),
  ]

  fileprivate class _StorageClass {
    var _kind: String = String()
    var _etag: String = String()
    var _id: String = String()
    var _selfLink: String = String()
    var _tableReference: Google_Cloud_Bigquery_V2_TableReference? = nil
    var _friendlyName: SwiftProtobuf.Google_Protobuf_StringValue? = nil
    var _description_p: SwiftProtobuf.Google_Protobuf_StringValue? = nil
    var _labels: Dictionary<String,String> = [:]
    var _schema: Google_Cloud_Bigquery_V2_TableSchema? = nil
    var _timePartitioning: Google_Cloud_Bigquery_V2_TimePartitioning? = nil
    var _rangePartitioning: Google_Cloud_Bigquery_V2_RangePartitioning? = nil
    var _clustering: Google_Cloud_Bigquery_V2_Clustering? = nil
    var _requirePartitionFilter: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _partitionDefinition: Google_Cloud_Bigquery_V2_PartitioningDefinition? = nil
    var _numBytes: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _numPhysicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _numLongTermBytes: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _numRows: SwiftProtobuf.Google_Protobuf_UInt64Value? = nil
    var _creationTime: Int64 = 0
    var _expirationTime: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _lastModifiedTime: UInt64 = 0
    var _type: String = String()
    var _view: Google_Cloud_Bigquery_V2_ViewDefinition? = nil
    var _materializedView: Google_Cloud_Bigquery_V2_MaterializedViewDefinition? = nil
    var _materializedViewStatus: Google_Cloud_Bigquery_V2_MaterializedViewStatus? = nil
    var _externalDataConfiguration: Google_Cloud_Bigquery_V2_ExternalDataConfiguration? = nil
    var _biglakeConfiguration: Google_Cloud_Bigquery_V2_BigLakeConfiguration? = nil
    var _location: String = String()
    var _streamingBuffer: Google_Cloud_Bigquery_V2_Streamingbuffer? = nil
    var _encryptionConfiguration: Google_Cloud_Bigquery_V2_EncryptionConfiguration? = nil
    var _snapshotDefinition: Google_Cloud_Bigquery_V2_SnapshotDefinition? = nil
    var _defaultCollation: SwiftProtobuf.Google_Protobuf_StringValue? = nil
    var _defaultRoundingMode: Google_Cloud_Bigquery_V2_TableFieldSchema.RoundingMode = .unspecified
    var _cloneDefinition: Google_Cloud_Bigquery_V2_CloneDefinition? = nil
    var _numTimeTravelPhysicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _numTotalLogicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _numActiveLogicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _numLongTermLogicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _numCurrentPhysicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _numTotalPhysicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _numActivePhysicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _numLongTermPhysicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _numPartitions: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _maxStaleness: String = String()
    var _restrictions: Google_Cloud_Bigquery_V2_RestrictionConfig? = nil
    var _tableConstraints: Google_Cloud_Bigquery_V2_TableConstraints? = nil
    var _resourceTags: Dictionary<String,String> = [:]
    var _tableReplicationInfo: Google_Cloud_Bigquery_V2_TableReplicationInfo? = nil
    var _replicas: [Google_Cloud_Bigquery_V2_TableReference] = []
    var _externalCatalogTableOptions: Google_Cloud_Bigquery_V2_ExternalCatalogTableOptions? = nil

    #if swift(>=5.10)
      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()
    #else
      static let defaultInstance = _StorageClass()
    #endif

    private init() {}

    init(copying source: _StorageClass) {
      _kind = source._kind
      _etag = source._etag
      _id = source._id
      _selfLink = source._selfLink
      _tableReference = source._tableReference
      _friendlyName = source._friendlyName
      _description_p = source._description_p
      _labels = source._labels
      _schema = source._schema
      _timePartitioning = source._timePartitioning
      _rangePartitioning = source._rangePartitioning
      _clustering = source._clustering
      _requirePartitionFilter = source._requirePartitionFilter
      _partitionDefinition = source._partitionDefinition
      _numBytes = source._numBytes
      _numPhysicalBytes = source._numPhysicalBytes
      _numLongTermBytes = source._numLongTermBytes
      _numRows = source._numRows
      _creationTime = source._creationTime
      _expirationTime = source._expirationTime
      _lastModifiedTime = source._lastModifiedTime
      _type = source._type
      _view = source._view
      _materializedView = source._materializedView
      _materializedViewStatus = source._materializedViewStatus
      _externalDataConfiguration = source._externalDataConfiguration
      _biglakeConfiguration = source._biglakeConfiguration
      _location = source._location
      _streamingBuffer = source._streamingBuffer
      _encryptionConfiguration = source._encryptionConfiguration
      _snapshotDefinition = source._snapshotDefinition
      _defaultCollation = source._defaultCollation
      _defaultRoundingMode = source._defaultRoundingMode
      _cloneDefinition = source._cloneDefinition
      _numTimeTravelPhysicalBytes = source._numTimeTravelPhysicalBytes
      _numTotalLogicalBytes = source._numTotalLogicalBytes
      _numActiveLogicalBytes = source._numActiveLogicalBytes
      _numLongTermLogicalBytes = source._numLongTermLogicalBytes
      _numCurrentPhysicalBytes = source._numCurrentPhysicalBytes
      _numTotalPhysicalBytes = source._numTotalPhysicalBytes
      _numActivePhysicalBytes = source._numActivePhysicalBytes
      _numLongTermPhysicalBytes = source._numLongTermPhysicalBytes
      _numPartitions = source._numPartitions
      _maxStaleness = source._maxStaleness
      _restrictions = source._restrictions
      _tableConstraints = source._tableConstraints
      _resourceTags = source._resourceTags
      _tableReplicationInfo = source._tableReplicationInfo
      _replicas = source._replicas
      _externalCatalogTableOptions = source._externalCatalogTableOptions
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._kind) }()
        case 2: try { try decoder.decodeSingularStringField(value: &_storage._etag) }()
        case 3: try { try decoder.decodeSingularStringField(value: &_storage._id) }()
        case 4: try { try decoder.decodeSingularStringField(value: &_storage._selfLink) }()
        case 5: try { try decoder.decodeSingularMessageField(value: &_storage._tableReference) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._friendlyName) }()
        case 7: try { try decoder.decodeSingularMessageField(value: &_storage._description_p) }()
        case 8: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &_storage._labels) }()
        case 9: try { try decoder.decodeSingularMessageField(value: &_storage._schema) }()
        case 10: try { try decoder.decodeSingularMessageField(value: &_storage._timePartitioning) }()
        case 11: try { try decoder.decodeSingularMessageField(value: &_storage._numBytes) }()
        case 12: try { try decoder.decodeSingularMessageField(value: &_storage._numLongTermBytes) }()
        case 13: try { try decoder.decodeSingularMessageField(value: &_storage._numRows) }()
        case 14: try { try decoder.decodeSingularInt64Field(value: &_storage._creationTime) }()
        case 15: try { try decoder.decodeSingularMessageField(value: &_storage._expirationTime) }()
        case 16: try { try decoder.decodeSingularFixed64Field(value: &_storage._lastModifiedTime) }()
        case 17: try { try decoder.decodeSingularStringField(value: &_storage._type) }()
        case 18: try { try decoder.decodeSingularMessageField(value: &_storage._view) }()
        case 19: try { try decoder.decodeSingularMessageField(value: &_storage._externalDataConfiguration) }()
        case 20: try { try decoder.decodeSingularStringField(value: &_storage._location) }()
        case 21: try { try decoder.decodeSingularMessageField(value: &_storage._streamingBuffer) }()
        case 22: try { try decoder.decodeSingularMessageField(value: &_storage._encryptionConfiguration) }()
        case 23: try { try decoder.decodeSingularMessageField(value: &_storage._clustering) }()
        case 25: try { try decoder.decodeSingularMessageField(value: &_storage._materializedView) }()
        case 26: try { try decoder.decodeSingularMessageField(value: &_storage._numPhysicalBytes) }()
        case 27: try { try decoder.decodeSingularMessageField(value: &_storage._rangePartitioning) }()
        case 28: try { try decoder.decodeSingularMessageField(value: &_storage._requirePartitionFilter) }()
        case 29: try { try decoder.decodeSingularMessageField(value: &_storage._snapshotDefinition) }()
        case 30: try { try decoder.decodeSingularMessageField(value: &_storage._defaultCollation) }()
        case 31: try { try decoder.decodeSingularMessageField(value: &_storage._cloneDefinition) }()
        case 33: try { try decoder.decodeSingularMessageField(value: &_storage._numTimeTravelPhysicalBytes) }()
        case 34: try { try decoder.decodeSingularMessageField(value: &_storage._numTotalLogicalBytes) }()
        case 35: try { try decoder.decodeSingularMessageField(value: &_storage._numActiveLogicalBytes) }()
        case 36: try { try decoder.decodeSingularMessageField(value: &_storage._numLongTermLogicalBytes) }()
        case 37: try { try decoder.decodeSingularMessageField(value: &_storage._numTotalPhysicalBytes) }()
        case 38: try { try decoder.decodeSingularMessageField(value: &_storage._numActivePhysicalBytes) }()
        case 39: try { try decoder.decodeSingularMessageField(value: &_storage._numLongTermPhysicalBytes) }()
        case 40: try { try decoder.decodeSingularMessageField(value: &_storage._numPartitions) }()
        case 41: try { try decoder.decodeSingularStringField(value: &_storage._maxStaleness) }()
        case 42: try { try decoder.decodeSingularMessageField(value: &_storage._materializedViewStatus) }()
        case 44: try { try decoder.decodeSingularEnumField(value: &_storage._defaultRoundingMode) }()
        case 45: try { try decoder.decodeSingularMessageField(value: &_storage._biglakeConfiguration) }()
        case 46: try { try decoder.decodeSingularMessageField(value: &_storage._restrictions) }()
        case 47: try { try decoder.decodeSingularMessageField(value: &_storage._tableConstraints) }()
        case 48: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &_storage._resourceTags) }()
        case 49: try { try decoder.decodeSingularMessageField(value: &_storage._tableReplicationInfo) }()
        case 50: try { try decoder.decodeRepeatedMessageField(value: &_storage._replicas) }()
        case 51: try { try decoder.decodeSingularMessageField(value: &_storage._partitionDefinition) }()
        case 53: try { try decoder.decodeSingularMessageField(value: &_storage._numCurrentPhysicalBytes) }()
        case 54: try { try decoder.decodeSingularMessageField(value: &_storage._externalCatalogTableOptions) }()
        default: break
        }
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if !_storage._kind.isEmpty {
        try visitor.visitSingularStringField(value: _storage._kind, fieldNumber: 1)
      }
      if !_storage._etag.isEmpty {
        try visitor.visitSingularStringField(value: _storage._etag, fieldNumber: 2)
      }
      if !_storage._id.isEmpty {
        try visitor.visitSingularStringField(value: _storage._id, fieldNumber: 3)
      }
      if !_storage._selfLink.isEmpty {
        try visitor.visitSingularStringField(value: _storage._selfLink, fieldNumber: 4)
      }
      try { if let v = _storage._tableReference {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
      } }()
      try { if let v = _storage._friendlyName {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      } }()
      try { if let v = _storage._description_p {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      } }()
      if !_storage._labels.isEmpty {
        try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: _storage._labels, fieldNumber: 8)
      }
      try { if let v = _storage._schema {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      } }()
      try { if let v = _storage._timePartitioning {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
      } }()
      try { if let v = _storage._numBytes {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
      } }()
      try { if let v = _storage._numLongTermBytes {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 12)
      } }()
      try { if let v = _storage._numRows {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 13)
      } }()
      if _storage._creationTime != 0 {
        try visitor.visitSingularInt64Field(value: _storage._creationTime, fieldNumber: 14)
      }
      try { if let v = _storage._expirationTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 15)
      } }()
      if _storage._lastModifiedTime != 0 {
        try visitor.visitSingularFixed64Field(value: _storage._lastModifiedTime, fieldNumber: 16)
      }
      if !_storage._type.isEmpty {
        try visitor.visitSingularStringField(value: _storage._type, fieldNumber: 17)
      }
      try { if let v = _storage._view {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 18)
      } }()
      try { if let v = _storage._externalDataConfiguration {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 19)
      } }()
      if !_storage._location.isEmpty {
        try visitor.visitSingularStringField(value: _storage._location, fieldNumber: 20)
      }
      try { if let v = _storage._streamingBuffer {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 21)
      } }()
      try { if let v = _storage._encryptionConfiguration {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 22)
      } }()
      try { if let v = _storage._clustering {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 23)
      } }()
      try { if let v = _storage._materializedView {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 25)
      } }()
      try { if let v = _storage._numPhysicalBytes {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 26)
      } }()
      try { if let v = _storage._rangePartitioning {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 27)
      } }()
      try { if let v = _storage._requirePartitionFilter {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 28)
      } }()
      try { if let v = _storage._snapshotDefinition {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 29)
      } }()
      try { if let v = _storage._defaultCollation {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 30)
      } }()
      try { if let v = _storage._cloneDefinition {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 31)
      } }()
      try { if let v = _storage._numTimeTravelPhysicalBytes {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 33)
      } }()
      try { if let v = _storage._numTotalLogicalBytes {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 34)
      } }()
      try { if let v = _storage._numActiveLogicalBytes {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 35)
      } }()
      try { if let v = _storage._numLongTermLogicalBytes {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 36)
      } }()
      try { if let v = _storage._numTotalPhysicalBytes {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 37)
      } }()
      try { if let v = _storage._numActivePhysicalBytes {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 38)
      } }()
      try { if let v = _storage._numLongTermPhysicalBytes {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 39)
      } }()
      try { if let v = _storage._numPartitions {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 40)
      } }()
      if !_storage._maxStaleness.isEmpty {
        try visitor.visitSingularStringField(value: _storage._maxStaleness, fieldNumber: 41)
      }
      try { if let v = _storage._materializedViewStatus {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 42)
      } }()
      if _storage._defaultRoundingMode != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._defaultRoundingMode, fieldNumber: 44)
      }
      try { if let v = _storage._biglakeConfiguration {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 45)
      } }()
      try { if let v = _storage._restrictions {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 46)
      } }()
      try { if let v = _storage._tableConstraints {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 47)
      } }()
      if !_storage._resourceTags.isEmpty {
        try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: _storage._resourceTags, fieldNumber: 48)
      }
      try { if let v = _storage._tableReplicationInfo {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 49)
      } }()
      if !_storage._replicas.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._replicas, fieldNumber: 50)
      }
      try { if let v = _storage._partitionDefinition {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 51)
      } }()
      try { if let v = _storage._numCurrentPhysicalBytes {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 53)
      } }()
      try { if let v = _storage._externalCatalogTableOptions {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 54)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Table, rhs: Google_Cloud_Bigquery_V2_Table) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._kind != rhs_storage._kind {return false}
        if _storage._etag != rhs_storage._etag {return false}
        if _storage._id != rhs_storage._id {return false}
        if _storage._selfLink != rhs_storage._selfLink {return false}
        if _storage._tableReference != rhs_storage._tableReference {return false}
        if _storage._friendlyName != rhs_storage._friendlyName {return false}
        if _storage._description_p != rhs_storage._description_p {return false}
        if _storage._labels != rhs_storage._labels {return false}
        if _storage._schema != rhs_storage._schema {return false}
        if _storage._timePartitioning != rhs_storage._timePartitioning {return false}
        if _storage._rangePartitioning != rhs_storage._rangePartitioning {return false}
        if _storage._clustering != rhs_storage._clustering {return false}
        if _storage._requirePartitionFilter != rhs_storage._requirePartitionFilter {return false}
        if _storage._partitionDefinition != rhs_storage._partitionDefinition {return false}
        if _storage._numBytes != rhs_storage._numBytes {return false}
        if _storage._numPhysicalBytes != rhs_storage._numPhysicalBytes {return false}
        if _storage._numLongTermBytes != rhs_storage._numLongTermBytes {return false}
        if _storage._numRows != rhs_storage._numRows {return false}
        if _storage._creationTime != rhs_storage._creationTime {return false}
        if _storage._expirationTime != rhs_storage._expirationTime {return false}
        if _storage._lastModifiedTime != rhs_storage._lastModifiedTime {return false}
        if _storage._type != rhs_storage._type {return false}
        if _storage._view != rhs_storage._view {return false}
        if _storage._materializedView != rhs_storage._materializedView {return false}
        if _storage._materializedViewStatus != rhs_storage._materializedViewStatus {return false}
        if _storage._externalDataConfiguration != rhs_storage._externalDataConfiguration {return false}
        if _storage._biglakeConfiguration != rhs_storage._biglakeConfiguration {return false}
        if _storage._location != rhs_storage._location {return false}
        if _storage._streamingBuffer != rhs_storage._streamingBuffer {return false}
        if _storage._encryptionConfiguration != rhs_storage._encryptionConfiguration {return false}
        if _storage._snapshotDefinition != rhs_storage._snapshotDefinition {return false}
        if _storage._defaultCollation != rhs_storage._defaultCollation {return false}
        if _storage._defaultRoundingMode != rhs_storage._defaultRoundingMode {return false}
        if _storage._cloneDefinition != rhs_storage._cloneDefinition {return false}
        if _storage._numTimeTravelPhysicalBytes != rhs_storage._numTimeTravelPhysicalBytes {return false}
        if _storage._numTotalLogicalBytes != rhs_storage._numTotalLogicalBytes {return false}
        if _storage._numActiveLogicalBytes != rhs_storage._numActiveLogicalBytes {return false}
        if _storage._numLongTermLogicalBytes != rhs_storage._numLongTermLogicalBytes {return false}
        if _storage._numCurrentPhysicalBytes != rhs_storage._numCurrentPhysicalBytes {return false}
        if _storage._numTotalPhysicalBytes != rhs_storage._numTotalPhysicalBytes {return false}
        if _storage._numActivePhysicalBytes != rhs_storage._numActivePhysicalBytes {return false}
        if _storage._numLongTermPhysicalBytes != rhs_storage._numLongTermPhysicalBytes {return false}
        if _storage._numPartitions != rhs_storage._numPartitions {return false}
        if _storage._maxStaleness != rhs_storage._maxStaleness {return false}
        if _storage._restrictions != rhs_storage._restrictions {return false}
        if _storage._tableConstraints != rhs_storage._tableConstraints {return false}
        if _storage._resourceTags != rhs_storage._resourceTags {return false}
        if _storage._tableReplicationInfo != rhs_storage._tableReplicationInfo {return false}
        if _storage._replicas != rhs_storage._replicas {return false}
        if _storage._externalCatalogTableOptions != rhs_storage._externalCatalogTableOptions {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_GetTableRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".GetTableRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "dataset_id"),
    3: .standard(proto: "table_id"),
    4: .standard(proto: "selected_fields"),
    5: .same(proto: "view"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.datasetID) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.tableID) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.selectedFields) }()
      case 5: try { try decoder.decodeSingularEnumField(value: &self.view) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.datasetID.isEmpty {
      try visitor.visitSingularStringField(value: self.datasetID, fieldNumber: 2)
    }
    if !self.tableID.isEmpty {
      try visitor.visitSingularStringField(value: self.tableID, fieldNumber: 3)
    }
    if !self.selectedFields.isEmpty {
      try visitor.visitSingularStringField(value: self.selectedFields, fieldNumber: 4)
    }
    if self.view != .unspecified {
      try visitor.visitSingularEnumField(value: self.view, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_GetTableRequest, rhs: Google_Cloud_Bigquery_V2_GetTableRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.datasetID != rhs.datasetID {return false}
    if lhs.tableID != rhs.tableID {return false}
    if lhs.selectedFields != rhs.selectedFields {return false}
    if lhs.view != rhs.view {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_GetTableRequest.TableMetadataView: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "TABLE_METADATA_VIEW_UNSPECIFIED"),
    1: .same(proto: "BASIC"),
    2: .same(proto: "STORAGE_STATS"),
    3: .same(proto: "FULL"),
  ]
}

extension Google_Cloud_Bigquery_V2_InsertTableRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".InsertTableRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "dataset_id"),
    4: .same(proto: "table"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.datasetID) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._table) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.datasetID.isEmpty {
      try visitor.visitSingularStringField(value: self.datasetID, fieldNumber: 2)
    }
    try { if let v = self._table {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_InsertTableRequest, rhs: Google_Cloud_Bigquery_V2_InsertTableRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.datasetID != rhs.datasetID {return false}
    if lhs._table != rhs._table {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_UpdateOrPatchTableRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".UpdateOrPatchTableRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "dataset_id"),
    3: .standard(proto: "table_id"),
    4: .same(proto: "table"),
    5: .standard(proto: "autodetect_schema"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.datasetID) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.tableID) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._table) }()
      case 5: try { try decoder.decodeSingularBoolField(value: &self.autodetectSchema) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.datasetID.isEmpty {
      try visitor.visitSingularStringField(value: self.datasetID, fieldNumber: 2)
    }
    if !self.tableID.isEmpty {
      try visitor.visitSingularStringField(value: self.tableID, fieldNumber: 3)
    }
    try { if let v = self._table {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    if self.autodetectSchema != false {
      try visitor.visitSingularBoolField(value: self.autodetectSchema, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_UpdateOrPatchTableRequest, rhs: Google_Cloud_Bigquery_V2_UpdateOrPatchTableRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.datasetID != rhs.datasetID {return false}
    if lhs.tableID != rhs.tableID {return false}
    if lhs._table != rhs._table {return false}
    if lhs.autodetectSchema != rhs.autodetectSchema {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_DeleteTableRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".DeleteTableRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "dataset_id"),
    3: .standard(proto: "table_id"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.datasetID) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.tableID) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.datasetID.isEmpty {
      try visitor.visitSingularStringField(value: self.datasetID, fieldNumber: 2)
    }
    if !self.tableID.isEmpty {
      try visitor.visitSingularStringField(value: self.tableID, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_DeleteTableRequest, rhs: Google_Cloud_Bigquery_V2_DeleteTableRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.datasetID != rhs.datasetID {return false}
    if lhs.tableID != rhs.tableID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_ListTablesRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".ListTablesRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "dataset_id"),
    3: .standard(proto: "max_results"),
    4: .standard(proto: "page_token"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.datasetID) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._maxResults) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.pageToken) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.datasetID.isEmpty {
      try visitor.visitSingularStringField(value: self.datasetID, fieldNumber: 2)
    }
    try { if let v = self._maxResults {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    if !self.pageToken.isEmpty {
      try visitor.visitSingularStringField(value: self.pageToken, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_ListTablesRequest, rhs: Google_Cloud_Bigquery_V2_ListTablesRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.datasetID != rhs.datasetID {return false}
    if lhs._maxResults != rhs._maxResults {return false}
    if lhs.pageToken != rhs.pageToken {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_ListFormatView: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".ListFormatView"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "use_legacy_sql"),
    2: .standard(proto: "privacy_policy"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._useLegacySql) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._privacyPolicy) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._useLegacySql {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._privacyPolicy {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_ListFormatView, rhs: Google_Cloud_Bigquery_V2_ListFormatView) -> Bool {
    if lhs._useLegacySql != rhs._useLegacySql {return false}
    if lhs._privacyPolicy != rhs._privacyPolicy {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_ListFormatTable: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".ListFormatTable"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "kind"),
    2: .same(proto: "id"),
    3: .standard(proto: "table_reference"),
    4: .standard(proto: "friendly_name"),
    5: .same(proto: "type"),
    6: .standard(proto: "time_partitioning"),
    12: .standard(proto: "range_partitioning"),
    11: .same(proto: "clustering"),
    7: .same(proto: "labels"),
    8: .same(proto: "view"),
    9: .standard(proto: "creation_time"),
    10: .standard(proto: "expiration_time"),
    14: .standard(proto: "require_partition_filter"),
  ]

  fileprivate class _StorageClass {
    var _kind: String = String()
    var _id: String = String()
    var _tableReference: Google_Cloud_Bigquery_V2_TableReference? = nil
    var _friendlyName: SwiftProtobuf.Google_Protobuf_StringValue? = nil
    var _type: String = String()
    var _timePartitioning: Google_Cloud_Bigquery_V2_TimePartitioning? = nil
    var _rangePartitioning: Google_Cloud_Bigquery_V2_RangePartitioning? = nil
    var _clustering: Google_Cloud_Bigquery_V2_Clustering? = nil
    var _labels: Dictionary<String,String> = [:]
    var _view: Google_Cloud_Bigquery_V2_ListFormatView? = nil
    var _creationTime: Int64 = 0
    var _expirationTime: Int64 = 0
    var _requirePartitionFilter: SwiftProtobuf.Google_Protobuf_BoolValue? = nil

    #if swift(>=5.10)
      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()
    #else
      static let defaultInstance = _StorageClass()
    #endif

    private init() {}

    init(copying source: _StorageClass) {
      _kind = source._kind
      _id = source._id
      _tableReference = source._tableReference
      _friendlyName = source._friendlyName
      _type = source._type
      _timePartitioning = source._timePartitioning
      _rangePartitioning = source._rangePartitioning
      _clustering = source._clustering
      _labels = source._labels
      _view = source._view
      _creationTime = source._creationTime
      _expirationTime = source._expirationTime
      _requirePartitionFilter = source._requirePartitionFilter
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._kind) }()
        case 2: try { try decoder.decodeSingularStringField(value: &_storage._id) }()
        case 3: try { try decoder.decodeSingularMessageField(value: &_storage._tableReference) }()
        case 4: try { try decoder.decodeSingularMessageField(value: &_storage._friendlyName) }()
        case 5: try { try decoder.decodeSingularStringField(value: &_storage._type) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._timePartitioning) }()
        case 7: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &_storage._labels) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._view) }()
        case 9: try { try decoder.decodeSingularInt64Field(value: &_storage._creationTime) }()
        case 10: try { try decoder.decodeSingularInt64Field(value: &_storage._expirationTime) }()
        case 11: try { try decoder.decodeSingularMessageField(value: &_storage._clustering) }()
        case 12: try { try decoder.decodeSingularMessageField(value: &_storage._rangePartitioning) }()
        case 14: try { try decoder.decodeSingularMessageField(value: &_storage._requirePartitionFilter) }()
        default: break
        }
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if !_storage._kind.isEmpty {
        try visitor.visitSingularStringField(value: _storage._kind, fieldNumber: 1)
      }
      if !_storage._id.isEmpty {
        try visitor.visitSingularStringField(value: _storage._id, fieldNumber: 2)
      }
      try { if let v = _storage._tableReference {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      } }()
      try { if let v = _storage._friendlyName {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      } }()
      if !_storage._type.isEmpty {
        try visitor.visitSingularStringField(value: _storage._type, fieldNumber: 5)
      }
      try { if let v = _storage._timePartitioning {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      } }()
      if !_storage._labels.isEmpty {
        try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: _storage._labels, fieldNumber: 7)
      }
      try { if let v = _storage._view {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      } }()
      if _storage._creationTime != 0 {
        try visitor.visitSingularInt64Field(value: _storage._creationTime, fieldNumber: 9)
      }
      if _storage._expirationTime != 0 {
        try visitor.visitSingularInt64Field(value: _storage._expirationTime, fieldNumber: 10)
      }
      try { if let v = _storage._clustering {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
      } }()
      try { if let v = _storage._rangePartitioning {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 12)
      } }()
      try { if let v = _storage._requirePartitionFilter {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 14)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_ListFormatTable, rhs: Google_Cloud_Bigquery_V2_ListFormatTable) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._kind != rhs_storage._kind {return false}
        if _storage._id != rhs_storage._id {return false}
        if _storage._tableReference != rhs_storage._tableReference {return false}
        if _storage._friendlyName != rhs_storage._friendlyName {return false}
        if _storage._type != rhs_storage._type {return false}
        if _storage._timePartitioning != rhs_storage._timePartitioning {return false}
        if _storage._rangePartitioning != rhs_storage._rangePartitioning {return false}
        if _storage._clustering != rhs_storage._clustering {return false}
        if _storage._labels != rhs_storage._labels {return false}
        if _storage._view != rhs_storage._view {return false}
        if _storage._creationTime != rhs_storage._creationTime {return false}
        if _storage._expirationTime != rhs_storage._expirationTime {return false}
        if _storage._requirePartitionFilter != rhs_storage._requirePartitionFilter {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_TableList: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".TableList"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "kind"),
    2: .same(proto: "etag"),
    3: .standard(proto: "next_page_token"),
    4: .same(proto: "tables"),
    5: .standard(proto: "total_items"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.kind) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.etag) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.nextPageToken) }()
      case 4: try { try decoder.decodeRepeatedMessageField(value: &self.tables) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._totalItems) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.kind.isEmpty {
      try visitor.visitSingularStringField(value: self.kind, fieldNumber: 1)
    }
    if !self.etag.isEmpty {
      try visitor.visitSingularStringField(value: self.etag, fieldNumber: 2)
    }
    if !self.nextPageToken.isEmpty {
      try visitor.visitSingularStringField(value: self.nextPageToken, fieldNumber: 3)
    }
    if !self.tables.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.tables, fieldNumber: 4)
    }
    try { if let v = self._totalItems {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_TableList, rhs: Google_Cloud_Bigquery_V2_TableList) -> Bool {
    if lhs.kind != rhs.kind {return false}
    if lhs.etag != rhs.etag {return false}
    if lhs.nextPageToken != rhs.nextPageToken {return false}
    if lhs.tables != rhs.tables {return false}
    if lhs._totalItems != rhs._totalItems {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
