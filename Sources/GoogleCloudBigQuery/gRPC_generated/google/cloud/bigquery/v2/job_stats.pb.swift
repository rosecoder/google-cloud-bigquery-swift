// DO NOT EDIT.
// swift-format-ignore-file
// swiftlint:disable all
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/bigquery/v2/job_stats.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// The type of editions.
/// Different features and behaviors are provided to different editions
/// Capacity commitments and reservations are linked to editions.
package enum Google_Cloud_Bigquery_V2_ReservationEdition: SwiftProtobuf.Enum, Swift.CaseIterable {
  package typealias RawValue = Int

  /// Default value, which will be treated as ENTERPRISE.
  case unspecified // = 0

  /// Standard edition.
  case standard // = 1

  /// Enterprise edition.
  case enterprise // = 2

  /// Enterprise plus edition.
  case enterprisePlus // = 3
  case UNRECOGNIZED(Int)

  package init() {
    self = .unspecified
  }

  package init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .unspecified
    case 1: self = .standard
    case 2: self = .enterprise
    case 3: self = .enterprisePlus
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  package var rawValue: Int {
    switch self {
    case .unspecified: return 0
    case .standard: return 1
    case .enterprise: return 2
    case .enterprisePlus: return 3
    case .UNRECOGNIZED(let i): return i
    }
  }

  // The compiler won't synthesize support with the UNRECOGNIZED case.
  package static let allCases: [Google_Cloud_Bigquery_V2_ReservationEdition] = [
    .unspecified,
    .standard,
    .enterprise,
    .enterprisePlus,
  ]

}

/// An operation within a stage.
package struct Google_Cloud_Bigquery_V2_ExplainQueryStep: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Machine-readable operation type.
  package var kind: String = String()

  /// Human-readable description of the step(s).
  package var substeps: [String] = []

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

/// A single stage of query execution.
package struct Google_Cloud_Bigquery_V2_ExplainQueryStage: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Human-readable name for the stage.
  package var name: String {
    get {return _storage._name}
    set {_uniqueStorage()._name = newValue}
  }

  /// Unique ID for the stage within the plan.
  package var id: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._id ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._id = newValue}
  }
  /// Returns true if `id` has been explicitly set.
  package var hasID: Bool {return _storage._id != nil}
  /// Clears the value of `id`. Subsequent reads from it will return its default value.
  package mutating func clearID() {_uniqueStorage()._id = nil}

  /// Stage start time represented as milliseconds since the epoch.
  package var startMs: Int64 {
    get {return _storage._startMs}
    set {_uniqueStorage()._startMs = newValue}
  }

  /// Stage end time represented as milliseconds since the epoch.
  package var endMs: Int64 {
    get {return _storage._endMs}
    set {_uniqueStorage()._endMs = newValue}
  }

  /// IDs for stages that are inputs to this stage.
  package var inputStages: [Int64] {
    get {return _storage._inputStages}
    set {_uniqueStorage()._inputStages = newValue}
  }

  /// Relative amount of time the average shard spent waiting to be
  /// scheduled.
  package var waitRatioAvg: SwiftProtobuf.Google_Protobuf_DoubleValue {
    get {return _storage._waitRatioAvg ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
    set {_uniqueStorage()._waitRatioAvg = newValue}
  }
  /// Returns true if `waitRatioAvg` has been explicitly set.
  package var hasWaitRatioAvg: Bool {return _storage._waitRatioAvg != nil}
  /// Clears the value of `waitRatioAvg`. Subsequent reads from it will return its default value.
  package mutating func clearWaitRatioAvg() {_uniqueStorage()._waitRatioAvg = nil}

  /// Milliseconds the average shard spent waiting to be scheduled.
  package var waitMsAvg: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._waitMsAvg ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._waitMsAvg = newValue}
  }
  /// Returns true if `waitMsAvg` has been explicitly set.
  package var hasWaitMsAvg: Bool {return _storage._waitMsAvg != nil}
  /// Clears the value of `waitMsAvg`. Subsequent reads from it will return its default value.
  package mutating func clearWaitMsAvg() {_uniqueStorage()._waitMsAvg = nil}

  /// Relative amount of time the slowest shard spent waiting to be
  /// scheduled.
  package var waitRatioMax: SwiftProtobuf.Google_Protobuf_DoubleValue {
    get {return _storage._waitRatioMax ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
    set {_uniqueStorage()._waitRatioMax = newValue}
  }
  /// Returns true if `waitRatioMax` has been explicitly set.
  package var hasWaitRatioMax: Bool {return _storage._waitRatioMax != nil}
  /// Clears the value of `waitRatioMax`. Subsequent reads from it will return its default value.
  package mutating func clearWaitRatioMax() {_uniqueStorage()._waitRatioMax = nil}

  /// Milliseconds the slowest shard spent waiting to be scheduled.
  package var waitMsMax: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._waitMsMax ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._waitMsMax = newValue}
  }
  /// Returns true if `waitMsMax` has been explicitly set.
  package var hasWaitMsMax: Bool {return _storage._waitMsMax != nil}
  /// Clears the value of `waitMsMax`. Subsequent reads from it will return its default value.
  package mutating func clearWaitMsMax() {_uniqueStorage()._waitMsMax = nil}

  /// Relative amount of time the average shard spent reading input.
  package var readRatioAvg: SwiftProtobuf.Google_Protobuf_DoubleValue {
    get {return _storage._readRatioAvg ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
    set {_uniqueStorage()._readRatioAvg = newValue}
  }
  /// Returns true if `readRatioAvg` has been explicitly set.
  package var hasReadRatioAvg: Bool {return _storage._readRatioAvg != nil}
  /// Clears the value of `readRatioAvg`. Subsequent reads from it will return its default value.
  package mutating func clearReadRatioAvg() {_uniqueStorage()._readRatioAvg = nil}

  /// Milliseconds the average shard spent reading input.
  package var readMsAvg: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._readMsAvg ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._readMsAvg = newValue}
  }
  /// Returns true if `readMsAvg` has been explicitly set.
  package var hasReadMsAvg: Bool {return _storage._readMsAvg != nil}
  /// Clears the value of `readMsAvg`. Subsequent reads from it will return its default value.
  package mutating func clearReadMsAvg() {_uniqueStorage()._readMsAvg = nil}

  /// Relative amount of time the slowest shard spent reading input.
  package var readRatioMax: SwiftProtobuf.Google_Protobuf_DoubleValue {
    get {return _storage._readRatioMax ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
    set {_uniqueStorage()._readRatioMax = newValue}
  }
  /// Returns true if `readRatioMax` has been explicitly set.
  package var hasReadRatioMax: Bool {return _storage._readRatioMax != nil}
  /// Clears the value of `readRatioMax`. Subsequent reads from it will return its default value.
  package mutating func clearReadRatioMax() {_uniqueStorage()._readRatioMax = nil}

  /// Milliseconds the slowest shard spent reading input.
  package var readMsMax: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._readMsMax ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._readMsMax = newValue}
  }
  /// Returns true if `readMsMax` has been explicitly set.
  package var hasReadMsMax: Bool {return _storage._readMsMax != nil}
  /// Clears the value of `readMsMax`. Subsequent reads from it will return its default value.
  package mutating func clearReadMsMax() {_uniqueStorage()._readMsMax = nil}

  /// Relative amount of time the average shard spent on CPU-bound tasks.
  package var computeRatioAvg: SwiftProtobuf.Google_Protobuf_DoubleValue {
    get {return _storage._computeRatioAvg ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
    set {_uniqueStorage()._computeRatioAvg = newValue}
  }
  /// Returns true if `computeRatioAvg` has been explicitly set.
  package var hasComputeRatioAvg: Bool {return _storage._computeRatioAvg != nil}
  /// Clears the value of `computeRatioAvg`. Subsequent reads from it will return its default value.
  package mutating func clearComputeRatioAvg() {_uniqueStorage()._computeRatioAvg = nil}

  /// Milliseconds the average shard spent on CPU-bound tasks.
  package var computeMsAvg: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._computeMsAvg ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._computeMsAvg = newValue}
  }
  /// Returns true if `computeMsAvg` has been explicitly set.
  package var hasComputeMsAvg: Bool {return _storage._computeMsAvg != nil}
  /// Clears the value of `computeMsAvg`. Subsequent reads from it will return its default value.
  package mutating func clearComputeMsAvg() {_uniqueStorage()._computeMsAvg = nil}

  /// Relative amount of time the slowest shard spent on CPU-bound tasks.
  package var computeRatioMax: SwiftProtobuf.Google_Protobuf_DoubleValue {
    get {return _storage._computeRatioMax ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
    set {_uniqueStorage()._computeRatioMax = newValue}
  }
  /// Returns true if `computeRatioMax` has been explicitly set.
  package var hasComputeRatioMax: Bool {return _storage._computeRatioMax != nil}
  /// Clears the value of `computeRatioMax`. Subsequent reads from it will return its default value.
  package mutating func clearComputeRatioMax() {_uniqueStorage()._computeRatioMax = nil}

  /// Milliseconds the slowest shard spent on CPU-bound tasks.
  package var computeMsMax: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._computeMsMax ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._computeMsMax = newValue}
  }
  /// Returns true if `computeMsMax` has been explicitly set.
  package var hasComputeMsMax: Bool {return _storage._computeMsMax != nil}
  /// Clears the value of `computeMsMax`. Subsequent reads from it will return its default value.
  package mutating func clearComputeMsMax() {_uniqueStorage()._computeMsMax = nil}

  /// Relative amount of time the average shard spent on writing output.
  package var writeRatioAvg: SwiftProtobuf.Google_Protobuf_DoubleValue {
    get {return _storage._writeRatioAvg ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
    set {_uniqueStorage()._writeRatioAvg = newValue}
  }
  /// Returns true if `writeRatioAvg` has been explicitly set.
  package var hasWriteRatioAvg: Bool {return _storage._writeRatioAvg != nil}
  /// Clears the value of `writeRatioAvg`. Subsequent reads from it will return its default value.
  package mutating func clearWriteRatioAvg() {_uniqueStorage()._writeRatioAvg = nil}

  /// Milliseconds the average shard spent on writing output.
  package var writeMsAvg: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._writeMsAvg ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._writeMsAvg = newValue}
  }
  /// Returns true if `writeMsAvg` has been explicitly set.
  package var hasWriteMsAvg: Bool {return _storage._writeMsAvg != nil}
  /// Clears the value of `writeMsAvg`. Subsequent reads from it will return its default value.
  package mutating func clearWriteMsAvg() {_uniqueStorage()._writeMsAvg = nil}

  /// Relative amount of time the slowest shard spent on writing output.
  package var writeRatioMax: SwiftProtobuf.Google_Protobuf_DoubleValue {
    get {return _storage._writeRatioMax ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
    set {_uniqueStorage()._writeRatioMax = newValue}
  }
  /// Returns true if `writeRatioMax` has been explicitly set.
  package var hasWriteRatioMax: Bool {return _storage._writeRatioMax != nil}
  /// Clears the value of `writeRatioMax`. Subsequent reads from it will return its default value.
  package mutating func clearWriteRatioMax() {_uniqueStorage()._writeRatioMax = nil}

  /// Milliseconds the slowest shard spent on writing output.
  package var writeMsMax: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._writeMsMax ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._writeMsMax = newValue}
  }
  /// Returns true if `writeMsMax` has been explicitly set.
  package var hasWriteMsMax: Bool {return _storage._writeMsMax != nil}
  /// Clears the value of `writeMsMax`. Subsequent reads from it will return its default value.
  package mutating func clearWriteMsMax() {_uniqueStorage()._writeMsMax = nil}

  /// Total number of bytes written to shuffle.
  package var shuffleOutputBytes: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._shuffleOutputBytes ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._shuffleOutputBytes = newValue}
  }
  /// Returns true if `shuffleOutputBytes` has been explicitly set.
  package var hasShuffleOutputBytes: Bool {return _storage._shuffleOutputBytes != nil}
  /// Clears the value of `shuffleOutputBytes`. Subsequent reads from it will return its default value.
  package mutating func clearShuffleOutputBytes() {_uniqueStorage()._shuffleOutputBytes = nil}

  /// Total number of bytes written to shuffle and spilled to disk.
  package var shuffleOutputBytesSpilled: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._shuffleOutputBytesSpilled ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._shuffleOutputBytesSpilled = newValue}
  }
  /// Returns true if `shuffleOutputBytesSpilled` has been explicitly set.
  package var hasShuffleOutputBytesSpilled: Bool {return _storage._shuffleOutputBytesSpilled != nil}
  /// Clears the value of `shuffleOutputBytesSpilled`. Subsequent reads from it will return its default value.
  package mutating func clearShuffleOutputBytesSpilled() {_uniqueStorage()._shuffleOutputBytesSpilled = nil}

  /// Number of records read into the stage.
  package var recordsRead: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._recordsRead ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._recordsRead = newValue}
  }
  /// Returns true if `recordsRead` has been explicitly set.
  package var hasRecordsRead: Bool {return _storage._recordsRead != nil}
  /// Clears the value of `recordsRead`. Subsequent reads from it will return its default value.
  package mutating func clearRecordsRead() {_uniqueStorage()._recordsRead = nil}

  /// Number of records written by the stage.
  package var recordsWritten: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._recordsWritten ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._recordsWritten = newValue}
  }
  /// Returns true if `recordsWritten` has been explicitly set.
  package var hasRecordsWritten: Bool {return _storage._recordsWritten != nil}
  /// Clears the value of `recordsWritten`. Subsequent reads from it will return its default value.
  package mutating func clearRecordsWritten() {_uniqueStorage()._recordsWritten = nil}

  /// Number of parallel input segments to be processed
  package var parallelInputs: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._parallelInputs ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._parallelInputs = newValue}
  }
  /// Returns true if `parallelInputs` has been explicitly set.
  package var hasParallelInputs: Bool {return _storage._parallelInputs != nil}
  /// Clears the value of `parallelInputs`. Subsequent reads from it will return its default value.
  package mutating func clearParallelInputs() {_uniqueStorage()._parallelInputs = nil}

  /// Number of parallel input segments completed.
  package var completedParallelInputs: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._completedParallelInputs ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._completedParallelInputs = newValue}
  }
  /// Returns true if `completedParallelInputs` has been explicitly set.
  package var hasCompletedParallelInputs: Bool {return _storage._completedParallelInputs != nil}
  /// Clears the value of `completedParallelInputs`. Subsequent reads from it will return its default value.
  package mutating func clearCompletedParallelInputs() {_uniqueStorage()._completedParallelInputs = nil}

  /// Current status for this stage.
  package var status: String {
    get {return _storage._status}
    set {_uniqueStorage()._status = newValue}
  }

  /// List of operations within the stage in dependency order (approximately
  /// chronological).
  package var steps: [Google_Cloud_Bigquery_V2_ExplainQueryStep] {
    get {return _storage._steps}
    set {_uniqueStorage()._steps = newValue}
  }

  /// Slot-milliseconds used by the stage.
  package var slotMs: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._slotMs ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._slotMs = newValue}
  }
  /// Returns true if `slotMs` has been explicitly set.
  package var hasSlotMs: Bool {return _storage._slotMs != nil}
  /// Clears the value of `slotMs`. Subsequent reads from it will return its default value.
  package mutating func clearSlotMs() {_uniqueStorage()._slotMs = nil}

  /// Output only. Compute mode for this stage.
  package var computeMode: Google_Cloud_Bigquery_V2_ExplainQueryStage.ComputeMode {
    get {return _storage._computeMode}
    set {_uniqueStorage()._computeMode = newValue}
  }

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Indicates the type of compute mode.
  package enum ComputeMode: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// ComputeMode type not specified.
    case unspecified // = 0

    /// This stage was processed using BigQuery slots.
    case bigquery // = 1

    /// This stage was processed using BI Engine compute.
    case biEngine // = 2
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .bigquery
      case 2: self = .biEngine
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .bigquery: return 1
      case .biEngine: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_ExplainQueryStage.ComputeMode] = [
      .unspecified,
      .bigquery,
      .biEngine,
    ]

  }

  package init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Summary of the state of query execution at a given time.
package struct Google_Cloud_Bigquery_V2_QueryTimelineSample: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Milliseconds elapsed since the start of query execution.
  package var elapsedMs: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _elapsedMs ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_elapsedMs = newValue}
  }
  /// Returns true if `elapsedMs` has been explicitly set.
  package var hasElapsedMs: Bool {return self._elapsedMs != nil}
  /// Clears the value of `elapsedMs`. Subsequent reads from it will return its default value.
  package mutating func clearElapsedMs() {self._elapsedMs = nil}

  /// Cumulative slot-ms consumed by the query.
  package var totalSlotMs: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _totalSlotMs ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_totalSlotMs = newValue}
  }
  /// Returns true if `totalSlotMs` has been explicitly set.
  package var hasTotalSlotMs: Bool {return self._totalSlotMs != nil}
  /// Clears the value of `totalSlotMs`. Subsequent reads from it will return its default value.
  package mutating func clearTotalSlotMs() {self._totalSlotMs = nil}

  /// Total units of work remaining for the query. This number can be revised
  /// (increased or decreased) while the query is running.
  package var pendingUnits: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _pendingUnits ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_pendingUnits = newValue}
  }
  /// Returns true if `pendingUnits` has been explicitly set.
  package var hasPendingUnits: Bool {return self._pendingUnits != nil}
  /// Clears the value of `pendingUnits`. Subsequent reads from it will return its default value.
  package mutating func clearPendingUnits() {self._pendingUnits = nil}

  /// Total parallel units of work completed by this query.
  package var completedUnits: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _completedUnits ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_completedUnits = newValue}
  }
  /// Returns true if `completedUnits` has been explicitly set.
  package var hasCompletedUnits: Bool {return self._completedUnits != nil}
  /// Clears the value of `completedUnits`. Subsequent reads from it will return its default value.
  package mutating func clearCompletedUnits() {self._completedUnits = nil}

  /// Total number of active workers. This does not correspond directly to
  /// slot usage. This is the largest value observed since the last sample.
  package var activeUnits: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _activeUnits ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_activeUnits = newValue}
  }
  /// Returns true if `activeUnits` has been explicitly set.
  package var hasActiveUnits: Bool {return self._activeUnits != nil}
  /// Clears the value of `activeUnits`. Subsequent reads from it will return its default value.
  package mutating func clearActiveUnits() {self._activeUnits = nil}

  /// Units of work that can be scheduled immediately. Providing additional slots
  /// for these units of work will accelerate the query, if no other query in
  /// the reservation needs additional slots.
  package var estimatedRunnableUnits: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _estimatedRunnableUnits ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_estimatedRunnableUnits = newValue}
  }
  /// Returns true if `estimatedRunnableUnits` has been explicitly set.
  package var hasEstimatedRunnableUnits: Bool {return self._estimatedRunnableUnits != nil}
  /// Clears the value of `estimatedRunnableUnits`. Subsequent reads from it will return its default value.
  package mutating func clearEstimatedRunnableUnits() {self._estimatedRunnableUnits = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _elapsedMs: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _totalSlotMs: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _pendingUnits: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _completedUnits: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _activeUnits: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _estimatedRunnableUnits: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
}

/// The external service cost is a portion of the total cost, these costs are not
/// additive with total_bytes_billed. Moreover, this field only track external
/// service costs that will show up as BigQuery costs (e.g. training BigQuery
/// ML job with google cloud CAIP or Automl Tables services), not other costs
/// which may be accrued by running the query (e.g. reading from Bigtable or
/// Cloud Storage). The external service costs with different billing sku (e.g.
/// CAIP job is charged based on VM usage) are converted to BigQuery
/// billed_bytes and slot_ms with equivalent amount of US dollars. Services may
/// not directly correlate to these metrics, but these are the equivalents for
/// billing purposes.
/// Output only.
package struct Google_Cloud_Bigquery_V2_ExternalServiceCost: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// External service name.
  package var externalService: String = String()

  /// External service cost in terms of bigquery bytes processed.
  package var bytesProcessed: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _bytesProcessed ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_bytesProcessed = newValue}
  }
  /// Returns true if `bytesProcessed` has been explicitly set.
  package var hasBytesProcessed: Bool {return self._bytesProcessed != nil}
  /// Clears the value of `bytesProcessed`. Subsequent reads from it will return its default value.
  package mutating func clearBytesProcessed() {self._bytesProcessed = nil}

  /// External service cost in terms of bigquery bytes billed.
  package var bytesBilled: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _bytesBilled ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_bytesBilled = newValue}
  }
  /// Returns true if `bytesBilled` has been explicitly set.
  package var hasBytesBilled: Bool {return self._bytesBilled != nil}
  /// Clears the value of `bytesBilled`. Subsequent reads from it will return its default value.
  package mutating func clearBytesBilled() {self._bytesBilled = nil}

  /// External service cost in terms of bigquery slot milliseconds.
  package var slotMs: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _slotMs ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_slotMs = newValue}
  }
  /// Returns true if `slotMs` has been explicitly set.
  package var hasSlotMs: Bool {return self._slotMs != nil}
  /// Clears the value of `slotMs`. Subsequent reads from it will return its default value.
  package mutating func clearSlotMs() {self._slotMs = nil}

  /// Non-preemptable reserved slots used for external job.
  /// For example, reserved slots for Cloua AI Platform job are the VM usages
  /// converted to BigQuery slot with equivalent mount of price.
  package var reservedSlotCount: Int64 = 0

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _bytesProcessed: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _bytesBilled: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _slotMs: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
}

/// Statistics for the EXPORT DATA statement as part of Query Job. EXTRACT
/// JOB statistics are populated in JobStatistics4.
package struct Google_Cloud_Bigquery_V2_ExportDataStatistics: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Number of destination files generated in case of EXPORT DATA
  /// statement only.
  package var fileCount: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _fileCount ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_fileCount = newValue}
  }
  /// Returns true if `fileCount` has been explicitly set.
  package var hasFileCount: Bool {return self._fileCount != nil}
  /// Clears the value of `fileCount`. Subsequent reads from it will return its default value.
  package mutating func clearFileCount() {self._fileCount = nil}

  /// [Alpha] Number of destination rows generated in case of EXPORT DATA
  /// statement only.
  package var rowCount: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _rowCount ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_rowCount = newValue}
  }
  /// Returns true if `rowCount` has been explicitly set.
  package var hasRowCount: Bool {return self._rowCount != nil}
  /// Clears the value of `rowCount`. Subsequent reads from it will return its default value.
  package mutating func clearRowCount() {self._rowCount = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _fileCount: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _rowCount: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
}

/// Reason why BI Engine didn't accelerate the query (or sub-query).
package struct Google_Cloud_Bigquery_V2_BiEngineReason: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. High-level BI Engine reason for partial or disabled
  /// acceleration
  package var code: Google_Cloud_Bigquery_V2_BiEngineReason.Code = .unspecified

  /// Output only. Free form human-readable reason for partial or disabled
  /// acceleration.
  package var message: String = String()

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Indicates the high-level reason for no/partial acceleration
  package enum Code: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// BiEngineReason not specified.
    case unspecified // = 0

    /// No reservation available for BI Engine acceleration.
    case noReservation // = 1

    /// Not enough memory available for BI Engine acceleration.
    case insufficientReservation // = 2

    /// This particular SQL text is not supported for acceleration by BI Engine.
    case unsupportedSqlText // = 4

    /// Input too large for acceleration by BI Engine.
    case inputTooLarge // = 5

    /// Catch-all code for all other cases for partial or disabled acceleration.
    case otherReason // = 6

    /// One or more tables were not eligible for BI Engine acceleration.
    case tableExcluded // = 7
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .noReservation
      case 2: self = .insufficientReservation
      case 4: self = .unsupportedSqlText
      case 5: self = .inputTooLarge
      case 6: self = .otherReason
      case 7: self = .tableExcluded
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .noReservation: return 1
      case .insufficientReservation: return 2
      case .unsupportedSqlText: return 4
      case .inputTooLarge: return 5
      case .otherReason: return 6
      case .tableExcluded: return 7
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_BiEngineReason.Code] = [
      .unspecified,
      .noReservation,
      .insufficientReservation,
      .unsupportedSqlText,
      .inputTooLarge,
      .otherReason,
      .tableExcluded,
    ]

  }

  package init() {}
}

/// Statistics for a BI Engine specific query.
/// Populated as part of JobStatistics2
package struct Google_Cloud_Bigquery_V2_BiEngineStatistics: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Specifies which mode of BI Engine acceleration was performed
  /// (if any).
  package var biEngineMode: Google_Cloud_Bigquery_V2_BiEngineStatistics.BiEngineMode = .accelerationModeUnspecified

  /// Output only. Specifies which mode of BI Engine acceleration was performed
  /// (if any).
  package var accelerationMode: Google_Cloud_Bigquery_V2_BiEngineStatistics.BiEngineAccelerationMode = .unspecified

  /// In case of DISABLED or PARTIAL bi_engine_mode, these contain the
  /// explanatory reasons as to why BI Engine could not accelerate.
  /// In case the full query was accelerated, this field is not populated.
  package var biEngineReasons: [Google_Cloud_Bigquery_V2_BiEngineReason] = []

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Indicates the type of BI Engine acceleration.
  package enum BiEngineMode: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// BiEngineMode type not specified.
    case accelerationModeUnspecified // = 0

    /// BI Engine disabled the acceleration. bi_engine_reasons
    /// specifies a more detailed reason.
    case disabled // = 1

    /// Part of the query was accelerated using BI Engine.
    /// See bi_engine_reasons for why parts of the query were not
    /// accelerated.
    case partial // = 2

    /// All of the query was accelerated using BI Engine.
    case full // = 3
    case UNRECOGNIZED(Int)

    package init() {
      self = .accelerationModeUnspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .accelerationModeUnspecified
      case 1: self = .disabled
      case 2: self = .partial
      case 3: self = .full
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .accelerationModeUnspecified: return 0
      case .disabled: return 1
      case .partial: return 2
      case .full: return 3
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_BiEngineStatistics.BiEngineMode] = [
      .accelerationModeUnspecified,
      .disabled,
      .partial,
      .full,
    ]

  }

  /// Indicates the type of BI Engine acceleration.
  package enum BiEngineAccelerationMode: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// BiEngineMode type not specified.
    case unspecified // = 0

    /// BI Engine acceleration was attempted but disabled. bi_engine_reasons
    /// specifies a more detailed reason.
    case biEngineDisabled // = 1

    /// Some inputs were accelerated using BI Engine.
    /// See bi_engine_reasons for why parts of the query were not
    /// accelerated.
    case partialInput // = 2

    /// All of the query inputs were accelerated using BI Engine.
    case fullInput // = 3

    /// All of the query was accelerated using BI Engine.
    case fullQuery // = 4
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .biEngineDisabled
      case 2: self = .partialInput
      case 3: self = .fullInput
      case 4: self = .fullQuery
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .biEngineDisabled: return 1
      case .partialInput: return 2
      case .fullInput: return 3
      case .fullQuery: return 4
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_BiEngineStatistics.BiEngineAccelerationMode] = [
      .unspecified,
      .biEngineDisabled,
      .partialInput,
      .fullInput,
      .fullQuery,
    ]

  }

  package init() {}
}

/// Reason about why no search index was used in the search query (or
/// sub-query).
package struct Google_Cloud_Bigquery_V2_IndexUnusedReason: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Specifies the high-level reason for the scenario when no search index was
  /// used.
  package var code: Google_Cloud_Bigquery_V2_IndexUnusedReason.Code {
    get {return _code ?? .unspecified}
    set {_code = newValue}
  }
  /// Returns true if `code` has been explicitly set.
  package var hasCode: Bool {return self._code != nil}
  /// Clears the value of `code`. Subsequent reads from it will return its default value.
  package mutating func clearCode() {self._code = nil}

  /// Free form human-readable reason for the scenario when no search index was
  /// used.
  package var message: String {
    get {return _message ?? String()}
    set {_message = newValue}
  }
  /// Returns true if `message` has been explicitly set.
  package var hasMessage: Bool {return self._message != nil}
  /// Clears the value of `message`. Subsequent reads from it will return its default value.
  package mutating func clearMessage() {self._message = nil}

  /// Specifies the base table involved in the reason that no search index was
  /// used.
  package var baseTable: Google_Cloud_Bigquery_V2_TableReference {
    get {return _baseTable ?? Google_Cloud_Bigquery_V2_TableReference()}
    set {_baseTable = newValue}
  }
  /// Returns true if `baseTable` has been explicitly set.
  package var hasBaseTable: Bool {return self._baseTable != nil}
  /// Clears the value of `baseTable`. Subsequent reads from it will return its default value.
  package mutating func clearBaseTable() {self._baseTable = nil}

  /// Specifies the name of the unused search index, if available.
  package var indexName: String {
    get {return _indexName ?? String()}
    set {_indexName = newValue}
  }
  /// Returns true if `indexName` has been explicitly set.
  package var hasIndexName: Bool {return self._indexName != nil}
  /// Clears the value of `indexName`. Subsequent reads from it will return its default value.
  package mutating func clearIndexName() {self._indexName = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Indicates the high-level reason for the scenario when no search index was
  /// used.
  package enum Code: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Code not specified.
    case unspecified // = 0

    /// Indicates the search index configuration has not been created.
    case indexConfigNotAvailable // = 1

    /// Indicates the search index creation has not been completed.
    case pendingIndexCreation // = 2

    /// Indicates the base table has been truncated (rows have been removed
    /// from table with TRUNCATE TABLE statement) since the last time the search
    /// index was refreshed.
    case baseTableTruncated // = 3

    /// Indicates the search index configuration has been changed since the last
    /// time the search index was refreshed.
    case indexConfigModified // = 4

    /// Indicates the search query accesses data at a timestamp before the last
    /// time the search index was refreshed.
    case timeTravelQuery // = 5

    /// Indicates the usage of search index will not contribute to any pruning
    /// improvement for the search function, e.g. when the search predicate is in
    /// a disjunction with other non-search predicates.
    case noPruningPower // = 6

    /// Indicates the search index does not cover all fields in the search
    /// function.
    case unindexedSearchFields // = 7

    /// Indicates the search index does not support the given search query
    /// pattern.
    case unsupportedSearchPattern // = 8

    /// Indicates the query has been optimized by using a materialized view.
    case optimizedWithMaterializedView // = 9

    /// Indicates the query has been secured by data masking, and thus search
    /// indexes are not applicable.
    case securedByDataMasking // = 11

    /// Indicates that the search index and the search function call do not
    /// have the same text analyzer.
    case mismatchedTextAnalyzer // = 12

    /// Indicates the base table is too small (below a certain threshold).
    /// The index does not provide noticeable search performance gains
    /// when the base table is too small.
    case baseTableTooSmall // = 13

    /// Indicates that the total size of indexed base tables in your organization
    /// exceeds your region's limit and the index is not used in the query. To
    /// index larger base tables, you can
    /// <a
    /// href="https://cloud.google.com/bigquery/docs/search-index#use_your_own_reservation">use
    /// your own reservation</a> for index-management jobs.
    case baseTableTooLarge // = 14

    /// Indicates that the estimated performance gain from using the search index
    /// is too low for the given search query.
    case estimatedPerformanceGainTooLow // = 15

    /// Indicates that search indexes can not be used for search query with
    /// STANDARD edition.
    case notSupportedInStandardEdition // = 17

    /// Indicates that an option in the search function that cannot make use of
    /// the index has been selected.
    case indexSuppressedByFunctionOption // = 18

    /// Indicates that the query was cached, and thus the search index was not
    /// used.
    case queryCacheHit // = 19

    /// The index cannot be used in the search query because it is stale.
    case staleIndex // = 20

    /// Indicates an internal error that causes the search index to be unused.
    case internalError // = 10

    /// Indicates that the reason search indexes cannot be used in the query is
    /// not covered by any of the other IndexUnusedReason options.
    case otherReason // = 16
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .indexConfigNotAvailable
      case 2: self = .pendingIndexCreation
      case 3: self = .baseTableTruncated
      case 4: self = .indexConfigModified
      case 5: self = .timeTravelQuery
      case 6: self = .noPruningPower
      case 7: self = .unindexedSearchFields
      case 8: self = .unsupportedSearchPattern
      case 9: self = .optimizedWithMaterializedView
      case 10: self = .internalError
      case 11: self = .securedByDataMasking
      case 12: self = .mismatchedTextAnalyzer
      case 13: self = .baseTableTooSmall
      case 14: self = .baseTableTooLarge
      case 15: self = .estimatedPerformanceGainTooLow
      case 16: self = .otherReason
      case 17: self = .notSupportedInStandardEdition
      case 18: self = .indexSuppressedByFunctionOption
      case 19: self = .queryCacheHit
      case 20: self = .staleIndex
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .indexConfigNotAvailable: return 1
      case .pendingIndexCreation: return 2
      case .baseTableTruncated: return 3
      case .indexConfigModified: return 4
      case .timeTravelQuery: return 5
      case .noPruningPower: return 6
      case .unindexedSearchFields: return 7
      case .unsupportedSearchPattern: return 8
      case .optimizedWithMaterializedView: return 9
      case .internalError: return 10
      case .securedByDataMasking: return 11
      case .mismatchedTextAnalyzer: return 12
      case .baseTableTooSmall: return 13
      case .baseTableTooLarge: return 14
      case .estimatedPerformanceGainTooLow: return 15
      case .otherReason: return 16
      case .notSupportedInStandardEdition: return 17
      case .indexSuppressedByFunctionOption: return 18
      case .queryCacheHit: return 19
      case .staleIndex: return 20
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_IndexUnusedReason.Code] = [
      .unspecified,
      .indexConfigNotAvailable,
      .pendingIndexCreation,
      .baseTableTruncated,
      .indexConfigModified,
      .timeTravelQuery,
      .noPruningPower,
      .unindexedSearchFields,
      .unsupportedSearchPattern,
      .optimizedWithMaterializedView,
      .securedByDataMasking,
      .mismatchedTextAnalyzer,
      .baseTableTooSmall,
      .baseTableTooLarge,
      .estimatedPerformanceGainTooLow,
      .notSupportedInStandardEdition,
      .indexSuppressedByFunctionOption,
      .queryCacheHit,
      .staleIndex,
      .internalError,
      .otherReason,
    ]

  }

  package init() {}

  fileprivate var _code: Google_Cloud_Bigquery_V2_IndexUnusedReason.Code? = nil
  fileprivate var _message: String? = nil
  fileprivate var _baseTable: Google_Cloud_Bigquery_V2_TableReference? = nil
  fileprivate var _indexName: String? = nil
}

/// Statistics for a search query.
/// Populated as part of JobStatistics2.
package struct Google_Cloud_Bigquery_V2_SearchStatistics: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Specifies the index usage mode for the query.
  package var indexUsageMode: Google_Cloud_Bigquery_V2_SearchStatistics.IndexUsageMode = .unspecified

  /// When `indexUsageMode` is `UNUSED` or `PARTIALLY_USED`, this field explains
  /// why indexes were not used in all or part of the search query. If
  /// `indexUsageMode` is `FULLY_USED`, this field is not populated.
  package var indexUnusedReasons: [Google_Cloud_Bigquery_V2_IndexUnusedReason] = []

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Indicates the type of search index usage in the entire search query.
  package enum IndexUsageMode: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Index usage mode not specified.
    case unspecified // = 0

    /// No search indexes were used in the search query. See
    /// [`indexUnusedReasons`]
    /// (/bigquery/docs/reference/rest/v2/Job#IndexUnusedReason)
    /// for detailed reasons.
    case unused // = 1

    /// Part of the search query used search indexes. See [`indexUnusedReasons`]
    /// (/bigquery/docs/reference/rest/v2/Job#IndexUnusedReason)
    /// for why other parts of the query did not use search indexes.
    case partiallyUsed // = 2

    /// The entire search query used search indexes.
    case fullyUsed // = 4
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .unused
      case 2: self = .partiallyUsed
      case 4: self = .fullyUsed
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .unused: return 1
      case .partiallyUsed: return 2
      case .fullyUsed: return 4
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_SearchStatistics.IndexUsageMode] = [
      .unspecified,
      .unused,
      .partiallyUsed,
      .fullyUsed,
    ]

  }

  package init() {}
}

/// Statistics for a vector search query.
/// Populated as part of JobStatistics2.
package struct Google_Cloud_Bigquery_V2_VectorSearchStatistics: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Specifies the index usage mode for the query.
  package var indexUsageMode: Google_Cloud_Bigquery_V2_VectorSearchStatistics.IndexUsageMode = .unspecified

  /// When `indexUsageMode` is `UNUSED` or `PARTIALLY_USED`, this field explains
  /// why indexes were not used in all or part of the vector search query. If
  /// `indexUsageMode` is `FULLY_USED`, this field is not populated.
  package var indexUnusedReasons: [Google_Cloud_Bigquery_V2_IndexUnusedReason] = []

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Indicates the type of vector index usage in the entire vector search query.
  package enum IndexUsageMode: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Index usage mode not specified.
    case unspecified // = 0

    /// No vector indexes were used in the vector search query. See
    /// [`indexUnusedReasons`]
    /// (/bigquery/docs/reference/rest/v2/Job#IndexUnusedReason)
    /// for detailed reasons.
    case unused // = 1

    /// Part of the vector search query used vector indexes. See
    /// [`indexUnusedReasons`]
    /// (/bigquery/docs/reference/rest/v2/Job#IndexUnusedReason)
    /// for why other parts of the query did not use vector indexes.
    case partiallyUsed // = 2

    /// The entire vector search query used vector indexes.
    case fullyUsed // = 4
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .unused
      case 2: self = .partiallyUsed
      case 4: self = .fullyUsed
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .unused: return 1
      case .partiallyUsed: return 2
      case .fullyUsed: return 4
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_VectorSearchStatistics.IndexUsageMode] = [
      .unspecified,
      .unused,
      .partiallyUsed,
      .fullyUsed,
    ]

  }

  package init() {}
}

/// Query optimization information for a QUERY job.
package struct Google_Cloud_Bigquery_V2_QueryInfo: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Information about query optimizations.
  package var optimizationDetails: SwiftProtobuf.Google_Protobuf_Struct {
    get {return _optimizationDetails ?? SwiftProtobuf.Google_Protobuf_Struct()}
    set {_optimizationDetails = newValue}
  }
  /// Returns true if `optimizationDetails` has been explicitly set.
  package var hasOptimizationDetails: Bool {return self._optimizationDetails != nil}
  /// Clears the value of `optimizationDetails`. Subsequent reads from it will return its default value.
  package mutating func clearOptimizationDetails() {self._optimizationDetails = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _optimizationDetails: SwiftProtobuf.Google_Protobuf_Struct? = nil
}

/// Statistics for a LOAD query.
package struct Google_Cloud_Bigquery_V2_LoadQueryStatistics: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Number of source files in a LOAD query.
  package var inputFiles: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _inputFiles ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_inputFiles = newValue}
  }
  /// Returns true if `inputFiles` has been explicitly set.
  package var hasInputFiles: Bool {return self._inputFiles != nil}
  /// Clears the value of `inputFiles`. Subsequent reads from it will return its default value.
  package mutating func clearInputFiles() {self._inputFiles = nil}

  /// Output only. Number of bytes of source data in a LOAD query.
  package var inputFileBytes: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _inputFileBytes ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_inputFileBytes = newValue}
  }
  /// Returns true if `inputFileBytes` has been explicitly set.
  package var hasInputFileBytes: Bool {return self._inputFileBytes != nil}
  /// Clears the value of `inputFileBytes`. Subsequent reads from it will return its default value.
  package mutating func clearInputFileBytes() {self._inputFileBytes = nil}

  /// Output only. Number of rows imported in a LOAD query.
  /// Note that while a LOAD query is in the running state, this value may
  /// change.
  package var outputRows: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _outputRows ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_outputRows = newValue}
  }
  /// Returns true if `outputRows` has been explicitly set.
  package var hasOutputRows: Bool {return self._outputRows != nil}
  /// Clears the value of `outputRows`. Subsequent reads from it will return its default value.
  package mutating func clearOutputRows() {self._outputRows = nil}

  /// Output only. Size of the loaded data in bytes. Note that while a LOAD query
  /// is in the running state, this value may change.
  package var outputBytes: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _outputBytes ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_outputBytes = newValue}
  }
  /// Returns true if `outputBytes` has been explicitly set.
  package var hasOutputBytes: Bool {return self._outputBytes != nil}
  /// Clears the value of `outputBytes`. Subsequent reads from it will return its default value.
  package mutating func clearOutputBytes() {self._outputBytes = nil}

  /// Output only. The number of bad records encountered while processing a LOAD
  /// query. Note that if the job has failed because of more bad records
  /// encountered than the maximum allowed in the load job configuration, then
  /// this number can be less than the total number of bad records present in the
  /// input data.
  package var badRecords: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _badRecords ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_badRecords = newValue}
  }
  /// Returns true if `badRecords` has been explicitly set.
  package var hasBadRecords: Bool {return self._badRecords != nil}
  /// Clears the value of `badRecords`. Subsequent reads from it will return its default value.
  package mutating func clearBadRecords() {self._badRecords = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _inputFiles: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _inputFileBytes: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _outputRows: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _outputBytes: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _badRecords: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
}

/// Statistics for a query job.
package struct Google_Cloud_Bigquery_V2_JobStatistics2: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Describes execution plan for the query.
  package var queryPlan: [Google_Cloud_Bigquery_V2_ExplainQueryStage] {
    get {return _storage._queryPlan}
    set {_uniqueStorage()._queryPlan = newValue}
  }

  /// Output only. The original estimate of bytes processed for the job.
  package var estimatedBytesProcessed: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._estimatedBytesProcessed ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._estimatedBytesProcessed = newValue}
  }
  /// Returns true if `estimatedBytesProcessed` has been explicitly set.
  package var hasEstimatedBytesProcessed: Bool {return _storage._estimatedBytesProcessed != nil}
  /// Clears the value of `estimatedBytesProcessed`. Subsequent reads from it will return its default value.
  package mutating func clearEstimatedBytesProcessed() {_uniqueStorage()._estimatedBytesProcessed = nil}

  /// Output only. Describes a timeline of job execution.
  package var timeline: [Google_Cloud_Bigquery_V2_QueryTimelineSample] {
    get {return _storage._timeline}
    set {_uniqueStorage()._timeline = newValue}
  }

  /// Output only. Total number of partitions processed from all partitioned
  /// tables referenced in the job.
  package var totalPartitionsProcessed: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._totalPartitionsProcessed ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._totalPartitionsProcessed = newValue}
  }
  /// Returns true if `totalPartitionsProcessed` has been explicitly set.
  package var hasTotalPartitionsProcessed: Bool {return _storage._totalPartitionsProcessed != nil}
  /// Clears the value of `totalPartitionsProcessed`. Subsequent reads from it will return its default value.
  package mutating func clearTotalPartitionsProcessed() {_uniqueStorage()._totalPartitionsProcessed = nil}

  /// Output only. Total bytes processed for the job.
  package var totalBytesProcessed: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._totalBytesProcessed ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._totalBytesProcessed = newValue}
  }
  /// Returns true if `totalBytesProcessed` has been explicitly set.
  package var hasTotalBytesProcessed: Bool {return _storage._totalBytesProcessed != nil}
  /// Clears the value of `totalBytesProcessed`. Subsequent reads from it will return its default value.
  package mutating func clearTotalBytesProcessed() {_uniqueStorage()._totalBytesProcessed = nil}

  /// Output only. For dry-run jobs, totalBytesProcessed is an estimate and this
  /// field specifies the accuracy of the estimate. Possible values can be:
  /// UNKNOWN: accuracy of the estimate is unknown.
  /// PRECISE: estimate is precise.
  /// LOWER_BOUND: estimate is lower bound of what the query would cost.
  /// UPPER_BOUND: estimate is upper bound of what the query would cost.
  package var totalBytesProcessedAccuracy: String {
    get {return _storage._totalBytesProcessedAccuracy}
    set {_uniqueStorage()._totalBytesProcessedAccuracy = newValue}
  }

  /// Output only. If the project is configured to use on-demand pricing,
  /// then this field contains the total bytes billed for the job.
  /// If the project is configured to use flat-rate pricing, then you are
  /// not billed for bytes and this field is informational only.
  package var totalBytesBilled: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._totalBytesBilled ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._totalBytesBilled = newValue}
  }
  /// Returns true if `totalBytesBilled` has been explicitly set.
  package var hasTotalBytesBilled: Bool {return _storage._totalBytesBilled != nil}
  /// Clears the value of `totalBytesBilled`. Subsequent reads from it will return its default value.
  package mutating func clearTotalBytesBilled() {_uniqueStorage()._totalBytesBilled = nil}

  /// Output only. Billing tier for the job. This is a BigQuery-specific concept
  /// which is not related to the Google Cloud notion of "free tier". The value
  /// here is a measure of the query's resource consumption relative to the
  /// amount of data scanned. For on-demand queries, the limit is 100, and all
  /// queries within this limit are billed at the standard on-demand rates.
  /// On-demand queries that exceed this limit will fail with a
  /// billingTierLimitExceeded error.
  package var billingTier: SwiftProtobuf.Google_Protobuf_Int32Value {
    get {return _storage._billingTier ?? SwiftProtobuf.Google_Protobuf_Int32Value()}
    set {_uniqueStorage()._billingTier = newValue}
  }
  /// Returns true if `billingTier` has been explicitly set.
  package var hasBillingTier: Bool {return _storage._billingTier != nil}
  /// Clears the value of `billingTier`. Subsequent reads from it will return its default value.
  package mutating func clearBillingTier() {_uniqueStorage()._billingTier = nil}

  /// Output only. Slot-milliseconds for the job.
  package var totalSlotMs: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._totalSlotMs ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._totalSlotMs = newValue}
  }
  /// Returns true if `totalSlotMs` has been explicitly set.
  package var hasTotalSlotMs: Bool {return _storage._totalSlotMs != nil}
  /// Clears the value of `totalSlotMs`. Subsequent reads from it will return its default value.
  package mutating func clearTotalSlotMs() {_uniqueStorage()._totalSlotMs = nil}

  /// Output only. Whether the query result was fetched from the query cache.
  package var cacheHit: SwiftProtobuf.Google_Protobuf_BoolValue {
    get {return _storage._cacheHit ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
    set {_uniqueStorage()._cacheHit = newValue}
  }
  /// Returns true if `cacheHit` has been explicitly set.
  package var hasCacheHit: Bool {return _storage._cacheHit != nil}
  /// Clears the value of `cacheHit`. Subsequent reads from it will return its default value.
  package mutating func clearCacheHit() {_uniqueStorage()._cacheHit = nil}

  /// Output only. Referenced tables for the job. Queries that reference more
  /// than 50 tables will not have a complete list.
  package var referencedTables: [Google_Cloud_Bigquery_V2_TableReference] {
    get {return _storage._referencedTables}
    set {_uniqueStorage()._referencedTables = newValue}
  }

  /// Output only. Referenced routines for the job.
  package var referencedRoutines: [Google_Cloud_Bigquery_V2_RoutineReference] {
    get {return _storage._referencedRoutines}
    set {_uniqueStorage()._referencedRoutines = newValue}
  }

  /// Output only. The schema of the results. Present only for successful dry
  /// run of non-legacy SQL queries.
  package var schema: Google_Cloud_Bigquery_V2_TableSchema {
    get {return _storage._schema ?? Google_Cloud_Bigquery_V2_TableSchema()}
    set {_uniqueStorage()._schema = newValue}
  }
  /// Returns true if `schema` has been explicitly set.
  package var hasSchema: Bool {return _storage._schema != nil}
  /// Clears the value of `schema`. Subsequent reads from it will return its default value.
  package mutating func clearSchema() {_uniqueStorage()._schema = nil}

  /// Output only. The number of rows affected by a DML statement. Present
  /// only for DML statements INSERT, UPDATE or DELETE.
  package var numDmlAffectedRows: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._numDmlAffectedRows ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._numDmlAffectedRows = newValue}
  }
  /// Returns true if `numDmlAffectedRows` has been explicitly set.
  package var hasNumDmlAffectedRows: Bool {return _storage._numDmlAffectedRows != nil}
  /// Clears the value of `numDmlAffectedRows`. Subsequent reads from it will return its default value.
  package mutating func clearNumDmlAffectedRows() {_uniqueStorage()._numDmlAffectedRows = nil}

  /// Output only. Detailed statistics for DML statements INSERT, UPDATE, DELETE,
  /// MERGE or TRUNCATE.
  package var dmlStats: Google_Cloud_Bigquery_V2_DmlStats {
    get {return _storage._dmlStats ?? Google_Cloud_Bigquery_V2_DmlStats()}
    set {_uniqueStorage()._dmlStats = newValue}
  }
  /// Returns true if `dmlStats` has been explicitly set.
  package var hasDmlStats: Bool {return _storage._dmlStats != nil}
  /// Clears the value of `dmlStats`. Subsequent reads from it will return its default value.
  package mutating func clearDmlStats() {_uniqueStorage()._dmlStats = nil}

  /// Output only. GoogleSQL only: list of undeclared query
  /// parameters detected during a dry run validation.
  package var undeclaredQueryParameters: [Google_Cloud_Bigquery_V2_QueryParameter] {
    get {return _storage._undeclaredQueryParameters}
    set {_uniqueStorage()._undeclaredQueryParameters = newValue}
  }

  /// Output only. The type of query statement, if valid.
  /// Possible values:
  ///
  /// * `SELECT`:
  /// [`SELECT`](https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#select_list)
  /// statement.
  /// * `ASSERT`:
  /// [`ASSERT`](https://cloud.google.com/bigquery/docs/reference/standard-sql/debugging-statements#assert)
  /// statement.
  /// * `INSERT`:
  /// [`INSERT`](https://cloud.google.com/bigquery/docs/reference/standard-sql/dml-syntax#insert_statement)
  /// statement.
  /// * `UPDATE`:
  /// [`UPDATE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#update_statement)
  /// statement.
  /// * `DELETE`:
  /// [`DELETE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-manipulation-language)
  /// statement.
  /// * `MERGE`:
  /// [`MERGE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-manipulation-language)
  /// statement.
  /// * `CREATE_TABLE`: [`CREATE
  /// TABLE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_table_statement)
  /// statement, without `AS SELECT`.
  /// * `CREATE_TABLE_AS_SELECT`: [`CREATE TABLE AS
  /// SELECT`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#query_statement)
  /// statement.
  /// * `CREATE_VIEW`: [`CREATE
  /// VIEW`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_view_statement)
  /// statement.
  /// * `CREATE_MODEL`: [`CREATE
  /// MODEL`](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create#create_model_statement)
  /// statement.
  /// * `CREATE_MATERIALIZED_VIEW`: [`CREATE MATERIALIZED
  /// VIEW`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_materialized_view_statement)
  /// statement.
  /// * `CREATE_FUNCTION`: [`CREATE
  /// FUNCTION`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_function_statement)
  /// statement.
  /// * `CREATE_TABLE_FUNCTION`: [`CREATE TABLE
  /// FUNCTION`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_table_function_statement)
  /// statement.
  /// * `CREATE_PROCEDURE`: [`CREATE
  /// PROCEDURE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_procedure)
  /// statement.
  /// * `CREATE_ROW_ACCESS_POLICY`: [`CREATE ROW ACCESS
  /// POLICY`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_row_access_policy_statement)
  /// statement.
  /// * `CREATE_SCHEMA`: [`CREATE
  /// SCHEMA`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_schema_statement)
  /// statement.
  /// * `CREATE_SNAPSHOT_TABLE`: [`CREATE SNAPSHOT
  /// TABLE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_snapshot_table_statement)
  /// statement.
  /// * `CREATE_SEARCH_INDEX`: [`CREATE SEARCH
  /// INDEX`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_search_index_statement)
  /// statement.
  /// * `DROP_TABLE`: [`DROP
  /// TABLE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_table_statement)
  /// statement.
  /// * `DROP_EXTERNAL_TABLE`: [`DROP EXTERNAL
  /// TABLE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_external_table_statement)
  /// statement.
  /// * `DROP_VIEW`: [`DROP
  /// VIEW`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_view_statement)
  /// statement.
  /// * `DROP_MODEL`: [`DROP
  /// MODEL`](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-drop-model)
  /// statement.
  /// * `DROP_MATERIALIZED_VIEW`: [`DROP MATERIALIZED
  ///  VIEW`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_materialized_view_statement)
  /// statement.
  /// * `DROP_FUNCTION` : [`DROP
  /// FUNCTION`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_function_statement)
  /// statement.
  /// * `DROP_TABLE_FUNCTION` : [`DROP TABLE
  /// FUNCTION`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_table_function)
  /// statement.
  /// * `DROP_PROCEDURE`: [`DROP
  /// PROCEDURE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_procedure_statement)
  /// statement.
  /// * `DROP_SEARCH_INDEX`: [`DROP SEARCH
  /// INDEX`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_search_index)
  /// statement.
  /// * `DROP_SCHEMA`: [`DROP
  /// SCHEMA`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_schema_statement)
  /// statement.
  /// * `DROP_SNAPSHOT_TABLE`: [`DROP SNAPSHOT
  /// TABLE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_snapshot_table_statement)
  /// statement.
  /// * `DROP_ROW_ACCESS_POLICY`: [`DROP [ALL] ROW ACCESS
  /// POLICY|POLICIES`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_row_access_policy_statement)
  /// statement.
  /// * `ALTER_TABLE`: [`ALTER
  /// TABLE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#alter_table_set_options_statement)
  /// statement.
  /// * `ALTER_VIEW`: [`ALTER
  /// VIEW`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#alter_view_set_options_statement)
  /// statement.
  /// * `ALTER_MATERIALIZED_VIEW`: [`ALTER MATERIALIZED
  /// VIEW`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#alter_materialized_view_set_options_statement)
  /// statement.
  /// * `ALTER_SCHEMA`: [`ALTER
  /// SCHEMA`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#aalter_schema_set_options_statement)
  /// statement.
  /// * `SCRIPT`:
  /// [`SCRIPT`](https://cloud.google.com/bigquery/docs/reference/standard-sql/procedural-language).
  /// * `TRUNCATE_TABLE`: [`TRUNCATE
  /// TABLE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/dml-syntax#truncate_table_statement)
  /// statement.
  /// * `CREATE_EXTERNAL_TABLE`: [`CREATE EXTERNAL
  /// TABLE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_external_table_statement)
  /// statement.
  /// * `EXPORT_DATA`: [`EXPORT
  /// DATA`](https://cloud.google.com/bigquery/docs/reference/standard-sql/other-statements#export_data_statement)
  /// statement.
  /// * `EXPORT_MODEL`: [`EXPORT
  /// MODEL`](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-export-model)
  /// statement.
  /// * `LOAD_DATA`: [`LOAD
  /// DATA`](https://cloud.google.com/bigquery/docs/reference/standard-sql/other-statements#load_data_statement)
  /// statement.
  /// * `CALL`:
  /// [`CALL`](https://cloud.google.com/bigquery/docs/reference/standard-sql/procedural-language#call)
  /// statement.
  package var statementType: String {
    get {return _storage._statementType}
    set {_uniqueStorage()._statementType = newValue}
  }

  /// Output only. The DDL operation performed, possibly
  /// dependent on the pre-existence of the DDL target.
  package var ddlOperationPerformed: String {
    get {return _storage._ddlOperationPerformed}
    set {_uniqueStorage()._ddlOperationPerformed = newValue}
  }

  /// Output only. The DDL target table. Present only for
  /// CREATE/DROP TABLE/VIEW and DROP ALL ROW ACCESS POLICIES queries.
  package var ddlTargetTable: Google_Cloud_Bigquery_V2_TableReference {
    get {return _storage._ddlTargetTable ?? Google_Cloud_Bigquery_V2_TableReference()}
    set {_uniqueStorage()._ddlTargetTable = newValue}
  }
  /// Returns true if `ddlTargetTable` has been explicitly set.
  package var hasDdlTargetTable: Bool {return _storage._ddlTargetTable != nil}
  /// Clears the value of `ddlTargetTable`. Subsequent reads from it will return its default value.
  package mutating func clearDdlTargetTable() {_uniqueStorage()._ddlTargetTable = nil}

  /// Output only. The table after rename. Present only for ALTER TABLE RENAME TO
  /// query.
  package var ddlDestinationTable: Google_Cloud_Bigquery_V2_TableReference {
    get {return _storage._ddlDestinationTable ?? Google_Cloud_Bigquery_V2_TableReference()}
    set {_uniqueStorage()._ddlDestinationTable = newValue}
  }
  /// Returns true if `ddlDestinationTable` has been explicitly set.
  package var hasDdlDestinationTable: Bool {return _storage._ddlDestinationTable != nil}
  /// Clears the value of `ddlDestinationTable`. Subsequent reads from it will return its default value.
  package mutating func clearDdlDestinationTable() {_uniqueStorage()._ddlDestinationTable = nil}

  /// Output only. The DDL target row access policy. Present only for
  /// CREATE/DROP ROW ACCESS POLICY queries.
  package var ddlTargetRowAccessPolicy: Google_Cloud_Bigquery_V2_RowAccessPolicyReference {
    get {return _storage._ddlTargetRowAccessPolicy ?? Google_Cloud_Bigquery_V2_RowAccessPolicyReference()}
    set {_uniqueStorage()._ddlTargetRowAccessPolicy = newValue}
  }
  /// Returns true if `ddlTargetRowAccessPolicy` has been explicitly set.
  package var hasDdlTargetRowAccessPolicy: Bool {return _storage._ddlTargetRowAccessPolicy != nil}
  /// Clears the value of `ddlTargetRowAccessPolicy`. Subsequent reads from it will return its default value.
  package mutating func clearDdlTargetRowAccessPolicy() {_uniqueStorage()._ddlTargetRowAccessPolicy = nil}

  /// Output only. The number of row access policies affected by a DDL statement.
  /// Present only for DROP ALL ROW ACCESS POLICIES queries.
  package var ddlAffectedRowAccessPolicyCount: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._ddlAffectedRowAccessPolicyCount ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._ddlAffectedRowAccessPolicyCount = newValue}
  }
  /// Returns true if `ddlAffectedRowAccessPolicyCount` has been explicitly set.
  package var hasDdlAffectedRowAccessPolicyCount: Bool {return _storage._ddlAffectedRowAccessPolicyCount != nil}
  /// Clears the value of `ddlAffectedRowAccessPolicyCount`. Subsequent reads from it will return its default value.
  package mutating func clearDdlAffectedRowAccessPolicyCount() {_uniqueStorage()._ddlAffectedRowAccessPolicyCount = nil}

  /// Output only. [Beta] The DDL target routine. Present only for
  /// CREATE/DROP FUNCTION/PROCEDURE queries.
  package var ddlTargetRoutine: Google_Cloud_Bigquery_V2_RoutineReference {
    get {return _storage._ddlTargetRoutine ?? Google_Cloud_Bigquery_V2_RoutineReference()}
    set {_uniqueStorage()._ddlTargetRoutine = newValue}
  }
  /// Returns true if `ddlTargetRoutine` has been explicitly set.
  package var hasDdlTargetRoutine: Bool {return _storage._ddlTargetRoutine != nil}
  /// Clears the value of `ddlTargetRoutine`. Subsequent reads from it will return its default value.
  package mutating func clearDdlTargetRoutine() {_uniqueStorage()._ddlTargetRoutine = nil}

  /// Output only. The DDL target dataset. Present only for CREATE/ALTER/DROP
  /// SCHEMA(dataset) queries.
  package var ddlTargetDataset: Google_Cloud_Bigquery_V2_DatasetReference {
    get {return _storage._ddlTargetDataset ?? Google_Cloud_Bigquery_V2_DatasetReference()}
    set {_uniqueStorage()._ddlTargetDataset = newValue}
  }
  /// Returns true if `ddlTargetDataset` has been explicitly set.
  package var hasDdlTargetDataset: Bool {return _storage._ddlTargetDataset != nil}
  /// Clears the value of `ddlTargetDataset`. Subsequent reads from it will return its default value.
  package mutating func clearDdlTargetDataset() {_uniqueStorage()._ddlTargetDataset = nil}

  /// Output only. Statistics of a BigQuery ML training job.
  package var mlStatistics: Google_Cloud_Bigquery_V2_MlStatistics {
    get {return _storage._mlStatistics ?? Google_Cloud_Bigquery_V2_MlStatistics()}
    set {_uniqueStorage()._mlStatistics = newValue}
  }
  /// Returns true if `mlStatistics` has been explicitly set.
  package var hasMlStatistics: Bool {return _storage._mlStatistics != nil}
  /// Clears the value of `mlStatistics`. Subsequent reads from it will return its default value.
  package mutating func clearMlStatistics() {_uniqueStorage()._mlStatistics = nil}

  /// Output only. Stats for EXPORT DATA statement.
  package var exportDataStatistics: Google_Cloud_Bigquery_V2_ExportDataStatistics {
    get {return _storage._exportDataStatistics ?? Google_Cloud_Bigquery_V2_ExportDataStatistics()}
    set {_uniqueStorage()._exportDataStatistics = newValue}
  }
  /// Returns true if `exportDataStatistics` has been explicitly set.
  package var hasExportDataStatistics: Bool {return _storage._exportDataStatistics != nil}
  /// Clears the value of `exportDataStatistics`. Subsequent reads from it will return its default value.
  package mutating func clearExportDataStatistics() {_uniqueStorage()._exportDataStatistics = nil}

  /// Output only. Job cost breakdown as bigquery internal cost and external
  /// service costs.
  package var externalServiceCosts: [Google_Cloud_Bigquery_V2_ExternalServiceCost] {
    get {return _storage._externalServiceCosts}
    set {_uniqueStorage()._externalServiceCosts = newValue}
  }

  /// Output only. BI Engine specific Statistics.
  package var biEngineStatistics: Google_Cloud_Bigquery_V2_BiEngineStatistics {
    get {return _storage._biEngineStatistics ?? Google_Cloud_Bigquery_V2_BiEngineStatistics()}
    set {_uniqueStorage()._biEngineStatistics = newValue}
  }
  /// Returns true if `biEngineStatistics` has been explicitly set.
  package var hasBiEngineStatistics: Bool {return _storage._biEngineStatistics != nil}
  /// Clears the value of `biEngineStatistics`. Subsequent reads from it will return its default value.
  package mutating func clearBiEngineStatistics() {_uniqueStorage()._biEngineStatistics = nil}

  /// Output only. Statistics for a LOAD query.
  package var loadQueryStatistics: Google_Cloud_Bigquery_V2_LoadQueryStatistics {
    get {return _storage._loadQueryStatistics ?? Google_Cloud_Bigquery_V2_LoadQueryStatistics()}
    set {_uniqueStorage()._loadQueryStatistics = newValue}
  }
  /// Returns true if `loadQueryStatistics` has been explicitly set.
  package var hasLoadQueryStatistics: Bool {return _storage._loadQueryStatistics != nil}
  /// Clears the value of `loadQueryStatistics`. Subsequent reads from it will return its default value.
  package mutating func clearLoadQueryStatistics() {_uniqueStorage()._loadQueryStatistics = nil}

  /// Output only. Referenced table for DCL statement.
  package var dclTargetTable: Google_Cloud_Bigquery_V2_TableReference {
    get {return _storage._dclTargetTable ?? Google_Cloud_Bigquery_V2_TableReference()}
    set {_uniqueStorage()._dclTargetTable = newValue}
  }
  /// Returns true if `dclTargetTable` has been explicitly set.
  package var hasDclTargetTable: Bool {return _storage._dclTargetTable != nil}
  /// Clears the value of `dclTargetTable`. Subsequent reads from it will return its default value.
  package mutating func clearDclTargetTable() {_uniqueStorage()._dclTargetTable = nil}

  /// Output only. Referenced view for DCL statement.
  package var dclTargetView: Google_Cloud_Bigquery_V2_TableReference {
    get {return _storage._dclTargetView ?? Google_Cloud_Bigquery_V2_TableReference()}
    set {_uniqueStorage()._dclTargetView = newValue}
  }
  /// Returns true if `dclTargetView` has been explicitly set.
  package var hasDclTargetView: Bool {return _storage._dclTargetView != nil}
  /// Clears the value of `dclTargetView`. Subsequent reads from it will return its default value.
  package mutating func clearDclTargetView() {_uniqueStorage()._dclTargetView = nil}

  /// Output only. Referenced dataset for DCL statement.
  package var dclTargetDataset: Google_Cloud_Bigquery_V2_DatasetReference {
    get {return _storage._dclTargetDataset ?? Google_Cloud_Bigquery_V2_DatasetReference()}
    set {_uniqueStorage()._dclTargetDataset = newValue}
  }
  /// Returns true if `dclTargetDataset` has been explicitly set.
  package var hasDclTargetDataset: Bool {return _storage._dclTargetDataset != nil}
  /// Clears the value of `dclTargetDataset`. Subsequent reads from it will return its default value.
  package mutating func clearDclTargetDataset() {_uniqueStorage()._dclTargetDataset = nil}

  /// Output only. Search query specific statistics.
  package var searchStatistics: Google_Cloud_Bigquery_V2_SearchStatistics {
    get {return _storage._searchStatistics ?? Google_Cloud_Bigquery_V2_SearchStatistics()}
    set {_uniqueStorage()._searchStatistics = newValue}
  }
  /// Returns true if `searchStatistics` has been explicitly set.
  package var hasSearchStatistics: Bool {return _storage._searchStatistics != nil}
  /// Clears the value of `searchStatistics`. Subsequent reads from it will return its default value.
  package mutating func clearSearchStatistics() {_uniqueStorage()._searchStatistics = nil}

  /// Output only. Vector Search query specific statistics.
  package var vectorSearchStatistics: Google_Cloud_Bigquery_V2_VectorSearchStatistics {
    get {return _storage._vectorSearchStatistics ?? Google_Cloud_Bigquery_V2_VectorSearchStatistics()}
    set {_uniqueStorage()._vectorSearchStatistics = newValue}
  }
  /// Returns true if `vectorSearchStatistics` has been explicitly set.
  package var hasVectorSearchStatistics: Bool {return _storage._vectorSearchStatistics != nil}
  /// Clears the value of `vectorSearchStatistics`. Subsequent reads from it will return its default value.
  package mutating func clearVectorSearchStatistics() {_uniqueStorage()._vectorSearchStatistics = nil}

  /// Output only. Performance insights.
  package var performanceInsights: Google_Cloud_Bigquery_V2_PerformanceInsights {
    get {return _storage._performanceInsights ?? Google_Cloud_Bigquery_V2_PerformanceInsights()}
    set {_uniqueStorage()._performanceInsights = newValue}
  }
  /// Returns true if `performanceInsights` has been explicitly set.
  package var hasPerformanceInsights: Bool {return _storage._performanceInsights != nil}
  /// Clears the value of `performanceInsights`. Subsequent reads from it will return its default value.
  package mutating func clearPerformanceInsights() {_uniqueStorage()._performanceInsights = nil}

  /// Output only. Query optimization information for a QUERY job.
  package var queryInfo: Google_Cloud_Bigquery_V2_QueryInfo {
    get {return _storage._queryInfo ?? Google_Cloud_Bigquery_V2_QueryInfo()}
    set {_uniqueStorage()._queryInfo = newValue}
  }
  /// Returns true if `queryInfo` has been explicitly set.
  package var hasQueryInfo: Bool {return _storage._queryInfo != nil}
  /// Clears the value of `queryInfo`. Subsequent reads from it will return its default value.
  package mutating func clearQueryInfo() {_uniqueStorage()._queryInfo = nil}

  /// Output only. Statistics of a Spark procedure job.
  package var sparkStatistics: Google_Cloud_Bigquery_V2_SparkStatistics {
    get {return _storage._sparkStatistics ?? Google_Cloud_Bigquery_V2_SparkStatistics()}
    set {_uniqueStorage()._sparkStatistics = newValue}
  }
  /// Returns true if `sparkStatistics` has been explicitly set.
  package var hasSparkStatistics: Bool {return _storage._sparkStatistics != nil}
  /// Clears the value of `sparkStatistics`. Subsequent reads from it will return its default value.
  package mutating func clearSparkStatistics() {_uniqueStorage()._sparkStatistics = nil}

  /// Output only. Total bytes transferred for cross-cloud queries such as Cross
  /// Cloud Transfer and CREATE TABLE AS SELECT (CTAS).
  package var transferredBytes: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._transferredBytes ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._transferredBytes = newValue}
  }
  /// Returns true if `transferredBytes` has been explicitly set.
  package var hasTransferredBytes: Bool {return _storage._transferredBytes != nil}
  /// Clears the value of `transferredBytes`. Subsequent reads from it will return its default value.
  package mutating func clearTransferredBytes() {_uniqueStorage()._transferredBytes = nil}

  /// Output only. Statistics of materialized views of a query job.
  package var materializedViewStatistics: Google_Cloud_Bigquery_V2_MaterializedViewStatistics {
    get {return _storage._materializedViewStatistics ?? Google_Cloud_Bigquery_V2_MaterializedViewStatistics()}
    set {_uniqueStorage()._materializedViewStatistics = newValue}
  }
  /// Returns true if `materializedViewStatistics` has been explicitly set.
  package var hasMaterializedViewStatistics: Bool {return _storage._materializedViewStatistics != nil}
  /// Clears the value of `materializedViewStatistics`. Subsequent reads from it will return its default value.
  package mutating func clearMaterializedViewStatistics() {_uniqueStorage()._materializedViewStatistics = nil}

  /// Output only. Statistics of metadata cache usage in a query for BigLake
  /// tables.
  package var metadataCacheStatistics: Google_Cloud_Bigquery_V2_MetadataCacheStatistics {
    get {return _storage._metadataCacheStatistics ?? Google_Cloud_Bigquery_V2_MetadataCacheStatistics()}
    set {_uniqueStorage()._metadataCacheStatistics = newValue}
  }
  /// Returns true if `metadataCacheStatistics` has been explicitly set.
  package var hasMetadataCacheStatistics: Bool {return _storage._metadataCacheStatistics != nil}
  /// Clears the value of `metadataCacheStatistics`. Subsequent reads from it will return its default value.
  package mutating func clearMetadataCacheStatistics() {_uniqueStorage()._metadataCacheStatistics = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Statistics for a load job.
package struct Google_Cloud_Bigquery_V2_JobStatistics3: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Number of source files in a load job.
  package var inputFiles: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _inputFiles ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_inputFiles = newValue}
  }
  /// Returns true if `inputFiles` has been explicitly set.
  package var hasInputFiles: Bool {return self._inputFiles != nil}
  /// Clears the value of `inputFiles`. Subsequent reads from it will return its default value.
  package mutating func clearInputFiles() {self._inputFiles = nil}

  /// Output only. Number of bytes of source data in a load job.
  package var inputFileBytes: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _inputFileBytes ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_inputFileBytes = newValue}
  }
  /// Returns true if `inputFileBytes` has been explicitly set.
  package var hasInputFileBytes: Bool {return self._inputFileBytes != nil}
  /// Clears the value of `inputFileBytes`. Subsequent reads from it will return its default value.
  package mutating func clearInputFileBytes() {self._inputFileBytes = nil}

  /// Output only. Number of rows imported in a load job.
  /// Note that while an import job is in the running state, this
  /// value may change.
  package var outputRows: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _outputRows ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_outputRows = newValue}
  }
  /// Returns true if `outputRows` has been explicitly set.
  package var hasOutputRows: Bool {return self._outputRows != nil}
  /// Clears the value of `outputRows`. Subsequent reads from it will return its default value.
  package mutating func clearOutputRows() {self._outputRows = nil}

  /// Output only. Size of the loaded data in bytes. Note
  /// that while a load job is in the running state, this value may change.
  package var outputBytes: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _outputBytes ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_outputBytes = newValue}
  }
  /// Returns true if `outputBytes` has been explicitly set.
  package var hasOutputBytes: Bool {return self._outputBytes != nil}
  /// Clears the value of `outputBytes`. Subsequent reads from it will return its default value.
  package mutating func clearOutputBytes() {self._outputBytes = nil}

  /// Output only. The number of bad records encountered. Note that if the job
  /// has failed because of more bad records encountered than the maximum
  /// allowed in the load job configuration, then this number can be less than
  /// the total number of bad records present in the input data.
  package var badRecords: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _badRecords ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_badRecords = newValue}
  }
  /// Returns true if `badRecords` has been explicitly set.
  package var hasBadRecords: Bool {return self._badRecords != nil}
  /// Clears the value of `badRecords`. Subsequent reads from it will return its default value.
  package mutating func clearBadRecords() {self._badRecords = nil}

  /// Output only. Describes a timeline of job execution.
  package var timeline: [Google_Cloud_Bigquery_V2_QueryTimelineSample] = []

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _inputFiles: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _inputFileBytes: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _outputRows: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _outputBytes: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _badRecords: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
}

/// Statistics for an extract job.
package struct Google_Cloud_Bigquery_V2_JobStatistics4: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Number of files per destination URI or URI pattern
  /// specified in the extract configuration. These values will be in the same
  /// order as the URIs specified in the 'destinationUris' field.
  package var destinationUriFileCounts: [Int64] = []

  /// Output only. Number of user bytes extracted into the result. This is the
  /// byte count as computed by BigQuery for billing purposes
  /// and doesn't have any relationship with the number of actual
  /// result bytes extracted in the desired format.
  package var inputBytes: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _inputBytes ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_inputBytes = newValue}
  }
  /// Returns true if `inputBytes` has been explicitly set.
  package var hasInputBytes: Bool {return self._inputBytes != nil}
  /// Clears the value of `inputBytes`. Subsequent reads from it will return its default value.
  package mutating func clearInputBytes() {self._inputBytes = nil}

  /// Output only. Describes a timeline of job execution.
  package var timeline: [Google_Cloud_Bigquery_V2_QueryTimelineSample] = []

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _inputBytes: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
}

/// Statistics for a copy job.
package struct Google_Cloud_Bigquery_V2_CopyJobStatistics: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Number of rows copied to the destination table.
  package var copiedRows: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _copiedRows ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_copiedRows = newValue}
  }
  /// Returns true if `copiedRows` has been explicitly set.
  package var hasCopiedRows: Bool {return self._copiedRows != nil}
  /// Clears the value of `copiedRows`. Subsequent reads from it will return its default value.
  package mutating func clearCopiedRows() {self._copiedRows = nil}

  /// Output only. Number of logical bytes copied to the destination table.
  package var copiedLogicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _copiedLogicalBytes ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_copiedLogicalBytes = newValue}
  }
  /// Returns true if `copiedLogicalBytes` has been explicitly set.
  package var hasCopiedLogicalBytes: Bool {return self._copiedLogicalBytes != nil}
  /// Clears the value of `copiedLogicalBytes`. Subsequent reads from it will return its default value.
  package mutating func clearCopiedLogicalBytes() {self._copiedLogicalBytes = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _copiedRows: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _copiedLogicalBytes: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
}

/// Job statistics specific to a BigQuery ML training job.
package struct Google_Cloud_Bigquery_V2_MlStatistics: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Maximum number of iterations specified as max_iterations in
  /// the 'CREATE MODEL' query. The actual number of iterations may be less than
  /// this number due to early stop.
  package var maxIterations: Int64 = 0

  /// Results for all completed iterations.
  /// Empty for [hyperparameter tuning
  /// jobs](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview).
  package var iterationResults: [Google_Cloud_Bigquery_V2_Model.TrainingRun.IterationResult] = []

  /// Output only. The type of the model that is being trained.
  package var modelType: Google_Cloud_Bigquery_V2_Model.ModelType = .unspecified

  /// Output only. Training type of the job.
  package var trainingType: Google_Cloud_Bigquery_V2_MlStatistics.TrainingType = .unspecified

  /// Output only. Trials of a [hyperparameter tuning
  /// job](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview)
  /// sorted by trial_id.
  package var hparamTrials: [Google_Cloud_Bigquery_V2_Model.HparamTuningTrial] = []

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Training type.
  package enum TrainingType: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Unspecified training type.
    case unspecified // = 0

    /// Single training with fixed parameter space.
    case singleTraining // = 1

    /// [Hyperparameter tuning
    /// training](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview).
    case hparamTuning // = 2
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .singleTraining
      case 2: self = .hparamTuning
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .singleTraining: return 1
      case .hparamTuning: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_MlStatistics.TrainingType] = [
      .unspecified,
      .singleTraining,
      .hparamTuning,
    ]

  }

  package init() {}
}

/// Job statistics specific to the child job of a script.
package struct Google_Cloud_Bigquery_V2_ScriptStatistics: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Whether this child job was a statement or expression.
  package var evaluationKind: Google_Cloud_Bigquery_V2_ScriptStatistics.EvaluationKind = .unspecified

  /// Stack trace showing the line/column/procedure name of each frame on the
  /// stack at the point where the current evaluation happened. The leaf frame
  /// is first, the primary script is last. Never empty.
  package var stackFrames: [Google_Cloud_Bigquery_V2_ScriptStatistics.ScriptStackFrame] = []

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Describes how the job is evaluated.
  package enum EvaluationKind: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Default value.
    case unspecified // = 0

    /// The statement appears directly in the script.
    case statement // = 1

    /// The statement evaluates an expression that appears in the script.
    case expression // = 2
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .statement
      case 2: self = .expression
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .statement: return 1
      case .expression: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_ScriptStatistics.EvaluationKind] = [
      .unspecified,
      .statement,
      .expression,
    ]

  }

  /// Represents the location of the statement/expression being evaluated.
  /// Line and column numbers are defined as follows:
  ///
  /// - Line and column numbers start with one.  That is, line 1 column 1 denotes
  ///   the start of the script.
  /// - When inside a stored procedure, all line/column numbers are relative
  ///   to the procedure body, not the script in which the procedure was defined.
  /// - Start/end positions exclude leading/trailing comments and whitespace.
  ///   The end position always ends with a ";", when present.
  /// - Multi-byte Unicode characters are treated as just one column.
  /// - If the original script (or procedure definition) contains TAB characters,
  ///   a tab "snaps" the indentation forward to the nearest multiple of 8
  ///   characters, plus 1. For example, a TAB on column 1, 2, 3, 4, 5, 6 , or 8
  ///   will advance the next character to column 9.  A TAB on column 9, 10, 11,
  ///   12, 13, 14, 15, or 16 will advance the next character to column 17.
  package struct ScriptStackFrame: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Output only. One-based start line.
    package var startLine: Int32 = 0

    /// Output only. One-based start column.
    package var startColumn: Int32 = 0

    /// Output only. One-based end line.
    package var endLine: Int32 = 0

    /// Output only. One-based end column.
    package var endColumn: Int32 = 0

    /// Output only. Name of the active procedure, empty if in a top-level
    /// script.
    package var procedureID: String = String()

    /// Output only. Text of the current statement/expression.
    package var text: String = String()

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    package init() {}
  }

  package init() {}
}

/// Statistics for row-level security.
package struct Google_Cloud_Bigquery_V2_RowLevelSecurityStatistics: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Whether any accessed data was protected by row access policies.
  package var rowLevelSecurityApplied: Bool = false

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

/// Statistics for data-masking.
package struct Google_Cloud_Bigquery_V2_DataMaskingStatistics: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Whether any accessed data was protected by the data masking.
  package var dataMaskingApplied: Bool = false

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

/// Statistics for a single job execution.
package struct Google_Cloud_Bigquery_V2_JobStatistics: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Creation time of this job, in milliseconds since the epoch.
  /// This field will be present on all jobs.
  package var creationTime: Int64 {
    get {return _storage._creationTime}
    set {_uniqueStorage()._creationTime = newValue}
  }

  /// Output only. Start time of this job, in milliseconds since the epoch.
  /// This field will be present when the job transitions from the PENDING state
  /// to either RUNNING or DONE.
  package var startTime: Int64 {
    get {return _storage._startTime}
    set {_uniqueStorage()._startTime = newValue}
  }

  /// Output only. End time of this job, in milliseconds since the epoch. This
  /// field will be present whenever a job is in the DONE state.
  package var endTime: Int64 {
    get {return _storage._endTime}
    set {_uniqueStorage()._endTime = newValue}
  }

  /// Output only. Total bytes processed for the job.
  package var totalBytesProcessed: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._totalBytesProcessed ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._totalBytesProcessed = newValue}
  }
  /// Returns true if `totalBytesProcessed` has been explicitly set.
  package var hasTotalBytesProcessed: Bool {return _storage._totalBytesProcessed != nil}
  /// Clears the value of `totalBytesProcessed`. Subsequent reads from it will return its default value.
  package mutating func clearTotalBytesProcessed() {_uniqueStorage()._totalBytesProcessed = nil}

  /// Output only. [TrustedTester] Job progress (0.0 -> 1.0) for LOAD and
  /// EXTRACT jobs.
  package var completionRatio: SwiftProtobuf.Google_Protobuf_DoubleValue {
    get {return _storage._completionRatio ?? SwiftProtobuf.Google_Protobuf_DoubleValue()}
    set {_uniqueStorage()._completionRatio = newValue}
  }
  /// Returns true if `completionRatio` has been explicitly set.
  package var hasCompletionRatio: Bool {return _storage._completionRatio != nil}
  /// Clears the value of `completionRatio`. Subsequent reads from it will return its default value.
  package mutating func clearCompletionRatio() {_uniqueStorage()._completionRatio = nil}

  /// Output only. Quotas which delayed this job's start time.
  package var quotaDeferments: [String] {
    get {return _storage._quotaDeferments}
    set {_uniqueStorage()._quotaDeferments = newValue}
  }

  /// Output only. Statistics for a query job.
  package var query: Google_Cloud_Bigquery_V2_JobStatistics2 {
    get {return _storage._query ?? Google_Cloud_Bigquery_V2_JobStatistics2()}
    set {_uniqueStorage()._query = newValue}
  }
  /// Returns true if `query` has been explicitly set.
  package var hasQuery: Bool {return _storage._query != nil}
  /// Clears the value of `query`. Subsequent reads from it will return its default value.
  package mutating func clearQuery() {_uniqueStorage()._query = nil}

  /// Output only. Statistics for a load job.
  package var load: Google_Cloud_Bigquery_V2_JobStatistics3 {
    get {return _storage._load ?? Google_Cloud_Bigquery_V2_JobStatistics3()}
    set {_uniqueStorage()._load = newValue}
  }
  /// Returns true if `load` has been explicitly set.
  package var hasLoad: Bool {return _storage._load != nil}
  /// Clears the value of `load`. Subsequent reads from it will return its default value.
  package mutating func clearLoad() {_uniqueStorage()._load = nil}

  /// Output only. Statistics for an extract job.
  package var extract: Google_Cloud_Bigquery_V2_JobStatistics4 {
    get {return _storage._extract ?? Google_Cloud_Bigquery_V2_JobStatistics4()}
    set {_uniqueStorage()._extract = newValue}
  }
  /// Returns true if `extract` has been explicitly set.
  package var hasExtract: Bool {return _storage._extract != nil}
  /// Clears the value of `extract`. Subsequent reads from it will return its default value.
  package mutating func clearExtract() {_uniqueStorage()._extract = nil}

  /// Output only. Statistics for a copy job.
  package var copy: Google_Cloud_Bigquery_V2_CopyJobStatistics {
    get {return _storage._copy ?? Google_Cloud_Bigquery_V2_CopyJobStatistics()}
    set {_uniqueStorage()._copy = newValue}
  }
  /// Returns true if `copy` has been explicitly set.
  package var hasCopy: Bool {return _storage._copy != nil}
  /// Clears the value of `copy`. Subsequent reads from it will return its default value.
  package mutating func clearCopy() {_uniqueStorage()._copy = nil}

  /// Output only. Slot-milliseconds for the job.
  package var totalSlotMs: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._totalSlotMs ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._totalSlotMs = newValue}
  }
  /// Returns true if `totalSlotMs` has been explicitly set.
  package var hasTotalSlotMs: Bool {return _storage._totalSlotMs != nil}
  /// Clears the value of `totalSlotMs`. Subsequent reads from it will return its default value.
  package mutating func clearTotalSlotMs() {_uniqueStorage()._totalSlotMs = nil}

  /// Output only. Name of the primary reservation assigned to this job. Note
  /// that this could be different than reservations reported in the reservation
  /// usage field if parent reservations were used to execute this job.
  package var reservationID: String {
    get {return _storage._reservationID}
    set {_uniqueStorage()._reservationID = newValue}
  }

  /// Output only. Number of child jobs executed.
  package var numChildJobs: Int64 {
    get {return _storage._numChildJobs}
    set {_uniqueStorage()._numChildJobs = newValue}
  }

  /// Output only. If this is a child job, specifies the job ID of the parent.
  package var parentJobID: String {
    get {return _storage._parentJobID}
    set {_uniqueStorage()._parentJobID = newValue}
  }

  /// Output only. If this a child job of a script, specifies information about
  /// the context of this job within the script.
  package var scriptStatistics: Google_Cloud_Bigquery_V2_ScriptStatistics {
    get {return _storage._scriptStatistics ?? Google_Cloud_Bigquery_V2_ScriptStatistics()}
    set {_uniqueStorage()._scriptStatistics = newValue}
  }
  /// Returns true if `scriptStatistics` has been explicitly set.
  package var hasScriptStatistics: Bool {return _storage._scriptStatistics != nil}
  /// Clears the value of `scriptStatistics`. Subsequent reads from it will return its default value.
  package mutating func clearScriptStatistics() {_uniqueStorage()._scriptStatistics = nil}

  /// Output only. Statistics for row-level security. Present only for query and
  /// extract jobs.
  package var rowLevelSecurityStatistics: Google_Cloud_Bigquery_V2_RowLevelSecurityStatistics {
    get {return _storage._rowLevelSecurityStatistics ?? Google_Cloud_Bigquery_V2_RowLevelSecurityStatistics()}
    set {_uniqueStorage()._rowLevelSecurityStatistics = newValue}
  }
  /// Returns true if `rowLevelSecurityStatistics` has been explicitly set.
  package var hasRowLevelSecurityStatistics: Bool {return _storage._rowLevelSecurityStatistics != nil}
  /// Clears the value of `rowLevelSecurityStatistics`. Subsequent reads from it will return its default value.
  package mutating func clearRowLevelSecurityStatistics() {_uniqueStorage()._rowLevelSecurityStatistics = nil}

  /// Output only. Statistics for data-masking. Present only for query and
  /// extract jobs.
  package var dataMaskingStatistics: Google_Cloud_Bigquery_V2_DataMaskingStatistics {
    get {return _storage._dataMaskingStatistics ?? Google_Cloud_Bigquery_V2_DataMaskingStatistics()}
    set {_uniqueStorage()._dataMaskingStatistics = newValue}
  }
  /// Returns true if `dataMaskingStatistics` has been explicitly set.
  package var hasDataMaskingStatistics: Bool {return _storage._dataMaskingStatistics != nil}
  /// Clears the value of `dataMaskingStatistics`. Subsequent reads from it will return its default value.
  package mutating func clearDataMaskingStatistics() {_uniqueStorage()._dataMaskingStatistics = nil}

  /// Output only. [Alpha] Information of the multi-statement transaction if this
  /// job is part of one.
  ///
  /// This property is only expected on a child job or a job that is in a
  /// session. A script parent job is not part of the transaction started in the
  /// script.
  package var transactionInfo: Google_Cloud_Bigquery_V2_JobStatistics.TransactionInfo {
    get {return _storage._transactionInfo ?? Google_Cloud_Bigquery_V2_JobStatistics.TransactionInfo()}
    set {_uniqueStorage()._transactionInfo = newValue}
  }
  /// Returns true if `transactionInfo` has been explicitly set.
  package var hasTransactionInfo: Bool {return _storage._transactionInfo != nil}
  /// Clears the value of `transactionInfo`. Subsequent reads from it will return its default value.
  package mutating func clearTransactionInfo() {_uniqueStorage()._transactionInfo = nil}

  /// Output only. Information of the session if this job is part of one.
  package var sessionInfo: Google_Cloud_Bigquery_V2_SessionInfo {
    get {return _storage._sessionInfo ?? Google_Cloud_Bigquery_V2_SessionInfo()}
    set {_uniqueStorage()._sessionInfo = newValue}
  }
  /// Returns true if `sessionInfo` has been explicitly set.
  package var hasSessionInfo: Bool {return _storage._sessionInfo != nil}
  /// Clears the value of `sessionInfo`. Subsequent reads from it will return its default value.
  package mutating func clearSessionInfo() {_uniqueStorage()._sessionInfo = nil}

  /// Output only. The duration in milliseconds of the execution of the final
  /// attempt of this job, as BigQuery may internally re-attempt to execute the
  /// job.
  package var finalExecutionDurationMs: Int64 {
    get {return _storage._finalExecutionDurationMs}
    set {_uniqueStorage()._finalExecutionDurationMs = newValue}
  }

  /// Output only. Name of edition corresponding to the reservation for this job
  /// at the time of this update.
  package var edition: Google_Cloud_Bigquery_V2_ReservationEdition {
    get {return _storage._edition}
    set {_uniqueStorage()._edition = newValue}
  }

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// [Alpha] Information of a multi-statement transaction.
  package struct TransactionInfo: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Output only. [Alpha] Id of the transaction.
    package var transactionID: String = String()

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    package init() {}
  }

  package init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Detailed statistics for DML statements
package struct Google_Cloud_Bigquery_V2_DmlStats: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Number of inserted Rows. Populated by DML INSERT and MERGE
  /// statements
  package var insertedRowCount: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _insertedRowCount ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_insertedRowCount = newValue}
  }
  /// Returns true if `insertedRowCount` has been explicitly set.
  package var hasInsertedRowCount: Bool {return self._insertedRowCount != nil}
  /// Clears the value of `insertedRowCount`. Subsequent reads from it will return its default value.
  package mutating func clearInsertedRowCount() {self._insertedRowCount = nil}

  /// Output only. Number of deleted Rows. populated by DML DELETE, MERGE and
  /// TRUNCATE statements.
  package var deletedRowCount: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _deletedRowCount ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_deletedRowCount = newValue}
  }
  /// Returns true if `deletedRowCount` has been explicitly set.
  package var hasDeletedRowCount: Bool {return self._deletedRowCount != nil}
  /// Clears the value of `deletedRowCount`. Subsequent reads from it will return its default value.
  package mutating func clearDeletedRowCount() {self._deletedRowCount = nil}

  /// Output only. Number of updated Rows. Populated by DML UPDATE and MERGE
  /// statements.
  package var updatedRowCount: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _updatedRowCount ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_updatedRowCount = newValue}
  }
  /// Returns true if `updatedRowCount` has been explicitly set.
  package var hasUpdatedRowCount: Bool {return self._updatedRowCount != nil}
  /// Clears the value of `updatedRowCount`. Subsequent reads from it will return its default value.
  package mutating func clearUpdatedRowCount() {self._updatedRowCount = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _insertedRowCount: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _deletedRowCount: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _updatedRowCount: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
}

/// Performance insights for the job.
package struct Google_Cloud_Bigquery_V2_PerformanceInsights: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Average execution ms of previous runs. Indicates the job ran
  /// slow compared to previous executions. To find previous executions, use
  /// INFORMATION_SCHEMA tables and filter jobs with same query hash.
  package var avgPreviousExecutionMs: Int64 = 0

  /// Output only. Standalone query stage performance insights, for exploring
  /// potential improvements.
  package var stagePerformanceStandaloneInsights: [Google_Cloud_Bigquery_V2_StagePerformanceStandaloneInsight] = []

  /// Output only. Query stage performance insights compared to previous runs,
  /// for diagnosing performance regression.
  package var stagePerformanceChangeInsights: [Google_Cloud_Bigquery_V2_StagePerformanceChangeInsight] = []

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

/// Performance insights compared to the previous executions for a specific
/// stage.
package struct Google_Cloud_Bigquery_V2_StagePerformanceChangeInsight: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. The stage id that the insight mapped to.
  package var stageID: Int64 = 0

  /// Output only. Input data change insight of the query stage.
  package var inputDataChange: Google_Cloud_Bigquery_V2_InputDataChange {
    get {return _inputDataChange ?? Google_Cloud_Bigquery_V2_InputDataChange()}
    set {_inputDataChange = newValue}
  }
  /// Returns true if `inputDataChange` has been explicitly set.
  package var hasInputDataChange: Bool {return self._inputDataChange != nil}
  /// Clears the value of `inputDataChange`. Subsequent reads from it will return its default value.
  package mutating func clearInputDataChange() {self._inputDataChange = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _inputDataChange: Google_Cloud_Bigquery_V2_InputDataChange? = nil
}

/// Details about the input data change insight.
package struct Google_Cloud_Bigquery_V2_InputDataChange: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Records read difference percentage compared to a previous run.
  package var recordsReadDiffPercentage: Float = 0

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

/// Standalone performance insights for a specific stage.
package struct Google_Cloud_Bigquery_V2_StagePerformanceStandaloneInsight: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. The stage id that the insight mapped to.
  package var stageID: Int64 = 0

  /// Output only. True if the stage has a slot contention issue.
  package var slotContention: Bool {
    get {return _slotContention ?? false}
    set {_slotContention = newValue}
  }
  /// Returns true if `slotContention` has been explicitly set.
  package var hasSlotContention: Bool {return self._slotContention != nil}
  /// Clears the value of `slotContention`. Subsequent reads from it will return its default value.
  package mutating func clearSlotContention() {self._slotContention = nil}

  /// Output only. True if the stage has insufficient shuffle quota.
  package var insufficientShuffleQuota: Bool {
    get {return _insufficientShuffleQuota ?? false}
    set {_insufficientShuffleQuota = newValue}
  }
  /// Returns true if `insufficientShuffleQuota` has been explicitly set.
  package var hasInsufficientShuffleQuota: Bool {return self._insufficientShuffleQuota != nil}
  /// Clears the value of `insufficientShuffleQuota`. Subsequent reads from it will return its default value.
  package mutating func clearInsufficientShuffleQuota() {self._insufficientShuffleQuota = nil}

  /// Output only. If present, the stage had the following reasons for being
  /// disqualified from BI Engine execution.
  package var biEngineReasons: [Google_Cloud_Bigquery_V2_BiEngineReason] = []

  /// Output only. High cardinality joins in the stage.
  package var highCardinalityJoins: [Google_Cloud_Bigquery_V2_HighCardinalityJoin] = []

  /// Output only. Partition skew in the stage.
  package var partitionSkew: Google_Cloud_Bigquery_V2_PartitionSkew {
    get {return _partitionSkew ?? Google_Cloud_Bigquery_V2_PartitionSkew()}
    set {_partitionSkew = newValue}
  }
  /// Returns true if `partitionSkew` has been explicitly set.
  package var hasPartitionSkew: Bool {return self._partitionSkew != nil}
  /// Clears the value of `partitionSkew`. Subsequent reads from it will return its default value.
  package mutating func clearPartitionSkew() {self._partitionSkew = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _slotContention: Bool? = nil
  fileprivate var _insufficientShuffleQuota: Bool? = nil
  fileprivate var _partitionSkew: Google_Cloud_Bigquery_V2_PartitionSkew? = nil
}

/// High cardinality join detailed information.
package struct Google_Cloud_Bigquery_V2_HighCardinalityJoin: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Count of left input rows.
  package var leftRows: Int64 = 0

  /// Output only. Count of right input rows.
  package var rightRows: Int64 = 0

  /// Output only. Count of the output rows.
  package var outputRows: Int64 = 0

  /// Output only. The index of the join operator in the ExplainQueryStep lists.
  package var stepIndex: Int32 = 0

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

/// Partition skew detailed information.
package struct Google_Cloud_Bigquery_V2_PartitionSkew: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Source stages which produce skewed data.
  package var skewSources: [Google_Cloud_Bigquery_V2_PartitionSkew.SkewSource] = []

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Details about source stages which produce skewed data.
  package struct SkewSource: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Output only. Stage id of the skew source stage.
    package var stageID: Int64 = 0

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    package init() {}
  }

  package init() {}
}

/// Statistics for a BigSpark query.
/// Populated as part of JobStatistics2
package struct Google_Cloud_Bigquery_V2_SparkStatistics: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Spark job ID if a Spark job is created successfully.
  package var sparkJobID: String {
    get {return _sparkJobID ?? String()}
    set {_sparkJobID = newValue}
  }
  /// Returns true if `sparkJobID` has been explicitly set.
  package var hasSparkJobID: Bool {return self._sparkJobID != nil}
  /// Clears the value of `sparkJobID`. Subsequent reads from it will return its default value.
  package mutating func clearSparkJobID() {self._sparkJobID = nil}

  /// Output only. Location where the Spark job is executed.
  /// A location is selected by BigQueury for jobs configured to run in a
  /// multi-region.
  package var sparkJobLocation: String {
    get {return _sparkJobLocation ?? String()}
    set {_sparkJobLocation = newValue}
  }
  /// Returns true if `sparkJobLocation` has been explicitly set.
  package var hasSparkJobLocation: Bool {return self._sparkJobLocation != nil}
  /// Clears the value of `sparkJobLocation`. Subsequent reads from it will return its default value.
  package mutating func clearSparkJobLocation() {self._sparkJobLocation = nil}

  /// Output only. Endpoints returned from Dataproc.
  /// Key list:
  ///  - history_server_endpoint: A link to Spark job UI.
  package var endpoints: Dictionary<String,String> = [:]

  /// Output only. Logging info is used to generate a link to Cloud Logging.
  package var loggingInfo: Google_Cloud_Bigquery_V2_SparkStatistics.LoggingInfo {
    get {return _loggingInfo ?? Google_Cloud_Bigquery_V2_SparkStatistics.LoggingInfo()}
    set {_loggingInfo = newValue}
  }
  /// Returns true if `loggingInfo` has been explicitly set.
  package var hasLoggingInfo: Bool {return self._loggingInfo != nil}
  /// Clears the value of `loggingInfo`. Subsequent reads from it will return its default value.
  package mutating func clearLoggingInfo() {self._loggingInfo = nil}

  /// Output only. The Cloud KMS encryption key that is used to protect the
  /// resources created by the Spark job. If the Spark procedure uses the invoker
  /// security mode, the Cloud KMS encryption key is either inferred from the
  /// provided system variable,
  /// `@@spark_proc_properties.kms_key_name`, or the default key of the BigQuery
  /// job's project (if the CMEK organization policy is enforced). Otherwise, the
  /// Cloud KMS key is either inferred from the Spark connection associated with
  /// the procedure (if it is provided), or from the default key of the Spark
  /// connection's project if the CMEK organization policy is enforced.
  ///
  /// Example:
  ///
  /// * `projects/[kms_project_id]/locations/[region]/keyRings/[key_region]/cryptoKeys/[key]`
  package var kmsKeyName: String {
    get {return _kmsKeyName ?? String()}
    set {_kmsKeyName = newValue}
  }
  /// Returns true if `kmsKeyName` has been explicitly set.
  package var hasKmsKeyName: Bool {return self._kmsKeyName != nil}
  /// Clears the value of `kmsKeyName`. Subsequent reads from it will return its default value.
  package mutating func clearKmsKeyName() {self._kmsKeyName = nil}

  /// Output only. The Google Cloud Storage bucket that is used as the default
  /// file system by the Spark application. This field is only filled when the
  /// Spark procedure uses the invoker security mode. The `gcsStagingBucket`
  /// bucket is inferred from the `@@spark_proc_properties.staging_bucket` system
  /// variable (if it is provided). Otherwise, BigQuery creates a default staging
  /// bucket for the job and returns the bucket name in this field.
  ///
  /// Example:
  ///
  /// * `gs://[bucket_name]`
  package var gcsStagingBucket: String {
    get {return _gcsStagingBucket ?? String()}
    set {_gcsStagingBucket = newValue}
  }
  /// Returns true if `gcsStagingBucket` has been explicitly set.
  package var hasGcsStagingBucket: Bool {return self._gcsStagingBucket != nil}
  /// Clears the value of `gcsStagingBucket`. Subsequent reads from it will return its default value.
  package mutating func clearGcsStagingBucket() {self._gcsStagingBucket = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Spark job logs can be filtered by these fields in Cloud Logging.
  package struct LoggingInfo: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Output only. Resource type used for logging.
    package var resourceType: String = String()

    /// Output only. Project ID where the Spark logs were written.
    package var projectID: String = String()

    package var unknownFields = SwiftProtobuf.UnknownStorage()

    package init() {}
  }

  package init() {}

  fileprivate var _sparkJobID: String? = nil
  fileprivate var _sparkJobLocation: String? = nil
  fileprivate var _loggingInfo: Google_Cloud_Bigquery_V2_SparkStatistics.LoggingInfo? = nil
  fileprivate var _kmsKeyName: String? = nil
  fileprivate var _gcsStagingBucket: String? = nil
}

/// Statistics of materialized views considered in a query job.
package struct Google_Cloud_Bigquery_V2_MaterializedViewStatistics: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Materialized views considered for the query job. Only certain materialized
  /// views are used. For a detailed list, see the child message.
  ///
  /// If many materialized views are considered, then the list might be
  /// incomplete.
  package var materializedView: [Google_Cloud_Bigquery_V2_MaterializedView] = []

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

/// A materialized view considered for a query job.
package struct Google_Cloud_Bigquery_V2_MaterializedView: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The candidate materialized view.
  package var tableReference: Google_Cloud_Bigquery_V2_TableReference {
    get {return _tableReference ?? Google_Cloud_Bigquery_V2_TableReference()}
    set {_tableReference = newValue}
  }
  /// Returns true if `tableReference` has been explicitly set.
  package var hasTableReference: Bool {return self._tableReference != nil}
  /// Clears the value of `tableReference`. Subsequent reads from it will return its default value.
  package mutating func clearTableReference() {self._tableReference = nil}

  /// Whether the materialized view is chosen for the query.
  ///
  /// A materialized view can be chosen to rewrite multiple parts of the same
  /// query. If a materialized view is chosen to rewrite any part of the query,
  /// then this field is true, even if the materialized view was not chosen to
  /// rewrite others parts.
  package var chosen: Bool {
    get {return _chosen ?? false}
    set {_chosen = newValue}
  }
  /// Returns true if `chosen` has been explicitly set.
  package var hasChosen: Bool {return self._chosen != nil}
  /// Clears the value of `chosen`. Subsequent reads from it will return its default value.
  package mutating func clearChosen() {self._chosen = nil}

  /// If present, specifies a best-effort estimation of the bytes saved by using
  /// the materialized view rather than its base tables.
  package var estimatedBytesSaved: Int64 {
    get {return _estimatedBytesSaved ?? 0}
    set {_estimatedBytesSaved = newValue}
  }
  /// Returns true if `estimatedBytesSaved` has been explicitly set.
  package var hasEstimatedBytesSaved: Bool {return self._estimatedBytesSaved != nil}
  /// Clears the value of `estimatedBytesSaved`. Subsequent reads from it will return its default value.
  package mutating func clearEstimatedBytesSaved() {self._estimatedBytesSaved = nil}

  /// If present, specifies the reason why the materialized view was not chosen
  /// for the query.
  package var rejectedReason: Google_Cloud_Bigquery_V2_MaterializedView.RejectedReason {
    get {return _rejectedReason ?? .unspecified}
    set {_rejectedReason = newValue}
  }
  /// Returns true if `rejectedReason` has been explicitly set.
  package var hasRejectedReason: Bool {return self._rejectedReason != nil}
  /// Clears the value of `rejectedReason`. Subsequent reads from it will return its default value.
  package mutating func clearRejectedReason() {self._rejectedReason = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Reason why a materialized view was not chosen for a query. For more
  /// information, see [Understand why materialized views were
  /// rejected](https://cloud.google.com/bigquery/docs/materialized-views-use#understand-rejected).
  package enum RejectedReason: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Default unspecified value.
    case unspecified // = 0

    /// View has no cached data because it has not refreshed yet.
    case noData // = 1

    /// The estimated cost of the view is more expensive than another view or the
    /// base table.
    ///
    /// Note: The estimate cost might not match the billed cost.
    case cost // = 2

    /// View has no cached data because a base table is truncated.
    case baseTableTruncated // = 3

    /// View is invalidated because of a data change in one or more base tables.
    /// It could be any recent change if the
    /// [`max_staleness`](https://cloud.google.com/bigquery/docs/materialized-views-create#max_staleness)
    /// option is not set for the view, or otherwise any change outside of the
    /// staleness window.
    case baseTableDataChange // = 4

    /// View is invalidated because a base table's partition expiration has
    /// changed.
    case baseTablePartitionExpirationChange // = 5

    /// View is invalidated because a base table's partition has expired.
    case baseTableExpiredPartition // = 6

    /// View is invalidated because a base table has an incompatible metadata
    /// change.
    case baseTableIncompatibleMetadataChange // = 7

    /// View is invalidated because it was refreshed with a time zone other than
    /// that of the current job.
    case timeZone // = 8

    /// View is outside the time travel window.
    case outOfTimeTravelWindow // = 9

    /// View is inaccessible to the user because of a fine-grained security
    /// policy on one of its base tables.
    case baseTableFineGrainedSecurityPolicy // = 10

    /// One of the view's base tables is too stale. For example, the cached
    /// metadata of a BigLake external table needs to be updated.
    case baseTableTooStale // = 11
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .noData
      case 2: self = .cost
      case 3: self = .baseTableTruncated
      case 4: self = .baseTableDataChange
      case 5: self = .baseTablePartitionExpirationChange
      case 6: self = .baseTableExpiredPartition
      case 7: self = .baseTableIncompatibleMetadataChange
      case 8: self = .timeZone
      case 9: self = .outOfTimeTravelWindow
      case 10: self = .baseTableFineGrainedSecurityPolicy
      case 11: self = .baseTableTooStale
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .noData: return 1
      case .cost: return 2
      case .baseTableTruncated: return 3
      case .baseTableDataChange: return 4
      case .baseTablePartitionExpirationChange: return 5
      case .baseTableExpiredPartition: return 6
      case .baseTableIncompatibleMetadataChange: return 7
      case .timeZone: return 8
      case .outOfTimeTravelWindow: return 9
      case .baseTableFineGrainedSecurityPolicy: return 10
      case .baseTableTooStale: return 11
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_MaterializedView.RejectedReason] = [
      .unspecified,
      .noData,
      .cost,
      .baseTableTruncated,
      .baseTableDataChange,
      .baseTablePartitionExpirationChange,
      .baseTableExpiredPartition,
      .baseTableIncompatibleMetadataChange,
      .timeZone,
      .outOfTimeTravelWindow,
      .baseTableFineGrainedSecurityPolicy,
      .baseTableTooStale,
    ]

  }

  package init() {}

  fileprivate var _tableReference: Google_Cloud_Bigquery_V2_TableReference? = nil
  fileprivate var _chosen: Bool? = nil
  fileprivate var _estimatedBytesSaved: Int64? = nil
  fileprivate var _rejectedReason: Google_Cloud_Bigquery_V2_MaterializedView.RejectedReason? = nil
}

/// Table level detail on the usage of metadata caching. Only set for Metadata
/// caching eligible tables referenced in the query.
package struct Google_Cloud_Bigquery_V2_TableMetadataCacheUsage: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Metadata caching eligible table referenced in the query.
  package var tableReference: Google_Cloud_Bigquery_V2_TableReference {
    get {return _tableReference ?? Google_Cloud_Bigquery_V2_TableReference()}
    set {_tableReference = newValue}
  }
  /// Returns true if `tableReference` has been explicitly set.
  package var hasTableReference: Bool {return self._tableReference != nil}
  /// Clears the value of `tableReference`. Subsequent reads from it will return its default value.
  package mutating func clearTableReference() {self._tableReference = nil}

  /// Reason for not using metadata caching for the table.
  package var unusedReason: Google_Cloud_Bigquery_V2_TableMetadataCacheUsage.UnusedReason {
    get {return _unusedReason ?? .unspecified}
    set {_unusedReason = newValue}
  }
  /// Returns true if `unusedReason` has been explicitly set.
  package var hasUnusedReason: Bool {return self._unusedReason != nil}
  /// Clears the value of `unusedReason`. Subsequent reads from it will return its default value.
  package mutating func clearUnusedReason() {self._unusedReason = nil}

  /// Free form human-readable reason metadata caching was unused for
  /// the job.
  package var explanation: String {
    get {return _explanation ?? String()}
    set {_explanation = newValue}
  }
  /// Returns true if `explanation` has been explicitly set.
  package var hasExplanation: Bool {return self._explanation != nil}
  /// Clears the value of `explanation`. Subsequent reads from it will return its default value.
  package mutating func clearExplanation() {self._explanation = nil}

  /// Duration since last refresh as of this job for managed tables (indicates
  /// metadata cache staleness as seen by this job).
  package var staleness: SwiftProtobuf.Google_Protobuf_Duration {
    get {return _staleness ?? SwiftProtobuf.Google_Protobuf_Duration()}
    set {_staleness = newValue}
  }
  /// Returns true if `staleness` has been explicitly set.
  package var hasStaleness: Bool {return self._staleness != nil}
  /// Clears the value of `staleness`. Subsequent reads from it will return its default value.
  package mutating func clearStaleness() {self._staleness = nil}

  /// [Table
  /// type](https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#Table.FIELDS.type).
  package var tableType: String = String()

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Reasons for not using metadata caching.
  package enum UnusedReason: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Unused reasons not specified.
    case unspecified // = 0

    /// Metadata cache was outside the table's maxStaleness.
    case exceededMaxStaleness // = 1

    /// Metadata caching feature is not enabled. [Update BigLake tables]
    /// (/bigquery/docs/create-cloud-storage-table-biglake#update-biglake-tables)
    /// to enable the metadata caching.
    case metadataCachingNotEnabled // = 3

    /// Other unknown reason.
    case otherReason // = 2
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .exceededMaxStaleness
      case 2: self = .otherReason
      case 3: self = .metadataCachingNotEnabled
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .exceededMaxStaleness: return 1
      case .otherReason: return 2
      case .metadataCachingNotEnabled: return 3
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_TableMetadataCacheUsage.UnusedReason] = [
      .unspecified,
      .exceededMaxStaleness,
      .metadataCachingNotEnabled,
      .otherReason,
    ]

  }

  package init() {}

  fileprivate var _tableReference: Google_Cloud_Bigquery_V2_TableReference? = nil
  fileprivate var _unusedReason: Google_Cloud_Bigquery_V2_TableMetadataCacheUsage.UnusedReason? = nil
  fileprivate var _explanation: String? = nil
  fileprivate var _staleness: SwiftProtobuf.Google_Protobuf_Duration? = nil
}

/// Statistics for metadata caching in BigLake tables.
package struct Google_Cloud_Bigquery_V2_MetadataCacheStatistics: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Set for the Metadata caching eligible tables referenced in the query.
  package var tableMetadataCacheUsage: [Google_Cloud_Bigquery_V2_TableMetadataCacheUsage] = []

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.bigquery.v2"

extension Google_Cloud_Bigquery_V2_ReservationEdition: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "RESERVATION_EDITION_UNSPECIFIED"),
    1: .same(proto: "STANDARD"),
    2: .same(proto: "ENTERPRISE"),
    3: .same(proto: "ENTERPRISE_PLUS"),
  ]
}

extension Google_Cloud_Bigquery_V2_ExplainQueryStep: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".ExplainQueryStep"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "kind"),
    2: .same(proto: "substeps"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.kind) }()
      case 2: try { try decoder.decodeRepeatedStringField(value: &self.substeps) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.kind.isEmpty {
      try visitor.visitSingularStringField(value: self.kind, fieldNumber: 1)
    }
    if !self.substeps.isEmpty {
      try visitor.visitRepeatedStringField(value: self.substeps, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_ExplainQueryStep, rhs: Google_Cloud_Bigquery_V2_ExplainQueryStep) -> Bool {
    if lhs.kind != rhs.kind {return false}
    if lhs.substeps != rhs.substeps {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_ExplainQueryStage: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".ExplainQueryStage"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .same(proto: "id"),
    3: .standard(proto: "start_ms"),
    4: .standard(proto: "end_ms"),
    5: .standard(proto: "input_stages"),
    6: .standard(proto: "wait_ratio_avg"),
    7: .standard(proto: "wait_ms_avg"),
    8: .standard(proto: "wait_ratio_max"),
    9: .standard(proto: "wait_ms_max"),
    10: .standard(proto: "read_ratio_avg"),
    11: .standard(proto: "read_ms_avg"),
    12: .standard(proto: "read_ratio_max"),
    13: .standard(proto: "read_ms_max"),
    14: .standard(proto: "compute_ratio_avg"),
    15: .standard(proto: "compute_ms_avg"),
    16: .standard(proto: "compute_ratio_max"),
    17: .standard(proto: "compute_ms_max"),
    18: .standard(proto: "write_ratio_avg"),
    19: .standard(proto: "write_ms_avg"),
    20: .standard(proto: "write_ratio_max"),
    21: .standard(proto: "write_ms_max"),
    22: .standard(proto: "shuffle_output_bytes"),
    23: .standard(proto: "shuffle_output_bytes_spilled"),
    24: .standard(proto: "records_read"),
    25: .standard(proto: "records_written"),
    26: .standard(proto: "parallel_inputs"),
    27: .standard(proto: "completed_parallel_inputs"),
    28: .same(proto: "status"),
    29: .same(proto: "steps"),
    30: .standard(proto: "slot_ms"),
    31: .standard(proto: "compute_mode"),
  ]

  fileprivate class _StorageClass {
    var _name: String = String()
    var _id: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _startMs: Int64 = 0
    var _endMs: Int64 = 0
    var _inputStages: [Int64] = []
    var _waitRatioAvg: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _waitMsAvg: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _waitRatioMax: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _waitMsMax: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _readRatioAvg: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _readMsAvg: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _readRatioMax: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _readMsMax: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _computeRatioAvg: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _computeMsAvg: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _computeRatioMax: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _computeMsMax: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _writeRatioAvg: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _writeMsAvg: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _writeRatioMax: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _writeMsMax: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _shuffleOutputBytes: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _shuffleOutputBytesSpilled: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _recordsRead: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _recordsWritten: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _parallelInputs: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _completedParallelInputs: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _status: String = String()
    var _steps: [Google_Cloud_Bigquery_V2_ExplainQueryStep] = []
    var _slotMs: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _computeMode: Google_Cloud_Bigquery_V2_ExplainQueryStage.ComputeMode = .unspecified

    #if swift(>=5.10)
      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()
    #else
      static let defaultInstance = _StorageClass()
    #endif

    private init() {}

    init(copying source: _StorageClass) {
      _name = source._name
      _id = source._id
      _startMs = source._startMs
      _endMs = source._endMs
      _inputStages = source._inputStages
      _waitRatioAvg = source._waitRatioAvg
      _waitMsAvg = source._waitMsAvg
      _waitRatioMax = source._waitRatioMax
      _waitMsMax = source._waitMsMax
      _readRatioAvg = source._readRatioAvg
      _readMsAvg = source._readMsAvg
      _readRatioMax = source._readRatioMax
      _readMsMax = source._readMsMax
      _computeRatioAvg = source._computeRatioAvg
      _computeMsAvg = source._computeMsAvg
      _computeRatioMax = source._computeRatioMax
      _computeMsMax = source._computeMsMax
      _writeRatioAvg = source._writeRatioAvg
      _writeMsAvg = source._writeMsAvg
      _writeRatioMax = source._writeRatioMax
      _writeMsMax = source._writeMsMax
      _shuffleOutputBytes = source._shuffleOutputBytes
      _shuffleOutputBytesSpilled = source._shuffleOutputBytesSpilled
      _recordsRead = source._recordsRead
      _recordsWritten = source._recordsWritten
      _parallelInputs = source._parallelInputs
      _completedParallelInputs = source._completedParallelInputs
      _status = source._status
      _steps = source._steps
      _slotMs = source._slotMs
      _computeMode = source._computeMode
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._name) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._id) }()
        case 3: try { try decoder.decodeSingularInt64Field(value: &_storage._startMs) }()
        case 4: try { try decoder.decodeSingularInt64Field(value: &_storage._endMs) }()
        case 5: try { try decoder.decodeRepeatedInt64Field(value: &_storage._inputStages) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._waitRatioAvg) }()
        case 7: try { try decoder.decodeSingularMessageField(value: &_storage._waitMsAvg) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._waitRatioMax) }()
        case 9: try { try decoder.decodeSingularMessageField(value: &_storage._waitMsMax) }()
        case 10: try { try decoder.decodeSingularMessageField(value: &_storage._readRatioAvg) }()
        case 11: try { try decoder.decodeSingularMessageField(value: &_storage._readMsAvg) }()
        case 12: try { try decoder.decodeSingularMessageField(value: &_storage._readRatioMax) }()
        case 13: try { try decoder.decodeSingularMessageField(value: &_storage._readMsMax) }()
        case 14: try { try decoder.decodeSingularMessageField(value: &_storage._computeRatioAvg) }()
        case 15: try { try decoder.decodeSingularMessageField(value: &_storage._computeMsAvg) }()
        case 16: try { try decoder.decodeSingularMessageField(value: &_storage._computeRatioMax) }()
        case 17: try { try decoder.decodeSingularMessageField(value: &_storage._computeMsMax) }()
        case 18: try { try decoder.decodeSingularMessageField(value: &_storage._writeRatioAvg) }()
        case 19: try { try decoder.decodeSingularMessageField(value: &_storage._writeMsAvg) }()
        case 20: try { try decoder.decodeSingularMessageField(value: &_storage._writeRatioMax) }()
        case 21: try { try decoder.decodeSingularMessageField(value: &_storage._writeMsMax) }()
        case 22: try { try decoder.decodeSingularMessageField(value: &_storage._shuffleOutputBytes) }()
        case 23: try { try decoder.decodeSingularMessageField(value: &_storage._shuffleOutputBytesSpilled) }()
        case 24: try { try decoder.decodeSingularMessageField(value: &_storage._recordsRead) }()
        case 25: try { try decoder.decodeSingularMessageField(value: &_storage._recordsWritten) }()
        case 26: try { try decoder.decodeSingularMessageField(value: &_storage._parallelInputs) }()
        case 27: try { try decoder.decodeSingularMessageField(value: &_storage._completedParallelInputs) }()
        case 28: try { try decoder.decodeSingularStringField(value: &_storage._status) }()
        case 29: try { try decoder.decodeRepeatedMessageField(value: &_storage._steps) }()
        case 30: try { try decoder.decodeSingularMessageField(value: &_storage._slotMs) }()
        case 31: try { try decoder.decodeSingularEnumField(value: &_storage._computeMode) }()
        default: break
        }
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if !_storage._name.isEmpty {
        try visitor.visitSingularStringField(value: _storage._name, fieldNumber: 1)
      }
      try { if let v = _storage._id {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      } }()
      if _storage._startMs != 0 {
        try visitor.visitSingularInt64Field(value: _storage._startMs, fieldNumber: 3)
      }
      if _storage._endMs != 0 {
        try visitor.visitSingularInt64Field(value: _storage._endMs, fieldNumber: 4)
      }
      if !_storage._inputStages.isEmpty {
        try visitor.visitPackedInt64Field(value: _storage._inputStages, fieldNumber: 5)
      }
      try { if let v = _storage._waitRatioAvg {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      } }()
      try { if let v = _storage._waitMsAvg {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      } }()
      try { if let v = _storage._waitRatioMax {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      } }()
      try { if let v = _storage._waitMsMax {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      } }()
      try { if let v = _storage._readRatioAvg {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
      } }()
      try { if let v = _storage._readMsAvg {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
      } }()
      try { if let v = _storage._readRatioMax {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 12)
      } }()
      try { if let v = _storage._readMsMax {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 13)
      } }()
      try { if let v = _storage._computeRatioAvg {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 14)
      } }()
      try { if let v = _storage._computeMsAvg {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 15)
      } }()
      try { if let v = _storage._computeRatioMax {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 16)
      } }()
      try { if let v = _storage._computeMsMax {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 17)
      } }()
      try { if let v = _storage._writeRatioAvg {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 18)
      } }()
      try { if let v = _storage._writeMsAvg {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 19)
      } }()
      try { if let v = _storage._writeRatioMax {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 20)
      } }()
      try { if let v = _storage._writeMsMax {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 21)
      } }()
      try { if let v = _storage._shuffleOutputBytes {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 22)
      } }()
      try { if let v = _storage._shuffleOutputBytesSpilled {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 23)
      } }()
      try { if let v = _storage._recordsRead {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 24)
      } }()
      try { if let v = _storage._recordsWritten {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 25)
      } }()
      try { if let v = _storage._parallelInputs {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 26)
      } }()
      try { if let v = _storage._completedParallelInputs {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 27)
      } }()
      if !_storage._status.isEmpty {
        try visitor.visitSingularStringField(value: _storage._status, fieldNumber: 28)
      }
      if !_storage._steps.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._steps, fieldNumber: 29)
      }
      try { if let v = _storage._slotMs {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 30)
      } }()
      if _storage._computeMode != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._computeMode, fieldNumber: 31)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_ExplainQueryStage, rhs: Google_Cloud_Bigquery_V2_ExplainQueryStage) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._name != rhs_storage._name {return false}
        if _storage._id != rhs_storage._id {return false}
        if _storage._startMs != rhs_storage._startMs {return false}
        if _storage._endMs != rhs_storage._endMs {return false}
        if _storage._inputStages != rhs_storage._inputStages {return false}
        if _storage._waitRatioAvg != rhs_storage._waitRatioAvg {return false}
        if _storage._waitMsAvg != rhs_storage._waitMsAvg {return false}
        if _storage._waitRatioMax != rhs_storage._waitRatioMax {return false}
        if _storage._waitMsMax != rhs_storage._waitMsMax {return false}
        if _storage._readRatioAvg != rhs_storage._readRatioAvg {return false}
        if _storage._readMsAvg != rhs_storage._readMsAvg {return false}
        if _storage._readRatioMax != rhs_storage._readRatioMax {return false}
        if _storage._readMsMax != rhs_storage._readMsMax {return false}
        if _storage._computeRatioAvg != rhs_storage._computeRatioAvg {return false}
        if _storage._computeMsAvg != rhs_storage._computeMsAvg {return false}
        if _storage._computeRatioMax != rhs_storage._computeRatioMax {return false}
        if _storage._computeMsMax != rhs_storage._computeMsMax {return false}
        if _storage._writeRatioAvg != rhs_storage._writeRatioAvg {return false}
        if _storage._writeMsAvg != rhs_storage._writeMsAvg {return false}
        if _storage._writeRatioMax != rhs_storage._writeRatioMax {return false}
        if _storage._writeMsMax != rhs_storage._writeMsMax {return false}
        if _storage._shuffleOutputBytes != rhs_storage._shuffleOutputBytes {return false}
        if _storage._shuffleOutputBytesSpilled != rhs_storage._shuffleOutputBytesSpilled {return false}
        if _storage._recordsRead != rhs_storage._recordsRead {return false}
        if _storage._recordsWritten != rhs_storage._recordsWritten {return false}
        if _storage._parallelInputs != rhs_storage._parallelInputs {return false}
        if _storage._completedParallelInputs != rhs_storage._completedParallelInputs {return false}
        if _storage._status != rhs_storage._status {return false}
        if _storage._steps != rhs_storage._steps {return false}
        if _storage._slotMs != rhs_storage._slotMs {return false}
        if _storage._computeMode != rhs_storage._computeMode {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_ExplainQueryStage.ComputeMode: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "COMPUTE_MODE_UNSPECIFIED"),
    1: .same(proto: "BIGQUERY"),
    2: .same(proto: "BI_ENGINE"),
  ]
}

extension Google_Cloud_Bigquery_V2_QueryTimelineSample: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".QueryTimelineSample"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "elapsed_ms"),
    2: .standard(proto: "total_slot_ms"),
    3: .standard(proto: "pending_units"),
    4: .standard(proto: "completed_units"),
    5: .standard(proto: "active_units"),
    7: .standard(proto: "estimated_runnable_units"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._elapsedMs) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._totalSlotMs) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._pendingUnits) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._completedUnits) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._activeUnits) }()
      case 7: try { try decoder.decodeSingularMessageField(value: &self._estimatedRunnableUnits) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._elapsedMs {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._totalSlotMs {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._pendingUnits {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._completedUnits {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try { if let v = self._activeUnits {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    try { if let v = self._estimatedRunnableUnits {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_QueryTimelineSample, rhs: Google_Cloud_Bigquery_V2_QueryTimelineSample) -> Bool {
    if lhs._elapsedMs != rhs._elapsedMs {return false}
    if lhs._totalSlotMs != rhs._totalSlotMs {return false}
    if lhs._pendingUnits != rhs._pendingUnits {return false}
    if lhs._completedUnits != rhs._completedUnits {return false}
    if lhs._activeUnits != rhs._activeUnits {return false}
    if lhs._estimatedRunnableUnits != rhs._estimatedRunnableUnits {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_ExternalServiceCost: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".ExternalServiceCost"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "external_service"),
    2: .standard(proto: "bytes_processed"),
    3: .standard(proto: "bytes_billed"),
    4: .standard(proto: "slot_ms"),
    5: .standard(proto: "reserved_slot_count"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.externalService) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._bytesProcessed) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._bytesBilled) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._slotMs) }()
      case 5: try { try decoder.decodeSingularInt64Field(value: &self.reservedSlotCount) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.externalService.isEmpty {
      try visitor.visitSingularStringField(value: self.externalService, fieldNumber: 1)
    }
    try { if let v = self._bytesProcessed {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._bytesBilled {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._slotMs {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    if self.reservedSlotCount != 0 {
      try visitor.visitSingularInt64Field(value: self.reservedSlotCount, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_ExternalServiceCost, rhs: Google_Cloud_Bigquery_V2_ExternalServiceCost) -> Bool {
    if lhs.externalService != rhs.externalService {return false}
    if lhs._bytesProcessed != rhs._bytesProcessed {return false}
    if lhs._bytesBilled != rhs._bytesBilled {return false}
    if lhs._slotMs != rhs._slotMs {return false}
    if lhs.reservedSlotCount != rhs.reservedSlotCount {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_ExportDataStatistics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".ExportDataStatistics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "file_count"),
    2: .standard(proto: "row_count"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._fileCount) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._rowCount) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._fileCount {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._rowCount {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_ExportDataStatistics, rhs: Google_Cloud_Bigquery_V2_ExportDataStatistics) -> Bool {
    if lhs._fileCount != rhs._fileCount {return false}
    if lhs._rowCount != rhs._rowCount {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_BiEngineReason: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".BiEngineReason"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "code"),
    2: .same(proto: "message"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.code) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.message) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.code != .unspecified {
      try visitor.visitSingularEnumField(value: self.code, fieldNumber: 1)
    }
    if !self.message.isEmpty {
      try visitor.visitSingularStringField(value: self.message, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_BiEngineReason, rhs: Google_Cloud_Bigquery_V2_BiEngineReason) -> Bool {
    if lhs.code != rhs.code {return false}
    if lhs.message != rhs.message {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_BiEngineReason.Code: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "CODE_UNSPECIFIED"),
    1: .same(proto: "NO_RESERVATION"),
    2: .same(proto: "INSUFFICIENT_RESERVATION"),
    4: .same(proto: "UNSUPPORTED_SQL_TEXT"),
    5: .same(proto: "INPUT_TOO_LARGE"),
    6: .same(proto: "OTHER_REASON"),
    7: .same(proto: "TABLE_EXCLUDED"),
  ]
}

extension Google_Cloud_Bigquery_V2_BiEngineStatistics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".BiEngineStatistics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "bi_engine_mode"),
    3: .standard(proto: "acceleration_mode"),
    2: .standard(proto: "bi_engine_reasons"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.biEngineMode) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.biEngineReasons) }()
      case 3: try { try decoder.decodeSingularEnumField(value: &self.accelerationMode) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.biEngineMode != .accelerationModeUnspecified {
      try visitor.visitSingularEnumField(value: self.biEngineMode, fieldNumber: 1)
    }
    if !self.biEngineReasons.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.biEngineReasons, fieldNumber: 2)
    }
    if self.accelerationMode != .unspecified {
      try visitor.visitSingularEnumField(value: self.accelerationMode, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_BiEngineStatistics, rhs: Google_Cloud_Bigquery_V2_BiEngineStatistics) -> Bool {
    if lhs.biEngineMode != rhs.biEngineMode {return false}
    if lhs.accelerationMode != rhs.accelerationMode {return false}
    if lhs.biEngineReasons != rhs.biEngineReasons {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_BiEngineStatistics.BiEngineMode: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "ACCELERATION_MODE_UNSPECIFIED"),
    1: .same(proto: "DISABLED"),
    2: .same(proto: "PARTIAL"),
    3: .same(proto: "FULL"),
  ]
}

extension Google_Cloud_Bigquery_V2_BiEngineStatistics.BiEngineAccelerationMode: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "BI_ENGINE_ACCELERATION_MODE_UNSPECIFIED"),
    1: .same(proto: "BI_ENGINE_DISABLED"),
    2: .same(proto: "PARTIAL_INPUT"),
    3: .same(proto: "FULL_INPUT"),
    4: .same(proto: "FULL_QUERY"),
  ]
}

extension Google_Cloud_Bigquery_V2_IndexUnusedReason: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".IndexUnusedReason"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "code"),
    2: .same(proto: "message"),
    3: .standard(proto: "base_table"),
    4: .standard(proto: "index_name"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self._code) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self._message) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._baseTable) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self._indexName) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._code {
      try visitor.visitSingularEnumField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._message {
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._baseTable {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._indexName {
      try visitor.visitSingularStringField(value: v, fieldNumber: 4)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_IndexUnusedReason, rhs: Google_Cloud_Bigquery_V2_IndexUnusedReason) -> Bool {
    if lhs._code != rhs._code {return false}
    if lhs._message != rhs._message {return false}
    if lhs._baseTable != rhs._baseTable {return false}
    if lhs._indexName != rhs._indexName {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_IndexUnusedReason.Code: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "CODE_UNSPECIFIED"),
    1: .same(proto: "INDEX_CONFIG_NOT_AVAILABLE"),
    2: .same(proto: "PENDING_INDEX_CREATION"),
    3: .same(proto: "BASE_TABLE_TRUNCATED"),
    4: .same(proto: "INDEX_CONFIG_MODIFIED"),
    5: .same(proto: "TIME_TRAVEL_QUERY"),
    6: .same(proto: "NO_PRUNING_POWER"),
    7: .same(proto: "UNINDEXED_SEARCH_FIELDS"),
    8: .same(proto: "UNSUPPORTED_SEARCH_PATTERN"),
    9: .same(proto: "OPTIMIZED_WITH_MATERIALIZED_VIEW"),
    10: .same(proto: "INTERNAL_ERROR"),
    11: .same(proto: "SECURED_BY_DATA_MASKING"),
    12: .same(proto: "MISMATCHED_TEXT_ANALYZER"),
    13: .same(proto: "BASE_TABLE_TOO_SMALL"),
    14: .same(proto: "BASE_TABLE_TOO_LARGE"),
    15: .same(proto: "ESTIMATED_PERFORMANCE_GAIN_TOO_LOW"),
    16: .same(proto: "OTHER_REASON"),
    17: .same(proto: "NOT_SUPPORTED_IN_STANDARD_EDITION"),
    18: .same(proto: "INDEX_SUPPRESSED_BY_FUNCTION_OPTION"),
    19: .same(proto: "QUERY_CACHE_HIT"),
    20: .same(proto: "STALE_INDEX"),
  ]
}

extension Google_Cloud_Bigquery_V2_SearchStatistics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".SearchStatistics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "index_usage_mode"),
    2: .standard(proto: "index_unused_reasons"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.indexUsageMode) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.indexUnusedReasons) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.indexUsageMode != .unspecified {
      try visitor.visitSingularEnumField(value: self.indexUsageMode, fieldNumber: 1)
    }
    if !self.indexUnusedReasons.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.indexUnusedReasons, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_SearchStatistics, rhs: Google_Cloud_Bigquery_V2_SearchStatistics) -> Bool {
    if lhs.indexUsageMode != rhs.indexUsageMode {return false}
    if lhs.indexUnusedReasons != rhs.indexUnusedReasons {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_SearchStatistics.IndexUsageMode: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "INDEX_USAGE_MODE_UNSPECIFIED"),
    1: .same(proto: "UNUSED"),
    2: .same(proto: "PARTIALLY_USED"),
    4: .same(proto: "FULLY_USED"),
  ]
}

extension Google_Cloud_Bigquery_V2_VectorSearchStatistics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".VectorSearchStatistics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "index_usage_mode"),
    2: .standard(proto: "index_unused_reasons"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.indexUsageMode) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.indexUnusedReasons) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.indexUsageMode != .unspecified {
      try visitor.visitSingularEnumField(value: self.indexUsageMode, fieldNumber: 1)
    }
    if !self.indexUnusedReasons.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.indexUnusedReasons, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_VectorSearchStatistics, rhs: Google_Cloud_Bigquery_V2_VectorSearchStatistics) -> Bool {
    if lhs.indexUsageMode != rhs.indexUsageMode {return false}
    if lhs.indexUnusedReasons != rhs.indexUnusedReasons {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_VectorSearchStatistics.IndexUsageMode: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "INDEX_USAGE_MODE_UNSPECIFIED"),
    1: .same(proto: "UNUSED"),
    2: .same(proto: "PARTIALLY_USED"),
    4: .same(proto: "FULLY_USED"),
  ]
}

extension Google_Cloud_Bigquery_V2_QueryInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".QueryInfo"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    2: .standard(proto: "optimization_details"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 2: try { try decoder.decodeSingularMessageField(value: &self._optimizationDetails) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._optimizationDetails {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_QueryInfo, rhs: Google_Cloud_Bigquery_V2_QueryInfo) -> Bool {
    if lhs._optimizationDetails != rhs._optimizationDetails {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_LoadQueryStatistics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".LoadQueryStatistics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "input_files"),
    2: .standard(proto: "input_file_bytes"),
    3: .standard(proto: "output_rows"),
    4: .standard(proto: "output_bytes"),
    5: .standard(proto: "bad_records"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._inputFiles) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._inputFileBytes) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._outputRows) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._outputBytes) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._badRecords) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._inputFiles {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._inputFileBytes {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._outputRows {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._outputBytes {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try { if let v = self._badRecords {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_LoadQueryStatistics, rhs: Google_Cloud_Bigquery_V2_LoadQueryStatistics) -> Bool {
    if lhs._inputFiles != rhs._inputFiles {return false}
    if lhs._inputFileBytes != rhs._inputFileBytes {return false}
    if lhs._outputRows != rhs._outputRows {return false}
    if lhs._outputBytes != rhs._outputBytes {return false}
    if lhs._badRecords != rhs._badRecords {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_JobStatistics2: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".JobStatistics2"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "query_plan"),
    2: .standard(proto: "estimated_bytes_processed"),
    3: .same(proto: "timeline"),
    4: .standard(proto: "total_partitions_processed"),
    5: .standard(proto: "total_bytes_processed"),
    21: .standard(proto: "total_bytes_processed_accuracy"),
    6: .standard(proto: "total_bytes_billed"),
    7: .standard(proto: "billing_tier"),
    8: .standard(proto: "total_slot_ms"),
    9: .standard(proto: "cache_hit"),
    10: .standard(proto: "referenced_tables"),
    24: .standard(proto: "referenced_routines"),
    11: .same(proto: "schema"),
    12: .standard(proto: "num_dml_affected_rows"),
    32: .standard(proto: "dml_stats"),
    13: .standard(proto: "undeclared_query_parameters"),
    14: .standard(proto: "statement_type"),
    15: .standard(proto: "ddl_operation_performed"),
    16: .standard(proto: "ddl_target_table"),
    31: .standard(proto: "ddl_destination_table"),
    26: .standard(proto: "ddl_target_row_access_policy"),
    27: .standard(proto: "ddl_affected_row_access_policy_count"),
    22: .standard(proto: "ddl_target_routine"),
    30: .standard(proto: "ddl_target_dataset"),
    23: .standard(proto: "ml_statistics"),
    25: .standard(proto: "export_data_statistics"),
    28: .standard(proto: "external_service_costs"),
    29: .standard(proto: "bi_engine_statistics"),
    33: .standard(proto: "load_query_statistics"),
    34: .standard(proto: "dcl_target_table"),
    35: .standard(proto: "dcl_target_view"),
    36: .standard(proto: "dcl_target_dataset"),
    37: .standard(proto: "search_statistics"),
    44: .standard(proto: "vector_search_statistics"),
    38: .standard(proto: "performance_insights"),
    39: .standard(proto: "query_info"),
    40: .standard(proto: "spark_statistics"),
    41: .standard(proto: "transferred_bytes"),
    42: .standard(proto: "materialized_view_statistics"),
    43: .standard(proto: "metadata_cache_statistics"),
  ]

  fileprivate class _StorageClass {
    var _queryPlan: [Google_Cloud_Bigquery_V2_ExplainQueryStage] = []
    var _estimatedBytesProcessed: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _timeline: [Google_Cloud_Bigquery_V2_QueryTimelineSample] = []
    var _totalPartitionsProcessed: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _totalBytesProcessed: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _totalBytesProcessedAccuracy: String = String()
    var _totalBytesBilled: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _billingTier: SwiftProtobuf.Google_Protobuf_Int32Value? = nil
    var _totalSlotMs: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _cacheHit: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _referencedTables: [Google_Cloud_Bigquery_V2_TableReference] = []
    var _referencedRoutines: [Google_Cloud_Bigquery_V2_RoutineReference] = []
    var _schema: Google_Cloud_Bigquery_V2_TableSchema? = nil
    var _numDmlAffectedRows: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _dmlStats: Google_Cloud_Bigquery_V2_DmlStats? = nil
    var _undeclaredQueryParameters: [Google_Cloud_Bigquery_V2_QueryParameter] = []
    var _statementType: String = String()
    var _ddlOperationPerformed: String = String()
    var _ddlTargetTable: Google_Cloud_Bigquery_V2_TableReference? = nil
    var _ddlDestinationTable: Google_Cloud_Bigquery_V2_TableReference? = nil
    var _ddlTargetRowAccessPolicy: Google_Cloud_Bigquery_V2_RowAccessPolicyReference? = nil
    var _ddlAffectedRowAccessPolicyCount: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _ddlTargetRoutine: Google_Cloud_Bigquery_V2_RoutineReference? = nil
    var _ddlTargetDataset: Google_Cloud_Bigquery_V2_DatasetReference? = nil
    var _mlStatistics: Google_Cloud_Bigquery_V2_MlStatistics? = nil
    var _exportDataStatistics: Google_Cloud_Bigquery_V2_ExportDataStatistics? = nil
    var _externalServiceCosts: [Google_Cloud_Bigquery_V2_ExternalServiceCost] = []
    var _biEngineStatistics: Google_Cloud_Bigquery_V2_BiEngineStatistics? = nil
    var _loadQueryStatistics: Google_Cloud_Bigquery_V2_LoadQueryStatistics? = nil
    var _dclTargetTable: Google_Cloud_Bigquery_V2_TableReference? = nil
    var _dclTargetView: Google_Cloud_Bigquery_V2_TableReference? = nil
    var _dclTargetDataset: Google_Cloud_Bigquery_V2_DatasetReference? = nil
    var _searchStatistics: Google_Cloud_Bigquery_V2_SearchStatistics? = nil
    var _vectorSearchStatistics: Google_Cloud_Bigquery_V2_VectorSearchStatistics? = nil
    var _performanceInsights: Google_Cloud_Bigquery_V2_PerformanceInsights? = nil
    var _queryInfo: Google_Cloud_Bigquery_V2_QueryInfo? = nil
    var _sparkStatistics: Google_Cloud_Bigquery_V2_SparkStatistics? = nil
    var _transferredBytes: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _materializedViewStatistics: Google_Cloud_Bigquery_V2_MaterializedViewStatistics? = nil
    var _metadataCacheStatistics: Google_Cloud_Bigquery_V2_MetadataCacheStatistics? = nil

    #if swift(>=5.10)
      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()
    #else
      static let defaultInstance = _StorageClass()
    #endif

    private init() {}

    init(copying source: _StorageClass) {
      _queryPlan = source._queryPlan
      _estimatedBytesProcessed = source._estimatedBytesProcessed
      _timeline = source._timeline
      _totalPartitionsProcessed = source._totalPartitionsProcessed
      _totalBytesProcessed = source._totalBytesProcessed
      _totalBytesProcessedAccuracy = source._totalBytesProcessedAccuracy
      _totalBytesBilled = source._totalBytesBilled
      _billingTier = source._billingTier
      _totalSlotMs = source._totalSlotMs
      _cacheHit = source._cacheHit
      _referencedTables = source._referencedTables
      _referencedRoutines = source._referencedRoutines
      _schema = source._schema
      _numDmlAffectedRows = source._numDmlAffectedRows
      _dmlStats = source._dmlStats
      _undeclaredQueryParameters = source._undeclaredQueryParameters
      _statementType = source._statementType
      _ddlOperationPerformed = source._ddlOperationPerformed
      _ddlTargetTable = source._ddlTargetTable
      _ddlDestinationTable = source._ddlDestinationTable
      _ddlTargetRowAccessPolicy = source._ddlTargetRowAccessPolicy
      _ddlAffectedRowAccessPolicyCount = source._ddlAffectedRowAccessPolicyCount
      _ddlTargetRoutine = source._ddlTargetRoutine
      _ddlTargetDataset = source._ddlTargetDataset
      _mlStatistics = source._mlStatistics
      _exportDataStatistics = source._exportDataStatistics
      _externalServiceCosts = source._externalServiceCosts
      _biEngineStatistics = source._biEngineStatistics
      _loadQueryStatistics = source._loadQueryStatistics
      _dclTargetTable = source._dclTargetTable
      _dclTargetView = source._dclTargetView
      _dclTargetDataset = source._dclTargetDataset
      _searchStatistics = source._searchStatistics
      _vectorSearchStatistics = source._vectorSearchStatistics
      _performanceInsights = source._performanceInsights
      _queryInfo = source._queryInfo
      _sparkStatistics = source._sparkStatistics
      _transferredBytes = source._transferredBytes
      _materializedViewStatistics = source._materializedViewStatistics
      _metadataCacheStatistics = source._metadataCacheStatistics
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeRepeatedMessageField(value: &_storage._queryPlan) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._estimatedBytesProcessed) }()
        case 3: try { try decoder.decodeRepeatedMessageField(value: &_storage._timeline) }()
        case 4: try { try decoder.decodeSingularMessageField(value: &_storage._totalPartitionsProcessed) }()
        case 5: try { try decoder.decodeSingularMessageField(value: &_storage._totalBytesProcessed) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._totalBytesBilled) }()
        case 7: try { try decoder.decodeSingularMessageField(value: &_storage._billingTier) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._totalSlotMs) }()
        case 9: try { try decoder.decodeSingularMessageField(value: &_storage._cacheHit) }()
        case 10: try { try decoder.decodeRepeatedMessageField(value: &_storage._referencedTables) }()
        case 11: try { try decoder.decodeSingularMessageField(value: &_storage._schema) }()
        case 12: try { try decoder.decodeSingularMessageField(value: &_storage._numDmlAffectedRows) }()
        case 13: try { try decoder.decodeRepeatedMessageField(value: &_storage._undeclaredQueryParameters) }()
        case 14: try { try decoder.decodeSingularStringField(value: &_storage._statementType) }()
        case 15: try { try decoder.decodeSingularStringField(value: &_storage._ddlOperationPerformed) }()
        case 16: try { try decoder.decodeSingularMessageField(value: &_storage._ddlTargetTable) }()
        case 21: try { try decoder.decodeSingularStringField(value: &_storage._totalBytesProcessedAccuracy) }()
        case 22: try { try decoder.decodeSingularMessageField(value: &_storage._ddlTargetRoutine) }()
        case 23: try { try decoder.decodeSingularMessageField(value: &_storage._mlStatistics) }()
        case 24: try { try decoder.decodeRepeatedMessageField(value: &_storage._referencedRoutines) }()
        case 25: try { try decoder.decodeSingularMessageField(value: &_storage._exportDataStatistics) }()
        case 26: try { try decoder.decodeSingularMessageField(value: &_storage._ddlTargetRowAccessPolicy) }()
        case 27: try { try decoder.decodeSingularMessageField(value: &_storage._ddlAffectedRowAccessPolicyCount) }()
        case 28: try { try decoder.decodeRepeatedMessageField(value: &_storage._externalServiceCosts) }()
        case 29: try { try decoder.decodeSingularMessageField(value: &_storage._biEngineStatistics) }()
        case 30: try { try decoder.decodeSingularMessageField(value: &_storage._ddlTargetDataset) }()
        case 31: try { try decoder.decodeSingularMessageField(value: &_storage._ddlDestinationTable) }()
        case 32: try { try decoder.decodeSingularMessageField(value: &_storage._dmlStats) }()
        case 33: try { try decoder.decodeSingularMessageField(value: &_storage._loadQueryStatistics) }()
        case 34: try { try decoder.decodeSingularMessageField(value: &_storage._dclTargetTable) }()
        case 35: try { try decoder.decodeSingularMessageField(value: &_storage._dclTargetView) }()
        case 36: try { try decoder.decodeSingularMessageField(value: &_storage._dclTargetDataset) }()
        case 37: try { try decoder.decodeSingularMessageField(value: &_storage._searchStatistics) }()
        case 38: try { try decoder.decodeSingularMessageField(value: &_storage._performanceInsights) }()
        case 39: try { try decoder.decodeSingularMessageField(value: &_storage._queryInfo) }()
        case 40: try { try decoder.decodeSingularMessageField(value: &_storage._sparkStatistics) }()
        case 41: try { try decoder.decodeSingularMessageField(value: &_storage._transferredBytes) }()
        case 42: try { try decoder.decodeSingularMessageField(value: &_storage._materializedViewStatistics) }()
        case 43: try { try decoder.decodeSingularMessageField(value: &_storage._metadataCacheStatistics) }()
        case 44: try { try decoder.decodeSingularMessageField(value: &_storage._vectorSearchStatistics) }()
        default: break
        }
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if !_storage._queryPlan.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._queryPlan, fieldNumber: 1)
      }
      try { if let v = _storage._estimatedBytesProcessed {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      } }()
      if !_storage._timeline.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._timeline, fieldNumber: 3)
      }
      try { if let v = _storage._totalPartitionsProcessed {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      } }()
      try { if let v = _storage._totalBytesProcessed {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
      } }()
      try { if let v = _storage._totalBytesBilled {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      } }()
      try { if let v = _storage._billingTier {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      } }()
      try { if let v = _storage._totalSlotMs {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      } }()
      try { if let v = _storage._cacheHit {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      } }()
      if !_storage._referencedTables.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._referencedTables, fieldNumber: 10)
      }
      try { if let v = _storage._schema {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
      } }()
      try { if let v = _storage._numDmlAffectedRows {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 12)
      } }()
      if !_storage._undeclaredQueryParameters.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._undeclaredQueryParameters, fieldNumber: 13)
      }
      if !_storage._statementType.isEmpty {
        try visitor.visitSingularStringField(value: _storage._statementType, fieldNumber: 14)
      }
      if !_storage._ddlOperationPerformed.isEmpty {
        try visitor.visitSingularStringField(value: _storage._ddlOperationPerformed, fieldNumber: 15)
      }
      try { if let v = _storage._ddlTargetTable {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 16)
      } }()
      if !_storage._totalBytesProcessedAccuracy.isEmpty {
        try visitor.visitSingularStringField(value: _storage._totalBytesProcessedAccuracy, fieldNumber: 21)
      }
      try { if let v = _storage._ddlTargetRoutine {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 22)
      } }()
      try { if let v = _storage._mlStatistics {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 23)
      } }()
      if !_storage._referencedRoutines.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._referencedRoutines, fieldNumber: 24)
      }
      try { if let v = _storage._exportDataStatistics {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 25)
      } }()
      try { if let v = _storage._ddlTargetRowAccessPolicy {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 26)
      } }()
      try { if let v = _storage._ddlAffectedRowAccessPolicyCount {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 27)
      } }()
      if !_storage._externalServiceCosts.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._externalServiceCosts, fieldNumber: 28)
      }
      try { if let v = _storage._biEngineStatistics {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 29)
      } }()
      try { if let v = _storage._ddlTargetDataset {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 30)
      } }()
      try { if let v = _storage._ddlDestinationTable {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 31)
      } }()
      try { if let v = _storage._dmlStats {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 32)
      } }()
      try { if let v = _storage._loadQueryStatistics {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 33)
      } }()
      try { if let v = _storage._dclTargetTable {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 34)
      } }()
      try { if let v = _storage._dclTargetView {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 35)
      } }()
      try { if let v = _storage._dclTargetDataset {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 36)
      } }()
      try { if let v = _storage._searchStatistics {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 37)
      } }()
      try { if let v = _storage._performanceInsights {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 38)
      } }()
      try { if let v = _storage._queryInfo {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 39)
      } }()
      try { if let v = _storage._sparkStatistics {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 40)
      } }()
      try { if let v = _storage._transferredBytes {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 41)
      } }()
      try { if let v = _storage._materializedViewStatistics {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 42)
      } }()
      try { if let v = _storage._metadataCacheStatistics {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 43)
      } }()
      try { if let v = _storage._vectorSearchStatistics {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 44)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_JobStatistics2, rhs: Google_Cloud_Bigquery_V2_JobStatistics2) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._queryPlan != rhs_storage._queryPlan {return false}
        if _storage._estimatedBytesProcessed != rhs_storage._estimatedBytesProcessed {return false}
        if _storage._timeline != rhs_storage._timeline {return false}
        if _storage._totalPartitionsProcessed != rhs_storage._totalPartitionsProcessed {return false}
        if _storage._totalBytesProcessed != rhs_storage._totalBytesProcessed {return false}
        if _storage._totalBytesProcessedAccuracy != rhs_storage._totalBytesProcessedAccuracy {return false}
        if _storage._totalBytesBilled != rhs_storage._totalBytesBilled {return false}
        if _storage._billingTier != rhs_storage._billingTier {return false}
        if _storage._totalSlotMs != rhs_storage._totalSlotMs {return false}
        if _storage._cacheHit != rhs_storage._cacheHit {return false}
        if _storage._referencedTables != rhs_storage._referencedTables {return false}
        if _storage._referencedRoutines != rhs_storage._referencedRoutines {return false}
        if _storage._schema != rhs_storage._schema {return false}
        if _storage._numDmlAffectedRows != rhs_storage._numDmlAffectedRows {return false}
        if _storage._dmlStats != rhs_storage._dmlStats {return false}
        if _storage._undeclaredQueryParameters != rhs_storage._undeclaredQueryParameters {return false}
        if _storage._statementType != rhs_storage._statementType {return false}
        if _storage._ddlOperationPerformed != rhs_storage._ddlOperationPerformed {return false}
        if _storage._ddlTargetTable != rhs_storage._ddlTargetTable {return false}
        if _storage._ddlDestinationTable != rhs_storage._ddlDestinationTable {return false}
        if _storage._ddlTargetRowAccessPolicy != rhs_storage._ddlTargetRowAccessPolicy {return false}
        if _storage._ddlAffectedRowAccessPolicyCount != rhs_storage._ddlAffectedRowAccessPolicyCount {return false}
        if _storage._ddlTargetRoutine != rhs_storage._ddlTargetRoutine {return false}
        if _storage._ddlTargetDataset != rhs_storage._ddlTargetDataset {return false}
        if _storage._mlStatistics != rhs_storage._mlStatistics {return false}
        if _storage._exportDataStatistics != rhs_storage._exportDataStatistics {return false}
        if _storage._externalServiceCosts != rhs_storage._externalServiceCosts {return false}
        if _storage._biEngineStatistics != rhs_storage._biEngineStatistics {return false}
        if _storage._loadQueryStatistics != rhs_storage._loadQueryStatistics {return false}
        if _storage._dclTargetTable != rhs_storage._dclTargetTable {return false}
        if _storage._dclTargetView != rhs_storage._dclTargetView {return false}
        if _storage._dclTargetDataset != rhs_storage._dclTargetDataset {return false}
        if _storage._searchStatistics != rhs_storage._searchStatistics {return false}
        if _storage._vectorSearchStatistics != rhs_storage._vectorSearchStatistics {return false}
        if _storage._performanceInsights != rhs_storage._performanceInsights {return false}
        if _storage._queryInfo != rhs_storage._queryInfo {return false}
        if _storage._sparkStatistics != rhs_storage._sparkStatistics {return false}
        if _storage._transferredBytes != rhs_storage._transferredBytes {return false}
        if _storage._materializedViewStatistics != rhs_storage._materializedViewStatistics {return false}
        if _storage._metadataCacheStatistics != rhs_storage._metadataCacheStatistics {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_JobStatistics3: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".JobStatistics3"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "input_files"),
    2: .standard(proto: "input_file_bytes"),
    3: .standard(proto: "output_rows"),
    4: .standard(proto: "output_bytes"),
    5: .standard(proto: "bad_records"),
    7: .same(proto: "timeline"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._inputFiles) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._inputFileBytes) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._outputRows) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._outputBytes) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._badRecords) }()
      case 7: try { try decoder.decodeRepeatedMessageField(value: &self.timeline) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._inputFiles {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._inputFileBytes {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._outputRows {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._outputBytes {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try { if let v = self._badRecords {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    if !self.timeline.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.timeline, fieldNumber: 7)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_JobStatistics3, rhs: Google_Cloud_Bigquery_V2_JobStatistics3) -> Bool {
    if lhs._inputFiles != rhs._inputFiles {return false}
    if lhs._inputFileBytes != rhs._inputFileBytes {return false}
    if lhs._outputRows != rhs._outputRows {return false}
    if lhs._outputBytes != rhs._outputBytes {return false}
    if lhs._badRecords != rhs._badRecords {return false}
    if lhs.timeline != rhs.timeline {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_JobStatistics4: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".JobStatistics4"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "destination_uri_file_counts"),
    2: .standard(proto: "input_bytes"),
    3: .same(proto: "timeline"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedInt64Field(value: &self.destinationUriFileCounts) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._inputBytes) }()
      case 3: try { try decoder.decodeRepeatedMessageField(value: &self.timeline) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.destinationUriFileCounts.isEmpty {
      try visitor.visitPackedInt64Field(value: self.destinationUriFileCounts, fieldNumber: 1)
    }
    try { if let v = self._inputBytes {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if !self.timeline.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.timeline, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_JobStatistics4, rhs: Google_Cloud_Bigquery_V2_JobStatistics4) -> Bool {
    if lhs.destinationUriFileCounts != rhs.destinationUriFileCounts {return false}
    if lhs._inputBytes != rhs._inputBytes {return false}
    if lhs.timeline != rhs.timeline {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_CopyJobStatistics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".CopyJobStatistics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "copied_rows"),
    2: .standard(proto: "copied_logical_bytes"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._copiedRows) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._copiedLogicalBytes) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._copiedRows {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._copiedLogicalBytes {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_CopyJobStatistics, rhs: Google_Cloud_Bigquery_V2_CopyJobStatistics) -> Bool {
    if lhs._copiedRows != rhs._copiedRows {return false}
    if lhs._copiedLogicalBytes != rhs._copiedLogicalBytes {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_MlStatistics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".MlStatistics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "max_iterations"),
    2: .standard(proto: "iteration_results"),
    3: .standard(proto: "model_type"),
    4: .standard(proto: "training_type"),
    5: .standard(proto: "hparam_trials"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.maxIterations) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.iterationResults) }()
      case 3: try { try decoder.decodeSingularEnumField(value: &self.modelType) }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self.trainingType) }()
      case 5: try { try decoder.decodeRepeatedMessageField(value: &self.hparamTrials) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.maxIterations != 0 {
      try visitor.visitSingularInt64Field(value: self.maxIterations, fieldNumber: 1)
    }
    if !self.iterationResults.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.iterationResults, fieldNumber: 2)
    }
    if self.modelType != .unspecified {
      try visitor.visitSingularEnumField(value: self.modelType, fieldNumber: 3)
    }
    if self.trainingType != .unspecified {
      try visitor.visitSingularEnumField(value: self.trainingType, fieldNumber: 4)
    }
    if !self.hparamTrials.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.hparamTrials, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_MlStatistics, rhs: Google_Cloud_Bigquery_V2_MlStatistics) -> Bool {
    if lhs.maxIterations != rhs.maxIterations {return false}
    if lhs.iterationResults != rhs.iterationResults {return false}
    if lhs.modelType != rhs.modelType {return false}
    if lhs.trainingType != rhs.trainingType {return false}
    if lhs.hparamTrials != rhs.hparamTrials {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_MlStatistics.TrainingType: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "TRAINING_TYPE_UNSPECIFIED"),
    1: .same(proto: "SINGLE_TRAINING"),
    2: .same(proto: "HPARAM_TUNING"),
  ]
}

extension Google_Cloud_Bigquery_V2_ScriptStatistics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".ScriptStatistics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "evaluation_kind"),
    2: .standard(proto: "stack_frames"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.evaluationKind) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.stackFrames) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.evaluationKind != .unspecified {
      try visitor.visitSingularEnumField(value: self.evaluationKind, fieldNumber: 1)
    }
    if !self.stackFrames.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.stackFrames, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_ScriptStatistics, rhs: Google_Cloud_Bigquery_V2_ScriptStatistics) -> Bool {
    if lhs.evaluationKind != rhs.evaluationKind {return false}
    if lhs.stackFrames != rhs.stackFrames {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_ScriptStatistics.EvaluationKind: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "EVALUATION_KIND_UNSPECIFIED"),
    1: .same(proto: "STATEMENT"),
    2: .same(proto: "EXPRESSION"),
  ]
}

extension Google_Cloud_Bigquery_V2_ScriptStatistics.ScriptStackFrame: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_ScriptStatistics.protoMessageName + ".ScriptStackFrame"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "start_line"),
    2: .standard(proto: "start_column"),
    3: .standard(proto: "end_line"),
    4: .standard(proto: "end_column"),
    5: .standard(proto: "procedure_id"),
    6: .same(proto: "text"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt32Field(value: &self.startLine) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.startColumn) }()
      case 3: try { try decoder.decodeSingularInt32Field(value: &self.endLine) }()
      case 4: try { try decoder.decodeSingularInt32Field(value: &self.endColumn) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self.procedureID) }()
      case 6: try { try decoder.decodeSingularStringField(value: &self.text) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.startLine != 0 {
      try visitor.visitSingularInt32Field(value: self.startLine, fieldNumber: 1)
    }
    if self.startColumn != 0 {
      try visitor.visitSingularInt32Field(value: self.startColumn, fieldNumber: 2)
    }
    if self.endLine != 0 {
      try visitor.visitSingularInt32Field(value: self.endLine, fieldNumber: 3)
    }
    if self.endColumn != 0 {
      try visitor.visitSingularInt32Field(value: self.endColumn, fieldNumber: 4)
    }
    if !self.procedureID.isEmpty {
      try visitor.visitSingularStringField(value: self.procedureID, fieldNumber: 5)
    }
    if !self.text.isEmpty {
      try visitor.visitSingularStringField(value: self.text, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_ScriptStatistics.ScriptStackFrame, rhs: Google_Cloud_Bigquery_V2_ScriptStatistics.ScriptStackFrame) -> Bool {
    if lhs.startLine != rhs.startLine {return false}
    if lhs.startColumn != rhs.startColumn {return false}
    if lhs.endLine != rhs.endLine {return false}
    if lhs.endColumn != rhs.endColumn {return false}
    if lhs.procedureID != rhs.procedureID {return false}
    if lhs.text != rhs.text {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_RowLevelSecurityStatistics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".RowLevelSecurityStatistics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "row_level_security_applied"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBoolField(value: &self.rowLevelSecurityApplied) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.rowLevelSecurityApplied != false {
      try visitor.visitSingularBoolField(value: self.rowLevelSecurityApplied, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_RowLevelSecurityStatistics, rhs: Google_Cloud_Bigquery_V2_RowLevelSecurityStatistics) -> Bool {
    if lhs.rowLevelSecurityApplied != rhs.rowLevelSecurityApplied {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_DataMaskingStatistics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".DataMaskingStatistics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "data_masking_applied"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBoolField(value: &self.dataMaskingApplied) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.dataMaskingApplied != false {
      try visitor.visitSingularBoolField(value: self.dataMaskingApplied, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_DataMaskingStatistics, rhs: Google_Cloud_Bigquery_V2_DataMaskingStatistics) -> Bool {
    if lhs.dataMaskingApplied != rhs.dataMaskingApplied {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_JobStatistics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".JobStatistics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "creation_time"),
    2: .standard(proto: "start_time"),
    3: .standard(proto: "end_time"),
    4: .standard(proto: "total_bytes_processed"),
    5: .standard(proto: "completion_ratio"),
    9: .standard(proto: "quota_deferments"),
    6: .same(proto: "query"),
    7: .same(proto: "load"),
    8: .same(proto: "extract"),
    21: .same(proto: "copy"),
    10: .standard(proto: "total_slot_ms"),
    15: .standard(proto: "reservation_id"),
    12: .standard(proto: "num_child_jobs"),
    13: .standard(proto: "parent_job_id"),
    14: .standard(proto: "script_statistics"),
    16: .standard(proto: "row_level_security_statistics"),
    20: .standard(proto: "data_masking_statistics"),
    17: .standard(proto: "transaction_info"),
    18: .standard(proto: "session_info"),
    22: .standard(proto: "final_execution_duration_ms"),
    24: .same(proto: "edition"),
  ]

  fileprivate class _StorageClass {
    var _creationTime: Int64 = 0
    var _startTime: Int64 = 0
    var _endTime: Int64 = 0
    var _totalBytesProcessed: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _completionRatio: SwiftProtobuf.Google_Protobuf_DoubleValue? = nil
    var _quotaDeferments: [String] = []
    var _query: Google_Cloud_Bigquery_V2_JobStatistics2? = nil
    var _load: Google_Cloud_Bigquery_V2_JobStatistics3? = nil
    var _extract: Google_Cloud_Bigquery_V2_JobStatistics4? = nil
    var _copy: Google_Cloud_Bigquery_V2_CopyJobStatistics? = nil
    var _totalSlotMs: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _reservationID: String = String()
    var _numChildJobs: Int64 = 0
    var _parentJobID: String = String()
    var _scriptStatistics: Google_Cloud_Bigquery_V2_ScriptStatistics? = nil
    var _rowLevelSecurityStatistics: Google_Cloud_Bigquery_V2_RowLevelSecurityStatistics? = nil
    var _dataMaskingStatistics: Google_Cloud_Bigquery_V2_DataMaskingStatistics? = nil
    var _transactionInfo: Google_Cloud_Bigquery_V2_JobStatistics.TransactionInfo? = nil
    var _sessionInfo: Google_Cloud_Bigquery_V2_SessionInfo? = nil
    var _finalExecutionDurationMs: Int64 = 0
    var _edition: Google_Cloud_Bigquery_V2_ReservationEdition = .unspecified

    #if swift(>=5.10)
      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()
    #else
      static let defaultInstance = _StorageClass()
    #endif

    private init() {}

    init(copying source: _StorageClass) {
      _creationTime = source._creationTime
      _startTime = source._startTime
      _endTime = source._endTime
      _totalBytesProcessed = source._totalBytesProcessed
      _completionRatio = source._completionRatio
      _quotaDeferments = source._quotaDeferments
      _query = source._query
      _load = source._load
      _extract = source._extract
      _copy = source._copy
      _totalSlotMs = source._totalSlotMs
      _reservationID = source._reservationID
      _numChildJobs = source._numChildJobs
      _parentJobID = source._parentJobID
      _scriptStatistics = source._scriptStatistics
      _rowLevelSecurityStatistics = source._rowLevelSecurityStatistics
      _dataMaskingStatistics = source._dataMaskingStatistics
      _transactionInfo = source._transactionInfo
      _sessionInfo = source._sessionInfo
      _finalExecutionDurationMs = source._finalExecutionDurationMs
      _edition = source._edition
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularInt64Field(value: &_storage._creationTime) }()
        case 2: try { try decoder.decodeSingularInt64Field(value: &_storage._startTime) }()
        case 3: try { try decoder.decodeSingularInt64Field(value: &_storage._endTime) }()
        case 4: try { try decoder.decodeSingularMessageField(value: &_storage._totalBytesProcessed) }()
        case 5: try { try decoder.decodeSingularMessageField(value: &_storage._completionRatio) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._query) }()
        case 7: try { try decoder.decodeSingularMessageField(value: &_storage._load) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._extract) }()
        case 9: try { try decoder.decodeRepeatedStringField(value: &_storage._quotaDeferments) }()
        case 10: try { try decoder.decodeSingularMessageField(value: &_storage._totalSlotMs) }()
        case 12: try { try decoder.decodeSingularInt64Field(value: &_storage._numChildJobs) }()
        case 13: try { try decoder.decodeSingularStringField(value: &_storage._parentJobID) }()
        case 14: try { try decoder.decodeSingularMessageField(value: &_storage._scriptStatistics) }()
        case 15: try { try decoder.decodeSingularStringField(value: &_storage._reservationID) }()
        case 16: try { try decoder.decodeSingularMessageField(value: &_storage._rowLevelSecurityStatistics) }()
        case 17: try { try decoder.decodeSingularMessageField(value: &_storage._transactionInfo) }()
        case 18: try { try decoder.decodeSingularMessageField(value: &_storage._sessionInfo) }()
        case 20: try { try decoder.decodeSingularMessageField(value: &_storage._dataMaskingStatistics) }()
        case 21: try { try decoder.decodeSingularMessageField(value: &_storage._copy) }()
        case 22: try { try decoder.decodeSingularInt64Field(value: &_storage._finalExecutionDurationMs) }()
        case 24: try { try decoder.decodeSingularEnumField(value: &_storage._edition) }()
        default: break
        }
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if _storage._creationTime != 0 {
        try visitor.visitSingularInt64Field(value: _storage._creationTime, fieldNumber: 1)
      }
      if _storage._startTime != 0 {
        try visitor.visitSingularInt64Field(value: _storage._startTime, fieldNumber: 2)
      }
      if _storage._endTime != 0 {
        try visitor.visitSingularInt64Field(value: _storage._endTime, fieldNumber: 3)
      }
      try { if let v = _storage._totalBytesProcessed {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      } }()
      try { if let v = _storage._completionRatio {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
      } }()
      try { if let v = _storage._query {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      } }()
      try { if let v = _storage._load {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      } }()
      try { if let v = _storage._extract {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      } }()
      if !_storage._quotaDeferments.isEmpty {
        try visitor.visitRepeatedStringField(value: _storage._quotaDeferments, fieldNumber: 9)
      }
      try { if let v = _storage._totalSlotMs {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
      } }()
      if _storage._numChildJobs != 0 {
        try visitor.visitSingularInt64Field(value: _storage._numChildJobs, fieldNumber: 12)
      }
      if !_storage._parentJobID.isEmpty {
        try visitor.visitSingularStringField(value: _storage._parentJobID, fieldNumber: 13)
      }
      try { if let v = _storage._scriptStatistics {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 14)
      } }()
      if !_storage._reservationID.isEmpty {
        try visitor.visitSingularStringField(value: _storage._reservationID, fieldNumber: 15)
      }
      try { if let v = _storage._rowLevelSecurityStatistics {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 16)
      } }()
      try { if let v = _storage._transactionInfo {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 17)
      } }()
      try { if let v = _storage._sessionInfo {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 18)
      } }()
      try { if let v = _storage._dataMaskingStatistics {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 20)
      } }()
      try { if let v = _storage._copy {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 21)
      } }()
      if _storage._finalExecutionDurationMs != 0 {
        try visitor.visitSingularInt64Field(value: _storage._finalExecutionDurationMs, fieldNumber: 22)
      }
      if _storage._edition != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._edition, fieldNumber: 24)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_JobStatistics, rhs: Google_Cloud_Bigquery_V2_JobStatistics) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._creationTime != rhs_storage._creationTime {return false}
        if _storage._startTime != rhs_storage._startTime {return false}
        if _storage._endTime != rhs_storage._endTime {return false}
        if _storage._totalBytesProcessed != rhs_storage._totalBytesProcessed {return false}
        if _storage._completionRatio != rhs_storage._completionRatio {return false}
        if _storage._quotaDeferments != rhs_storage._quotaDeferments {return false}
        if _storage._query != rhs_storage._query {return false}
        if _storage._load != rhs_storage._load {return false}
        if _storage._extract != rhs_storage._extract {return false}
        if _storage._copy != rhs_storage._copy {return false}
        if _storage._totalSlotMs != rhs_storage._totalSlotMs {return false}
        if _storage._reservationID != rhs_storage._reservationID {return false}
        if _storage._numChildJobs != rhs_storage._numChildJobs {return false}
        if _storage._parentJobID != rhs_storage._parentJobID {return false}
        if _storage._scriptStatistics != rhs_storage._scriptStatistics {return false}
        if _storage._rowLevelSecurityStatistics != rhs_storage._rowLevelSecurityStatistics {return false}
        if _storage._dataMaskingStatistics != rhs_storage._dataMaskingStatistics {return false}
        if _storage._transactionInfo != rhs_storage._transactionInfo {return false}
        if _storage._sessionInfo != rhs_storage._sessionInfo {return false}
        if _storage._finalExecutionDurationMs != rhs_storage._finalExecutionDurationMs {return false}
        if _storage._edition != rhs_storage._edition {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_JobStatistics.TransactionInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_JobStatistics.protoMessageName + ".TransactionInfo"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "transaction_id"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.transactionID) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.transactionID.isEmpty {
      try visitor.visitSingularStringField(value: self.transactionID, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_JobStatistics.TransactionInfo, rhs: Google_Cloud_Bigquery_V2_JobStatistics.TransactionInfo) -> Bool {
    if lhs.transactionID != rhs.transactionID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_DmlStats: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".DmlStats"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "inserted_row_count"),
    2: .standard(proto: "deleted_row_count"),
    3: .standard(proto: "updated_row_count"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._insertedRowCount) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._deletedRowCount) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._updatedRowCount) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._insertedRowCount {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._deletedRowCount {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._updatedRowCount {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_DmlStats, rhs: Google_Cloud_Bigquery_V2_DmlStats) -> Bool {
    if lhs._insertedRowCount != rhs._insertedRowCount {return false}
    if lhs._deletedRowCount != rhs._deletedRowCount {return false}
    if lhs._updatedRowCount != rhs._updatedRowCount {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_PerformanceInsights: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".PerformanceInsights"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "avg_previous_execution_ms"),
    2: .standard(proto: "stage_performance_standalone_insights"),
    3: .standard(proto: "stage_performance_change_insights"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.avgPreviousExecutionMs) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.stagePerformanceStandaloneInsights) }()
      case 3: try { try decoder.decodeRepeatedMessageField(value: &self.stagePerformanceChangeInsights) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.avgPreviousExecutionMs != 0 {
      try visitor.visitSingularInt64Field(value: self.avgPreviousExecutionMs, fieldNumber: 1)
    }
    if !self.stagePerformanceStandaloneInsights.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.stagePerformanceStandaloneInsights, fieldNumber: 2)
    }
    if !self.stagePerformanceChangeInsights.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.stagePerformanceChangeInsights, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_PerformanceInsights, rhs: Google_Cloud_Bigquery_V2_PerformanceInsights) -> Bool {
    if lhs.avgPreviousExecutionMs != rhs.avgPreviousExecutionMs {return false}
    if lhs.stagePerformanceStandaloneInsights != rhs.stagePerformanceStandaloneInsights {return false}
    if lhs.stagePerformanceChangeInsights != rhs.stagePerformanceChangeInsights {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_StagePerformanceChangeInsight: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".StagePerformanceChangeInsight"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "stage_id"),
    2: .standard(proto: "input_data_change"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.stageID) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._inputDataChange) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.stageID != 0 {
      try visitor.visitSingularInt64Field(value: self.stageID, fieldNumber: 1)
    }
    try { if let v = self._inputDataChange {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_StagePerformanceChangeInsight, rhs: Google_Cloud_Bigquery_V2_StagePerformanceChangeInsight) -> Bool {
    if lhs.stageID != rhs.stageID {return false}
    if lhs._inputDataChange != rhs._inputDataChange {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_InputDataChange: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".InputDataChange"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "records_read_diff_percentage"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularFloatField(value: &self.recordsReadDiffPercentage) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.recordsReadDiffPercentage.bitPattern != 0 {
      try visitor.visitSingularFloatField(value: self.recordsReadDiffPercentage, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_InputDataChange, rhs: Google_Cloud_Bigquery_V2_InputDataChange) -> Bool {
    if lhs.recordsReadDiffPercentage != rhs.recordsReadDiffPercentage {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_StagePerformanceStandaloneInsight: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".StagePerformanceStandaloneInsight"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "stage_id"),
    2: .standard(proto: "slot_contention"),
    3: .standard(proto: "insufficient_shuffle_quota"),
    5: .standard(proto: "bi_engine_reasons"),
    6: .standard(proto: "high_cardinality_joins"),
    7: .standard(proto: "partition_skew"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.stageID) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self._slotContention) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self._insufficientShuffleQuota) }()
      case 5: try { try decoder.decodeRepeatedMessageField(value: &self.biEngineReasons) }()
      case 6: try { try decoder.decodeRepeatedMessageField(value: &self.highCardinalityJoins) }()
      case 7: try { try decoder.decodeSingularMessageField(value: &self._partitionSkew) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.stageID != 0 {
      try visitor.visitSingularInt64Field(value: self.stageID, fieldNumber: 1)
    }
    try { if let v = self._slotContention {
      try visitor.visitSingularBoolField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._insufficientShuffleQuota {
      try visitor.visitSingularBoolField(value: v, fieldNumber: 3)
    } }()
    if !self.biEngineReasons.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.biEngineReasons, fieldNumber: 5)
    }
    if !self.highCardinalityJoins.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.highCardinalityJoins, fieldNumber: 6)
    }
    try { if let v = self._partitionSkew {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_StagePerformanceStandaloneInsight, rhs: Google_Cloud_Bigquery_V2_StagePerformanceStandaloneInsight) -> Bool {
    if lhs.stageID != rhs.stageID {return false}
    if lhs._slotContention != rhs._slotContention {return false}
    if lhs._insufficientShuffleQuota != rhs._insufficientShuffleQuota {return false}
    if lhs.biEngineReasons != rhs.biEngineReasons {return false}
    if lhs.highCardinalityJoins != rhs.highCardinalityJoins {return false}
    if lhs._partitionSkew != rhs._partitionSkew {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_HighCardinalityJoin: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".HighCardinalityJoin"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "left_rows"),
    2: .standard(proto: "right_rows"),
    3: .standard(proto: "output_rows"),
    4: .standard(proto: "step_index"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.leftRows) }()
      case 2: try { try decoder.decodeSingularInt64Field(value: &self.rightRows) }()
      case 3: try { try decoder.decodeSingularInt64Field(value: &self.outputRows) }()
      case 4: try { try decoder.decodeSingularInt32Field(value: &self.stepIndex) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.leftRows != 0 {
      try visitor.visitSingularInt64Field(value: self.leftRows, fieldNumber: 1)
    }
    if self.rightRows != 0 {
      try visitor.visitSingularInt64Field(value: self.rightRows, fieldNumber: 2)
    }
    if self.outputRows != 0 {
      try visitor.visitSingularInt64Field(value: self.outputRows, fieldNumber: 3)
    }
    if self.stepIndex != 0 {
      try visitor.visitSingularInt32Field(value: self.stepIndex, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_HighCardinalityJoin, rhs: Google_Cloud_Bigquery_V2_HighCardinalityJoin) -> Bool {
    if lhs.leftRows != rhs.leftRows {return false}
    if lhs.rightRows != rhs.rightRows {return false}
    if lhs.outputRows != rhs.outputRows {return false}
    if lhs.stepIndex != rhs.stepIndex {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_PartitionSkew: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".PartitionSkew"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "skew_sources"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.skewSources) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.skewSources.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.skewSources, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_PartitionSkew, rhs: Google_Cloud_Bigquery_V2_PartitionSkew) -> Bool {
    if lhs.skewSources != rhs.skewSources {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_PartitionSkew.SkewSource: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_PartitionSkew.protoMessageName + ".SkewSource"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "stage_id"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.stageID) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.stageID != 0 {
      try visitor.visitSingularInt64Field(value: self.stageID, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_PartitionSkew.SkewSource, rhs: Google_Cloud_Bigquery_V2_PartitionSkew.SkewSource) -> Bool {
    if lhs.stageID != rhs.stageID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_SparkStatistics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".SparkStatistics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "spark_job_id"),
    2: .standard(proto: "spark_job_location"),
    3: .same(proto: "endpoints"),
    4: .standard(proto: "logging_info"),
    5: .standard(proto: "kms_key_name"),
    6: .standard(proto: "gcs_staging_bucket"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self._sparkJobID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self._sparkJobLocation) }()
      case 3: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &self.endpoints) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._loggingInfo) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self._kmsKeyName) }()
      case 6: try { try decoder.decodeSingularStringField(value: &self._gcsStagingBucket) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._sparkJobID {
      try visitor.visitSingularStringField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._sparkJobLocation {
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    } }()
    if !self.endpoints.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: self.endpoints, fieldNumber: 3)
    }
    try { if let v = self._loggingInfo {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try { if let v = self._kmsKeyName {
      try visitor.visitSingularStringField(value: v, fieldNumber: 5)
    } }()
    try { if let v = self._gcsStagingBucket {
      try visitor.visitSingularStringField(value: v, fieldNumber: 6)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_SparkStatistics, rhs: Google_Cloud_Bigquery_V2_SparkStatistics) -> Bool {
    if lhs._sparkJobID != rhs._sparkJobID {return false}
    if lhs._sparkJobLocation != rhs._sparkJobLocation {return false}
    if lhs.endpoints != rhs.endpoints {return false}
    if lhs._loggingInfo != rhs._loggingInfo {return false}
    if lhs._kmsKeyName != rhs._kmsKeyName {return false}
    if lhs._gcsStagingBucket != rhs._gcsStagingBucket {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_SparkStatistics.LoggingInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = Google_Cloud_Bigquery_V2_SparkStatistics.protoMessageName + ".LoggingInfo"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "resource_type"),
    2: .standard(proto: "project_id"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.resourceType) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.resourceType.isEmpty {
      try visitor.visitSingularStringField(value: self.resourceType, fieldNumber: 1)
    }
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_SparkStatistics.LoggingInfo, rhs: Google_Cloud_Bigquery_V2_SparkStatistics.LoggingInfo) -> Bool {
    if lhs.resourceType != rhs.resourceType {return false}
    if lhs.projectID != rhs.projectID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_MaterializedViewStatistics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".MaterializedViewStatistics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "materialized_view"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.materializedView) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.materializedView.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.materializedView, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_MaterializedViewStatistics, rhs: Google_Cloud_Bigquery_V2_MaterializedViewStatistics) -> Bool {
    if lhs.materializedView != rhs.materializedView {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_MaterializedView: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".MaterializedView"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "table_reference"),
    2: .same(proto: "chosen"),
    3: .standard(proto: "estimated_bytes_saved"),
    4: .standard(proto: "rejected_reason"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._tableReference) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self._chosen) }()
      case 3: try { try decoder.decodeSingularInt64Field(value: &self._estimatedBytesSaved) }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self._rejectedReason) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._tableReference {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._chosen {
      try visitor.visitSingularBoolField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._estimatedBytesSaved {
      try visitor.visitSingularInt64Field(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._rejectedReason {
      try visitor.visitSingularEnumField(value: v, fieldNumber: 4)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_MaterializedView, rhs: Google_Cloud_Bigquery_V2_MaterializedView) -> Bool {
    if lhs._tableReference != rhs._tableReference {return false}
    if lhs._chosen != rhs._chosen {return false}
    if lhs._estimatedBytesSaved != rhs._estimatedBytesSaved {return false}
    if lhs._rejectedReason != rhs._rejectedReason {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_MaterializedView.RejectedReason: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "REJECTED_REASON_UNSPECIFIED"),
    1: .same(proto: "NO_DATA"),
    2: .same(proto: "COST"),
    3: .same(proto: "BASE_TABLE_TRUNCATED"),
    4: .same(proto: "BASE_TABLE_DATA_CHANGE"),
    5: .same(proto: "BASE_TABLE_PARTITION_EXPIRATION_CHANGE"),
    6: .same(proto: "BASE_TABLE_EXPIRED_PARTITION"),
    7: .same(proto: "BASE_TABLE_INCOMPATIBLE_METADATA_CHANGE"),
    8: .same(proto: "TIME_ZONE"),
    9: .same(proto: "OUT_OF_TIME_TRAVEL_WINDOW"),
    10: .same(proto: "BASE_TABLE_FINE_GRAINED_SECURITY_POLICY"),
    11: .same(proto: "BASE_TABLE_TOO_STALE"),
  ]
}

extension Google_Cloud_Bigquery_V2_TableMetadataCacheUsage: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".TableMetadataCacheUsage"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "table_reference"),
    2: .standard(proto: "unused_reason"),
    3: .same(proto: "explanation"),
    5: .same(proto: "staleness"),
    6: .standard(proto: "table_type"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._tableReference) }()
      case 2: try { try decoder.decodeSingularEnumField(value: &self._unusedReason) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self._explanation) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._staleness) }()
      case 6: try { try decoder.decodeSingularStringField(value: &self.tableType) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._tableReference {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._unusedReason {
      try visitor.visitSingularEnumField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._explanation {
      try visitor.visitSingularStringField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._staleness {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    if !self.tableType.isEmpty {
      try visitor.visitSingularStringField(value: self.tableType, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_TableMetadataCacheUsage, rhs: Google_Cloud_Bigquery_V2_TableMetadataCacheUsage) -> Bool {
    if lhs._tableReference != rhs._tableReference {return false}
    if lhs._unusedReason != rhs._unusedReason {return false}
    if lhs._explanation != rhs._explanation {return false}
    if lhs._staleness != rhs._staleness {return false}
    if lhs.tableType != rhs.tableType {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_TableMetadataCacheUsage.UnusedReason: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "UNUSED_REASON_UNSPECIFIED"),
    1: .same(proto: "EXCEEDED_MAX_STALENESS"),
    2: .same(proto: "OTHER_REASON"),
    3: .same(proto: "METADATA_CACHING_NOT_ENABLED"),
  ]
}

extension Google_Cloud_Bigquery_V2_MetadataCacheStatistics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".MetadataCacheStatistics"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "table_metadata_cache_usage"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.tableMetadataCacheUsage) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.tableMetadataCacheUsage.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.tableMetadataCacheUsage, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_MetadataCacheStatistics, rhs: Google_Cloud_Bigquery_V2_MetadataCacheStatistics) -> Bool {
    if lhs.tableMetadataCacheUsage != rhs.tableMetadataCacheUsage {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
