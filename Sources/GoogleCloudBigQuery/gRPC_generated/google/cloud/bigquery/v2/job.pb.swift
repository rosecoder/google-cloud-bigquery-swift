// DO NOT EDIT.
// swift-format-ignore-file
// swiftlint:disable all
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/bigquery/v2/job.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

package struct Google_Cloud_Bigquery_V2_Job: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. The type of the resource.
  package var kind: String {
    get {return _storage._kind}
    set {_uniqueStorage()._kind = newValue}
  }

  /// Output only. A hash of this resource.
  package var etag: String {
    get {return _storage._etag}
    set {_uniqueStorage()._etag = newValue}
  }

  /// Output only. Opaque ID field of the job.
  package var id: String {
    get {return _storage._id}
    set {_uniqueStorage()._id = newValue}
  }

  /// Output only. A URL that can be used to access the resource again.
  package var selfLink: String {
    get {return _storage._selfLink}
    set {_uniqueStorage()._selfLink = newValue}
  }

  /// Output only. Email address of the user who ran the job.
  package var userEmail: String {
    get {return _storage._userEmail}
    set {_uniqueStorage()._userEmail = newValue}
  }

  /// Required. Describes the job configuration.
  package var configuration: Google_Cloud_Bigquery_V2_JobConfiguration {
    get {return _storage._configuration ?? Google_Cloud_Bigquery_V2_JobConfiguration()}
    set {_uniqueStorage()._configuration = newValue}
  }
  /// Returns true if `configuration` has been explicitly set.
  package var hasConfiguration: Bool {return _storage._configuration != nil}
  /// Clears the value of `configuration`. Subsequent reads from it will return its default value.
  package mutating func clearConfiguration() {_uniqueStorage()._configuration = nil}

  /// Optional. Reference describing the unique-per-user name of the job.
  package var jobReference: Google_Cloud_Bigquery_V2_JobReference {
    get {return _storage._jobReference ?? Google_Cloud_Bigquery_V2_JobReference()}
    set {_uniqueStorage()._jobReference = newValue}
  }
  /// Returns true if `jobReference` has been explicitly set.
  package var hasJobReference: Bool {return _storage._jobReference != nil}
  /// Clears the value of `jobReference`. Subsequent reads from it will return its default value.
  package mutating func clearJobReference() {_uniqueStorage()._jobReference = nil}

  /// Output only. Information about the job, including starting time and ending
  /// time of the job.
  package var statistics: Google_Cloud_Bigquery_V2_JobStatistics {
    get {return _storage._statistics ?? Google_Cloud_Bigquery_V2_JobStatistics()}
    set {_uniqueStorage()._statistics = newValue}
  }
  /// Returns true if `statistics` has been explicitly set.
  package var hasStatistics: Bool {return _storage._statistics != nil}
  /// Clears the value of `statistics`. Subsequent reads from it will return its default value.
  package mutating func clearStatistics() {_uniqueStorage()._statistics = nil}

  /// Output only. The status of this job. Examine this value when polling an
  /// asynchronous job to see if the job is complete.
  package var status: Google_Cloud_Bigquery_V2_JobStatus {
    get {return _storage._status ?? Google_Cloud_Bigquery_V2_JobStatus()}
    set {_uniqueStorage()._status = newValue}
  }
  /// Returns true if `status` has been explicitly set.
  package var hasStatus: Bool {return _storage._status != nil}
  /// Clears the value of `status`. Subsequent reads from it will return its default value.
  package mutating func clearStatus() {_uniqueStorage()._status = nil}

  /// Output only. [Full-projection-only] String representation of identity of
  /// requesting party. Populated for both first- and third-party identities.
  /// Only present for APIs that support third-party identities.
  package var principalSubject: String {
    get {return _storage._principalSubject}
    set {_uniqueStorage()._principalSubject = newValue}
  }

  /// Output only. The reason why a Job was created.
  /// [Preview](https://cloud.google.com/products/#product-launch-stages)
  package var jobCreationReason: Google_Cloud_Bigquery_V2_JobCreationReason {
    get {return _storage._jobCreationReason ?? Google_Cloud_Bigquery_V2_JobCreationReason()}
    set {_uniqueStorage()._jobCreationReason = newValue}
  }
  /// Returns true if `jobCreationReason` has been explicitly set.
  package var hasJobCreationReason: Bool {return _storage._jobCreationReason != nil}
  /// Clears the value of `jobCreationReason`. Subsequent reads from it will return its default value.
  package mutating func clearJobCreationReason() {_uniqueStorage()._jobCreationReason = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Describes format of a jobs cancellation request.
package struct Google_Cloud_Bigquery_V2_CancelJobRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the job to cancel
  package var projectID: String = String()

  /// Required. Job ID of the job to cancel
  package var jobID: String = String()

  /// The geographic location of the job. You must specify the location to run
  /// the job for the following scenarios:
  ///
  /// * If the location to run a job is not in the `us` or
  ///   the `eu` multi-regional location
  /// * If the job's location is in a single region (for example,
  ///   `us-central1`)
  ///
  /// For more information, see
  /// https://cloud.google.com/bigquery/docs/locations#specifying_your_location.
  package var location: String = String()

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

/// Describes format of a jobs cancellation response.
package struct Google_Cloud_Bigquery_V2_JobCancelResponse: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The resource type of the response.
  package var kind: String = String()

  /// The final state of the job.
  package var job: Google_Cloud_Bigquery_V2_Job {
    get {return _job ?? Google_Cloud_Bigquery_V2_Job()}
    set {_job = newValue}
  }
  /// Returns true if `job` has been explicitly set.
  package var hasJob: Bool {return self._job != nil}
  /// Clears the value of `job`. Subsequent reads from it will return its default value.
  package mutating func clearJob() {self._job = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _job: Google_Cloud_Bigquery_V2_Job? = nil
}

/// Describes format of a jobs get request.
package struct Google_Cloud_Bigquery_V2_GetJobRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the requested job.
  package var projectID: String = String()

  /// Required. Job ID of the requested job.
  package var jobID: String = String()

  /// The geographic location of the job. You must specify the location to run
  /// the job for the following scenarios:
  ///
  /// * If the location to run a job is not in the `us` or
  ///   the `eu` multi-regional location
  /// * If the job's location is in a single region (for example,
  ///   `us-central1`)
  ///
  /// For more information, see
  /// https://cloud.google.com/bigquery/docs/locations#specifying_your_location.
  package var location: String = String()

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

/// Describes format of a job insertion request.
package struct Google_Cloud_Bigquery_V2_InsertJobRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Project ID of project that will be billed for the job.
  package var projectID: String = String()

  /// Jobs resource to insert.
  package var job: Google_Cloud_Bigquery_V2_Job {
    get {return _job ?? Google_Cloud_Bigquery_V2_Job()}
    set {_job = newValue}
  }
  /// Returns true if `job` has been explicitly set.
  package var hasJob: Bool {return self._job != nil}
  /// Clears the value of `job`. Subsequent reads from it will return its default value.
  package mutating func clearJob() {self._job = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _job: Google_Cloud_Bigquery_V2_Job? = nil
}

/// Describes the format of a jobs deletion request.
package struct Google_Cloud_Bigquery_V2_DeleteJobRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the job for which metadata is to be deleted.
  package var projectID: String = String()

  /// Required. Job ID of the job for which metadata is to be deleted. If this is
  /// a parent job which has child jobs, the metadata from all child jobs will be
  /// deleted as well. Direct deletion of the metadata of child jobs is not
  /// allowed.
  package var jobID: String = String()

  /// The geographic location of the job. Required.
  /// See details at:
  /// https://cloud.google.com/bigquery/docs/locations#specifying_your_location.
  package var location: String = String()

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

/// Describes the format of the list jobs request.
package struct Google_Cloud_Bigquery_V2_ListJobsRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Project ID of the jobs to list.
  package var projectID: String = String()

  /// Whether to display jobs owned by all users in the project. Default False.
  package var allUsers: Bool = false

  /// The maximum number of results to return in a single response page.
  /// Leverage the page tokens to iterate through the entire collection.
  package var maxResults: SwiftProtobuf.Google_Protobuf_Int32Value {
    get {return _maxResults ?? SwiftProtobuf.Google_Protobuf_Int32Value()}
    set {_maxResults = newValue}
  }
  /// Returns true if `maxResults` has been explicitly set.
  package var hasMaxResults: Bool {return self._maxResults != nil}
  /// Clears the value of `maxResults`. Subsequent reads from it will return its default value.
  package mutating func clearMaxResults() {self._maxResults = nil}

  /// Min value for job creation time, in milliseconds since the POSIX epoch.
  /// If set, only jobs created after or at this timestamp are returned.
  package var minCreationTime: UInt64 = 0

  /// Max value for job creation time, in milliseconds since the POSIX epoch.
  /// If set, only jobs created before or at this timestamp are returned.
  package var maxCreationTime: SwiftProtobuf.Google_Protobuf_UInt64Value {
    get {return _maxCreationTime ?? SwiftProtobuf.Google_Protobuf_UInt64Value()}
    set {_maxCreationTime = newValue}
  }
  /// Returns true if `maxCreationTime` has been explicitly set.
  package var hasMaxCreationTime: Bool {return self._maxCreationTime != nil}
  /// Clears the value of `maxCreationTime`. Subsequent reads from it will return its default value.
  package mutating func clearMaxCreationTime() {self._maxCreationTime = nil}

  /// Page token, returned by a previous call, to request the next page of
  /// results.
  package var pageToken: String = String()

  /// Restrict information returned to a set of selected fields
  package var projection: Google_Cloud_Bigquery_V2_ListJobsRequest.Projection = .minimal

  /// Filter for job state
  package var stateFilter: [Google_Cloud_Bigquery_V2_ListJobsRequest.StateFilter] = []

  /// If set, show only child jobs of the specified parent.  Otherwise, show all
  /// top-level jobs.
  package var parentJobID: String = String()

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Projection is used to control what job information is returned.
  package enum Projection: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Does not include the job configuration
    case minimal // = 0

    /// Includes all job data
    case full // = 1
    case UNRECOGNIZED(Int)

    package init() {
      self = .minimal
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .minimal
      case 1: self = .full
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .minimal: return 0
      case .full: return 1
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_ListJobsRequest.Projection] = [
      .minimal,
      .full,
    ]

  }

  /// StateFilter allows filtration by job execution state.
  package enum StateFilter: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Finished jobs
    case done // = 0

    /// Pending jobs
    case pending // = 1

    /// Running jobs
    case running // = 2
    case UNRECOGNIZED(Int)

    package init() {
      self = .done
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .done
      case 1: self = .pending
      case 2: self = .running
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .done: return 0
      case .pending: return 1
      case .running: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_ListJobsRequest.StateFilter] = [
      .done,
      .pending,
      .running,
    ]

  }

  package init() {}

  fileprivate var _maxResults: SwiftProtobuf.Google_Protobuf_Int32Value? = nil
  fileprivate var _maxCreationTime: SwiftProtobuf.Google_Protobuf_UInt64Value? = nil
}

/// ListFormatJob is a partial projection of job information returned as part
/// of a jobs.list response.
package struct Google_Cloud_Bigquery_V2_ListFormatJob: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Unique opaque ID of the job.
  package var id: String {
    get {return _storage._id}
    set {_uniqueStorage()._id = newValue}
  }

  /// The resource type.
  package var kind: String {
    get {return _storage._kind}
    set {_uniqueStorage()._kind = newValue}
  }

  /// Unique opaque ID of the job.
  package var jobReference: Google_Cloud_Bigquery_V2_JobReference {
    get {return _storage._jobReference ?? Google_Cloud_Bigquery_V2_JobReference()}
    set {_uniqueStorage()._jobReference = newValue}
  }
  /// Returns true if `jobReference` has been explicitly set.
  package var hasJobReference: Bool {return _storage._jobReference != nil}
  /// Clears the value of `jobReference`. Subsequent reads from it will return its default value.
  package mutating func clearJobReference() {_uniqueStorage()._jobReference = nil}

  /// Running state of the job. When the state is DONE, errorResult can be
  /// checked to determine whether the job succeeded or failed.
  package var state: String {
    get {return _storage._state}
    set {_uniqueStorage()._state = newValue}
  }

  /// A result object that will be present only if the job has failed.
  package var errorResult: Google_Cloud_Bigquery_V2_ErrorProto {
    get {return _storage._errorResult ?? Google_Cloud_Bigquery_V2_ErrorProto()}
    set {_uniqueStorage()._errorResult = newValue}
  }
  /// Returns true if `errorResult` has been explicitly set.
  package var hasErrorResult: Bool {return _storage._errorResult != nil}
  /// Clears the value of `errorResult`. Subsequent reads from it will return its default value.
  package mutating func clearErrorResult() {_uniqueStorage()._errorResult = nil}

  /// Output only. Information about the job, including starting time and ending
  /// time of the job.
  package var statistics: Google_Cloud_Bigquery_V2_JobStatistics {
    get {return _storage._statistics ?? Google_Cloud_Bigquery_V2_JobStatistics()}
    set {_uniqueStorage()._statistics = newValue}
  }
  /// Returns true if `statistics` has been explicitly set.
  package var hasStatistics: Bool {return _storage._statistics != nil}
  /// Clears the value of `statistics`. Subsequent reads from it will return its default value.
  package mutating func clearStatistics() {_uniqueStorage()._statistics = nil}

  /// Required. Describes the job configuration.
  package var configuration: Google_Cloud_Bigquery_V2_JobConfiguration {
    get {return _storage._configuration ?? Google_Cloud_Bigquery_V2_JobConfiguration()}
    set {_uniqueStorage()._configuration = newValue}
  }
  /// Returns true if `configuration` has been explicitly set.
  package var hasConfiguration: Bool {return _storage._configuration != nil}
  /// Clears the value of `configuration`. Subsequent reads from it will return its default value.
  package mutating func clearConfiguration() {_uniqueStorage()._configuration = nil}

  /// [Full-projection-only] Describes the status of this job.
  package var status: Google_Cloud_Bigquery_V2_JobStatus {
    get {return _storage._status ?? Google_Cloud_Bigquery_V2_JobStatus()}
    set {_uniqueStorage()._status = newValue}
  }
  /// Returns true if `status` has been explicitly set.
  package var hasStatus: Bool {return _storage._status != nil}
  /// Clears the value of `status`. Subsequent reads from it will return its default value.
  package mutating func clearStatus() {_uniqueStorage()._status = nil}

  /// [Full-projection-only] Email address of the user who ran the job.
  package var userEmail: String {
    get {return _storage._userEmail}
    set {_uniqueStorage()._userEmail = newValue}
  }

  /// [Full-projection-only] String representation of identity of requesting
  /// party. Populated for both first- and third-party identities. Only present
  /// for APIs that support third-party identities.
  package var principalSubject: String {
    get {return _storage._principalSubject}
    set {_uniqueStorage()._principalSubject = newValue}
  }

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// JobList is the response format for a jobs.list call.
package struct Google_Cloud_Bigquery_V2_JobList: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// A hash of this page of results.
  package var etag: String = String()

  /// The resource type of the response.
  package var kind: String = String()

  /// A token to request the next page of results.
  package var nextPageToken: String = String()

  /// List of jobs that were requested.
  package var jobs: [Google_Cloud_Bigquery_V2_ListFormatJob] = []

  /// A list of skipped locations that were unreachable. For more information
  /// about BigQuery locations, see:
  /// https://cloud.google.com/bigquery/docs/locations. Example: "europe-west5"
  package var unreachable: [String] = []

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

/// Request object of GetQueryResults.
package struct Google_Cloud_Bigquery_V2_GetQueryResultsRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the query job.
  package var projectID: String = String()

  /// Required. Job ID of the query job.
  package var jobID: String = String()

  /// Zero-based index of the starting row.
  package var startIndex: SwiftProtobuf.Google_Protobuf_UInt64Value {
    get {return _startIndex ?? SwiftProtobuf.Google_Protobuf_UInt64Value()}
    set {_startIndex = newValue}
  }
  /// Returns true if `startIndex` has been explicitly set.
  package var hasStartIndex: Bool {return self._startIndex != nil}
  /// Clears the value of `startIndex`. Subsequent reads from it will return its default value.
  package mutating func clearStartIndex() {self._startIndex = nil}

  /// Page token, returned by a previous call, to request the next page of
  /// results.
  package var pageToken: String = String()

  /// Maximum number of results to read.
  package var maxResults: SwiftProtobuf.Google_Protobuf_UInt32Value {
    get {return _maxResults ?? SwiftProtobuf.Google_Protobuf_UInt32Value()}
    set {_maxResults = newValue}
  }
  /// Returns true if `maxResults` has been explicitly set.
  package var hasMaxResults: Bool {return self._maxResults != nil}
  /// Clears the value of `maxResults`. Subsequent reads from it will return its default value.
  package mutating func clearMaxResults() {self._maxResults = nil}

  /// Optional: Specifies the maximum amount of time, in milliseconds, that the
  /// client is willing to wait for the query to complete. By default, this limit
  /// is 10 seconds (10,000 milliseconds). If the query is complete, the
  /// jobComplete field in the response is true. If the query has not yet
  /// completed, jobComplete is false.
  ///
  /// You can request a longer timeout period in the timeoutMs field.  However,
  /// the call is not guaranteed to wait for the specified timeout; it typically
  /// returns after around 200 seconds (200,000 milliseconds), even if the query
  /// is not complete.
  ///
  /// If jobComplete is false, you can continue to wait for the query to complete
  /// by calling the getQueryResults method until the jobComplete field in the
  /// getQueryResults response is true.
  package var timeoutMs: SwiftProtobuf.Google_Protobuf_UInt32Value {
    get {return _timeoutMs ?? SwiftProtobuf.Google_Protobuf_UInt32Value()}
    set {_timeoutMs = newValue}
  }
  /// Returns true if `timeoutMs` has been explicitly set.
  package var hasTimeoutMs: Bool {return self._timeoutMs != nil}
  /// Clears the value of `timeoutMs`. Subsequent reads from it will return its default value.
  package mutating func clearTimeoutMs() {self._timeoutMs = nil}

  /// The geographic location of the job. You must specify the location to run
  /// the job for the following scenarios:
  ///
  /// * If the location to run a job is not in the `us` or
  ///   the `eu` multi-regional location
  /// * If the job's location is in a single region (for example,
  /// `us-central1`)
  ///
  /// For more information, see
  /// https://cloud.google.com/bigquery/docs/locations#specifying_your_location.
  package var location: String = String()

  /// Optional. Output format adjustments.
  package var formatOptions: Google_Cloud_Bigquery_V2_DataFormatOptions {
    get {return _formatOptions ?? Google_Cloud_Bigquery_V2_DataFormatOptions()}
    set {_formatOptions = newValue}
  }
  /// Returns true if `formatOptions` has been explicitly set.
  package var hasFormatOptions: Bool {return self._formatOptions != nil}
  /// Clears the value of `formatOptions`. Subsequent reads from it will return its default value.
  package mutating func clearFormatOptions() {self._formatOptions = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _startIndex: SwiftProtobuf.Google_Protobuf_UInt64Value? = nil
  fileprivate var _maxResults: SwiftProtobuf.Google_Protobuf_UInt32Value? = nil
  fileprivate var _timeoutMs: SwiftProtobuf.Google_Protobuf_UInt32Value? = nil
  fileprivate var _formatOptions: Google_Cloud_Bigquery_V2_DataFormatOptions? = nil
}

/// Response object of GetQueryResults.
package struct Google_Cloud_Bigquery_V2_GetQueryResultsResponse: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The resource type of the response.
  package var kind: String = String()

  /// A hash of this response.
  package var etag: String = String()

  /// The schema of the results. Present only when the query completes
  /// successfully.
  package var schema: Google_Cloud_Bigquery_V2_TableSchema {
    get {return _schema ?? Google_Cloud_Bigquery_V2_TableSchema()}
    set {_schema = newValue}
  }
  /// Returns true if `schema` has been explicitly set.
  package var hasSchema: Bool {return self._schema != nil}
  /// Clears the value of `schema`. Subsequent reads from it will return its default value.
  package mutating func clearSchema() {self._schema = nil}

  /// Reference to the BigQuery Job that was created to run the query. This field
  /// will be present even if the original request timed out, in which case
  /// GetQueryResults can be used to read the results once the query has
  /// completed. Since this API only returns the first page of results,
  /// subsequent pages can be fetched via the same mechanism (GetQueryResults).
  package var jobReference: Google_Cloud_Bigquery_V2_JobReference {
    get {return _jobReference ?? Google_Cloud_Bigquery_V2_JobReference()}
    set {_jobReference = newValue}
  }
  /// Returns true if `jobReference` has been explicitly set.
  package var hasJobReference: Bool {return self._jobReference != nil}
  /// Clears the value of `jobReference`. Subsequent reads from it will return its default value.
  package mutating func clearJobReference() {self._jobReference = nil}

  /// The total number of rows in the complete query result set, which can be
  /// more than the number of rows in this single page of results. Present only
  /// when the query completes successfully.
  package var totalRows: SwiftProtobuf.Google_Protobuf_UInt64Value {
    get {return _totalRows ?? SwiftProtobuf.Google_Protobuf_UInt64Value()}
    set {_totalRows = newValue}
  }
  /// Returns true if `totalRows` has been explicitly set.
  package var hasTotalRows: Bool {return self._totalRows != nil}
  /// Clears the value of `totalRows`. Subsequent reads from it will return its default value.
  package mutating func clearTotalRows() {self._totalRows = nil}

  /// A token used for paging results.  When this token is non-empty, it
  /// indicates additional results are available.
  package var pageToken: String = String()

  /// An object with as many results as can be contained within the maximum
  /// permitted reply size. To get any additional rows, you can call
  /// GetQueryResults and specify the jobReference returned above. Present only
  /// when the query completes successfully.
  ///
  /// The REST-based representation of this data leverages a series of
  /// JSON f,v objects for indicating fields and values.
  package var rows: [SwiftProtobuf.Google_Protobuf_Struct] = []

  /// The total number of bytes processed for this query.
  package var totalBytesProcessed: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _totalBytesProcessed ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_totalBytesProcessed = newValue}
  }
  /// Returns true if `totalBytesProcessed` has been explicitly set.
  package var hasTotalBytesProcessed: Bool {return self._totalBytesProcessed != nil}
  /// Clears the value of `totalBytesProcessed`. Subsequent reads from it will return its default value.
  package mutating func clearTotalBytesProcessed() {self._totalBytesProcessed = nil}

  /// Whether the query has completed or not. If rows or totalRows are present,
  /// this will always be true. If this is false, totalRows will not be
  /// available.
  package var jobComplete: SwiftProtobuf.Google_Protobuf_BoolValue {
    get {return _jobComplete ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
    set {_jobComplete = newValue}
  }
  /// Returns true if `jobComplete` has been explicitly set.
  package var hasJobComplete: Bool {return self._jobComplete != nil}
  /// Clears the value of `jobComplete`. Subsequent reads from it will return its default value.
  package mutating func clearJobComplete() {self._jobComplete = nil}

  /// Output only. The first errors or warnings encountered during the running
  /// of the job. The final message includes the number of errors that caused the
  /// process to stop. Errors here do not necessarily mean that the job has
  /// completed or was unsuccessful. For more information about error messages,
  /// see [Error
  /// messages](https://cloud.google.com/bigquery/docs/error-messages).
  package var errors: [Google_Cloud_Bigquery_V2_ErrorProto] = []

  /// Whether the query result was fetched from the query cache.
  package var cacheHit: SwiftProtobuf.Google_Protobuf_BoolValue {
    get {return _cacheHit ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
    set {_cacheHit = newValue}
  }
  /// Returns true if `cacheHit` has been explicitly set.
  package var hasCacheHit: Bool {return self._cacheHit != nil}
  /// Clears the value of `cacheHit`. Subsequent reads from it will return its default value.
  package mutating func clearCacheHit() {self._cacheHit = nil}

  /// Output only. The number of rows affected by a DML statement. Present only
  /// for DML statements INSERT, UPDATE or DELETE.
  package var numDmlAffectedRows: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _numDmlAffectedRows ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_numDmlAffectedRows = newValue}
  }
  /// Returns true if `numDmlAffectedRows` has been explicitly set.
  package var hasNumDmlAffectedRows: Bool {return self._numDmlAffectedRows != nil}
  /// Clears the value of `numDmlAffectedRows`. Subsequent reads from it will return its default value.
  package mutating func clearNumDmlAffectedRows() {self._numDmlAffectedRows = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _schema: Google_Cloud_Bigquery_V2_TableSchema? = nil
  fileprivate var _jobReference: Google_Cloud_Bigquery_V2_JobReference? = nil
  fileprivate var _totalRows: SwiftProtobuf.Google_Protobuf_UInt64Value? = nil
  fileprivate var _totalBytesProcessed: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
  fileprivate var _jobComplete: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
  fileprivate var _cacheHit: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
  fileprivate var _numDmlAffectedRows: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
}

/// Request format for the query request.
package struct Google_Cloud_Bigquery_V2_PostQueryRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the query request.
  package var projectID: String = String()

  /// The query request body.
  package var queryRequest: Google_Cloud_Bigquery_V2_QueryRequest {
    get {return _queryRequest ?? Google_Cloud_Bigquery_V2_QueryRequest()}
    set {_queryRequest = newValue}
  }
  /// Returns true if `queryRequest` has been explicitly set.
  package var hasQueryRequest: Bool {return self._queryRequest != nil}
  /// Clears the value of `queryRequest`. Subsequent reads from it will return its default value.
  package mutating func clearQueryRequest() {self._queryRequest = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _queryRequest: Google_Cloud_Bigquery_V2_QueryRequest? = nil
}

/// Describes the format of the jobs.query request.
package struct Google_Cloud_Bigquery_V2_QueryRequest: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The resource type of the request.
  package var kind: String {
    get {return _storage._kind}
    set {_uniqueStorage()._kind = newValue}
  }

  /// Required. A query string to execute, using Google Standard SQL or legacy
  /// SQL syntax. Example: "SELECT COUNT(f1) FROM
  /// myProjectId.myDatasetId.myTableId".
  package var query: String {
    get {return _storage._query}
    set {_uniqueStorage()._query = newValue}
  }

  /// Optional. The maximum number of rows of data to return per page of
  /// results. Setting this flag to a small value such as 1000 and then paging
  /// through results might improve reliability when the query result set is
  /// large. In addition to this limit, responses are also limited to 10 MB. By
  /// default, there is no maximum row count, and only the byte limit applies.
  package var maxResults: SwiftProtobuf.Google_Protobuf_UInt32Value {
    get {return _storage._maxResults ?? SwiftProtobuf.Google_Protobuf_UInt32Value()}
    set {_uniqueStorage()._maxResults = newValue}
  }
  /// Returns true if `maxResults` has been explicitly set.
  package var hasMaxResults: Bool {return _storage._maxResults != nil}
  /// Clears the value of `maxResults`. Subsequent reads from it will return its default value.
  package mutating func clearMaxResults() {_uniqueStorage()._maxResults = nil}

  /// Optional. Specifies the default datasetId and projectId to assume for any
  /// unqualified table names in the query. If not set, all table names in the
  /// query string must be qualified in the format 'datasetId.tableId'.
  package var defaultDataset: Google_Cloud_Bigquery_V2_DatasetReference {
    get {return _storage._defaultDataset ?? Google_Cloud_Bigquery_V2_DatasetReference()}
    set {_uniqueStorage()._defaultDataset = newValue}
  }
  /// Returns true if `defaultDataset` has been explicitly set.
  package var hasDefaultDataset: Bool {return _storage._defaultDataset != nil}
  /// Clears the value of `defaultDataset`. Subsequent reads from it will return its default value.
  package mutating func clearDefaultDataset() {_uniqueStorage()._defaultDataset = nil}

  /// Optional. Optional: Specifies the maximum amount of time, in milliseconds,
  /// that the client is willing to wait for the query to complete. By default,
  /// this limit is 10 seconds (10,000 milliseconds). If the query is complete,
  /// the jobComplete field in the response is true. If the query has not yet
  /// completed, jobComplete is false.
  ///
  /// You can request a longer timeout period in the timeoutMs field.  However,
  /// the call is not guaranteed to wait for the specified timeout; it typically
  /// returns after around 200 seconds (200,000 milliseconds), even if the query
  /// is not complete.
  ///
  /// If jobComplete is false, you can continue to wait for the query to complete
  /// by calling the getQueryResults method until the jobComplete field in the
  /// getQueryResults response is true.
  package var timeoutMs: SwiftProtobuf.Google_Protobuf_UInt32Value {
    get {return _storage._timeoutMs ?? SwiftProtobuf.Google_Protobuf_UInt32Value()}
    set {_uniqueStorage()._timeoutMs = newValue}
  }
  /// Returns true if `timeoutMs` has been explicitly set.
  package var hasTimeoutMs: Bool {return _storage._timeoutMs != nil}
  /// Clears the value of `timeoutMs`. Subsequent reads from it will return its default value.
  package mutating func clearTimeoutMs() {_uniqueStorage()._timeoutMs = nil}

  /// Optional. If set to true, BigQuery doesn't run the job. Instead, if the
  /// query is valid, BigQuery returns statistics about the job such as how many
  /// bytes would be processed. If the query is invalid, an error returns. The
  /// default value is false.
  package var dryRun: Bool {
    get {return _storage._dryRun}
    set {_uniqueStorage()._dryRun = newValue}
  }

  /// Optional. Whether to look for the result in the query cache. The query
  /// cache is a best-effort cache that will be flushed whenever tables in the
  /// query are modified. The default value is true.
  package var useQueryCache: SwiftProtobuf.Google_Protobuf_BoolValue {
    get {return _storage._useQueryCache ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
    set {_uniqueStorage()._useQueryCache = newValue}
  }
  /// Returns true if `useQueryCache` has been explicitly set.
  package var hasUseQueryCache: Bool {return _storage._useQueryCache != nil}
  /// Clears the value of `useQueryCache`. Subsequent reads from it will return its default value.
  package mutating func clearUseQueryCache() {_uniqueStorage()._useQueryCache = nil}

  /// Specifies whether to use BigQuery's legacy SQL dialect for this query. The
  /// default value is true. If set to false, the query will use BigQuery's
  /// GoogleSQL: https://cloud.google.com/bigquery/sql-reference/ When
  /// useLegacySql is set to false, the value of flattenResults is ignored; query
  /// will be run as if flattenResults is false.
  package var useLegacySql: SwiftProtobuf.Google_Protobuf_BoolValue {
    get {return _storage._useLegacySql ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
    set {_uniqueStorage()._useLegacySql = newValue}
  }
  /// Returns true if `useLegacySql` has been explicitly set.
  package var hasUseLegacySql: Bool {return _storage._useLegacySql != nil}
  /// Clears the value of `useLegacySql`. Subsequent reads from it will return its default value.
  package mutating func clearUseLegacySql() {_uniqueStorage()._useLegacySql = nil}

  /// GoogleSQL only. Set to POSITIONAL to use positional (?) query parameters
  /// or to NAMED to use named (@myparam) query parameters in this query.
  package var parameterMode: String {
    get {return _storage._parameterMode}
    set {_uniqueStorage()._parameterMode = newValue}
  }

  /// Query parameters for GoogleSQL queries.
  package var queryParameters: [Google_Cloud_Bigquery_V2_QueryParameter] {
    get {return _storage._queryParameters}
    set {_uniqueStorage()._queryParameters = newValue}
  }

  /// The geographic location where the job should run. See details at
  /// https://cloud.google.com/bigquery/docs/locations#specifying_your_location.
  package var location: String {
    get {return _storage._location}
    set {_uniqueStorage()._location = newValue}
  }

  /// Optional. Output format adjustments.
  package var formatOptions: Google_Cloud_Bigquery_V2_DataFormatOptions {
    get {return _storage._formatOptions ?? Google_Cloud_Bigquery_V2_DataFormatOptions()}
    set {_uniqueStorage()._formatOptions = newValue}
  }
  /// Returns true if `formatOptions` has been explicitly set.
  package var hasFormatOptions: Bool {return _storage._formatOptions != nil}
  /// Clears the value of `formatOptions`. Subsequent reads from it will return its default value.
  package mutating func clearFormatOptions() {_uniqueStorage()._formatOptions = nil}

  /// Optional. Connection properties which can modify the query behavior.
  package var connectionProperties: [Google_Cloud_Bigquery_V2_ConnectionProperty] {
    get {return _storage._connectionProperties}
    set {_uniqueStorage()._connectionProperties = newValue}
  }

  /// Optional. The labels associated with this query.
  /// Labels can be used to organize and group query jobs.
  /// Label keys and values can be no longer than 63 characters, can only contain
  /// lowercase letters, numeric characters, underscores and dashes.
  /// International characters are allowed. Label keys must start with a letter
  /// and each label in the list must have a different key.
  package var labels: Dictionary<String,String> {
    get {return _storage._labels}
    set {_uniqueStorage()._labels = newValue}
  }

  /// Optional. Limits the bytes billed for this query. Queries with
  /// bytes billed above this limit will fail (without incurring a charge).
  /// If unspecified, the project default is used.
  package var maximumBytesBilled: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._maximumBytesBilled ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._maximumBytesBilled = newValue}
  }
  /// Returns true if `maximumBytesBilled` has been explicitly set.
  package var hasMaximumBytesBilled: Bool {return _storage._maximumBytesBilled != nil}
  /// Clears the value of `maximumBytesBilled`. Subsequent reads from it will return its default value.
  package mutating func clearMaximumBytesBilled() {_uniqueStorage()._maximumBytesBilled = nil}

  /// Optional. A unique user provided identifier to ensure idempotent behavior
  /// for queries. Note that this is different from the job_id. It has the
  /// following properties:
  ///
  /// 1. It is case-sensitive, limited to up to 36 ASCII characters. A UUID is
  ///    recommended.
  ///
  /// 2. Read only queries can ignore this token since they are nullipotent by
  ///    definition.
  ///
  /// 3. For the purposes of idempotency ensured by the request_id, a request
  ///    is considered duplicate of another only if they have the same request_id
  ///    and are actually duplicates. When determining whether a request is a
  ///    duplicate of another request, all parameters in the request that
  ///    may affect the result are considered. For example, query,
  ///    connection_properties, query_parameters, use_legacy_sql are parameters
  ///    that affect the result and are considered when determining whether a
  ///    request is a duplicate, but properties like timeout_ms don't
  ///    affect the result and are thus not considered. Dry run query
  ///    requests are never considered duplicate of another request.
  ///
  /// 4. When a duplicate mutating query request is detected, it returns:
  ///    a. the results of the mutation if it completes successfully within
  ///       the timeout.
  ///    b. the running operation if it is still in progress at the end of the
  ///        timeout.
  ///
  /// 5. Its lifetime is limited to 15 minutes. In other words, if two
  ///    requests are sent with the same request_id, but more than 15 minutes
  ///    apart, idempotency is not guaranteed.
  package var requestID: String {
    get {return _storage._requestID}
    set {_uniqueStorage()._requestID = newValue}
  }

  /// Optional. If true, creates a new session using a randomly generated
  /// session_id. If false, runs query with an existing session_id passed in
  /// ConnectionProperty, otherwise runs query in non-session mode.
  ///
  /// The session location will be set to QueryRequest.location if it is present,
  /// otherwise it's set to the default location based on existing routing logic.
  package var createSession: SwiftProtobuf.Google_Protobuf_BoolValue {
    get {return _storage._createSession ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
    set {_uniqueStorage()._createSession = newValue}
  }
  /// Returns true if `createSession` has been explicitly set.
  package var hasCreateSession: Bool {return _storage._createSession != nil}
  /// Clears the value of `createSession`. Subsequent reads from it will return its default value.
  package mutating func clearCreateSession() {_uniqueStorage()._createSession = nil}

  /// Optional. If not set, jobs are always required.
  ///
  /// If set, the query request will follow the behavior described
  /// JobCreationMode.
  /// [Preview](https://cloud.google.com/products/#product-launch-stages)
  package var jobCreationMode: Google_Cloud_Bigquery_V2_QueryRequest.JobCreationMode {
    get {return _storage._jobCreationMode}
    set {_uniqueStorage()._jobCreationMode = newValue}
  }

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Job Creation Mode provides different options on job creation.
  package enum JobCreationMode: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// If unspecified JOB_CREATION_REQUIRED is the default.
    case unspecified // = 0

    /// Default. Job creation is always required.
    case jobCreationRequired // = 1

    /// Job creation is optional. Returning immediate results is prioritized.
    /// BigQuery will automatically determine if a Job needs to be created.
    /// The conditions under which BigQuery can decide to not create a Job are
    /// subject to change. If Job creation is required, JOB_CREATION_REQUIRED
    /// mode should be used, which is the default.
    case jobCreationOptional // = 2
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .jobCreationRequired
      case 2: self = .jobCreationOptional
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .jobCreationRequired: return 1
      case .jobCreationOptional: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_QueryRequest.JobCreationMode] = [
      .unspecified,
      .jobCreationRequired,
      .jobCreationOptional,
    ]

  }

  package init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

package struct Google_Cloud_Bigquery_V2_QueryResponse: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The resource type.
  package var kind: String {
    get {return _storage._kind}
    set {_uniqueStorage()._kind = newValue}
  }

  /// The schema of the results. Present only when the query completes
  /// successfully.
  package var schema: Google_Cloud_Bigquery_V2_TableSchema {
    get {return _storage._schema ?? Google_Cloud_Bigquery_V2_TableSchema()}
    set {_uniqueStorage()._schema = newValue}
  }
  /// Returns true if `schema` has been explicitly set.
  package var hasSchema: Bool {return _storage._schema != nil}
  /// Clears the value of `schema`. Subsequent reads from it will return its default value.
  package mutating func clearSchema() {_uniqueStorage()._schema = nil}

  /// Reference to the Job that was created to run the query. This field will be
  /// present even if the original request timed out, in which case
  /// GetQueryResults can be used to read the results once the query has
  /// completed. Since this API only returns the first page of results,
  /// subsequent pages can be fetched via the same mechanism (GetQueryResults).
  ///
  /// If job_creation_mode was set to `JOB_CREATION_OPTIONAL` and the query
  /// completes without creating a job, this field will be empty.
  package var jobReference: Google_Cloud_Bigquery_V2_JobReference {
    get {return _storage._jobReference ?? Google_Cloud_Bigquery_V2_JobReference()}
    set {_uniqueStorage()._jobReference = newValue}
  }
  /// Returns true if `jobReference` has been explicitly set.
  package var hasJobReference: Bool {return _storage._jobReference != nil}
  /// Clears the value of `jobReference`. Subsequent reads from it will return its default value.
  package mutating func clearJobReference() {_uniqueStorage()._jobReference = nil}

  /// Optional. The reason why a Job was created.
  ///
  /// Only relevant when a job_reference is present in the response.
  /// If job_reference is not present it will always be unset.
  /// [Preview](https://cloud.google.com/products/#product-launch-stages)
  package var jobCreationReason: Google_Cloud_Bigquery_V2_JobCreationReason {
    get {return _storage._jobCreationReason ?? Google_Cloud_Bigquery_V2_JobCreationReason()}
    set {_uniqueStorage()._jobCreationReason = newValue}
  }
  /// Returns true if `jobCreationReason` has been explicitly set.
  package var hasJobCreationReason: Bool {return _storage._jobCreationReason != nil}
  /// Clears the value of `jobCreationReason`. Subsequent reads from it will return its default value.
  package mutating func clearJobCreationReason() {_uniqueStorage()._jobCreationReason = nil}

  /// Auto-generated ID for the query.
  /// [Preview](https://cloud.google.com/products/#product-launch-stages)
  package var queryID: String {
    get {return _storage._queryID}
    set {_uniqueStorage()._queryID = newValue}
  }

  /// The total number of rows in the complete query result set, which can be
  /// more than the number of rows in this single page of results.
  package var totalRows: SwiftProtobuf.Google_Protobuf_UInt64Value {
    get {return _storage._totalRows ?? SwiftProtobuf.Google_Protobuf_UInt64Value()}
    set {_uniqueStorage()._totalRows = newValue}
  }
  /// Returns true if `totalRows` has been explicitly set.
  package var hasTotalRows: Bool {return _storage._totalRows != nil}
  /// Clears the value of `totalRows`. Subsequent reads from it will return its default value.
  package mutating func clearTotalRows() {_uniqueStorage()._totalRows = nil}

  /// A token used for paging results. A non-empty token indicates that
  /// additional results are available. To see additional results,
  /// query the
  /// [`jobs.getQueryResults`](https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/getQueryResults)
  /// method. For more information, see [Paging through table
  /// data](https://cloud.google.com/bigquery/docs/paging-results).
  package var pageToken: String {
    get {return _storage._pageToken}
    set {_uniqueStorage()._pageToken = newValue}
  }

  /// An object with as many results as can be contained within the maximum
  /// permitted reply size. To get any additional rows, you can call
  /// GetQueryResults and specify the jobReference returned above.
  package var rows: [SwiftProtobuf.Google_Protobuf_Struct] {
    get {return _storage._rows}
    set {_uniqueStorage()._rows = newValue}
  }

  /// The total number of bytes processed for this query. If this query was a dry
  /// run, this is the number of bytes that would be processed if the query were
  /// run.
  package var totalBytesProcessed: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._totalBytesProcessed ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._totalBytesProcessed = newValue}
  }
  /// Returns true if `totalBytesProcessed` has been explicitly set.
  package var hasTotalBytesProcessed: Bool {return _storage._totalBytesProcessed != nil}
  /// Clears the value of `totalBytesProcessed`. Subsequent reads from it will return its default value.
  package mutating func clearTotalBytesProcessed() {_uniqueStorage()._totalBytesProcessed = nil}

  /// Whether the query has completed or not. If rows or totalRows are present,
  /// this will always be true. If this is false, totalRows will not be
  /// available.
  package var jobComplete: SwiftProtobuf.Google_Protobuf_BoolValue {
    get {return _storage._jobComplete ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
    set {_uniqueStorage()._jobComplete = newValue}
  }
  /// Returns true if `jobComplete` has been explicitly set.
  package var hasJobComplete: Bool {return _storage._jobComplete != nil}
  /// Clears the value of `jobComplete`. Subsequent reads from it will return its default value.
  package mutating func clearJobComplete() {_uniqueStorage()._jobComplete = nil}

  /// Output only. The first errors or warnings encountered during the running of
  /// the job. The final message includes the number of errors that caused the
  /// process to stop. Errors here do not necessarily mean that the job has
  /// completed or was unsuccessful. For more information about error messages,
  /// see [Error
  /// messages](https://cloud.google.com/bigquery/docs/error-messages).
  package var errors: [Google_Cloud_Bigquery_V2_ErrorProto] {
    get {return _storage._errors}
    set {_uniqueStorage()._errors = newValue}
  }

  /// Whether the query result was fetched from the query cache.
  package var cacheHit: SwiftProtobuf.Google_Protobuf_BoolValue {
    get {return _storage._cacheHit ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
    set {_uniqueStorage()._cacheHit = newValue}
  }
  /// Returns true if `cacheHit` has been explicitly set.
  package var hasCacheHit: Bool {return _storage._cacheHit != nil}
  /// Clears the value of `cacheHit`. Subsequent reads from it will return its default value.
  package mutating func clearCacheHit() {_uniqueStorage()._cacheHit = nil}

  /// Output only. The number of rows affected by a DML statement. Present only
  /// for DML statements INSERT, UPDATE or DELETE.
  package var numDmlAffectedRows: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._numDmlAffectedRows ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._numDmlAffectedRows = newValue}
  }
  /// Returns true if `numDmlAffectedRows` has been explicitly set.
  package var hasNumDmlAffectedRows: Bool {return _storage._numDmlAffectedRows != nil}
  /// Clears the value of `numDmlAffectedRows`. Subsequent reads from it will return its default value.
  package mutating func clearNumDmlAffectedRows() {_uniqueStorage()._numDmlAffectedRows = nil}

  /// Output only. Information of the session if this job is part of one.
  package var sessionInfo: Google_Cloud_Bigquery_V2_SessionInfo {
    get {return _storage._sessionInfo ?? Google_Cloud_Bigquery_V2_SessionInfo()}
    set {_uniqueStorage()._sessionInfo = newValue}
  }
  /// Returns true if `sessionInfo` has been explicitly set.
  package var hasSessionInfo: Bool {return _storage._sessionInfo != nil}
  /// Clears the value of `sessionInfo`. Subsequent reads from it will return its default value.
  package mutating func clearSessionInfo() {_uniqueStorage()._sessionInfo = nil}

  /// Output only. Detailed statistics for DML statements INSERT, UPDATE, DELETE,
  /// MERGE or TRUNCATE.
  package var dmlStats: Google_Cloud_Bigquery_V2_DmlStats {
    get {return _storage._dmlStats ?? Google_Cloud_Bigquery_V2_DmlStats()}
    set {_uniqueStorage()._dmlStats = newValue}
  }
  /// Returns true if `dmlStats` has been explicitly set.
  package var hasDmlStats: Bool {return _storage._dmlStats != nil}
  /// Clears the value of `dmlStats`. Subsequent reads from it will return its default value.
  package mutating func clearDmlStats() {_uniqueStorage()._dmlStats = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.bigquery.v2"

extension Google_Cloud_Bigquery_V2_Job: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".Job"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "kind"),
    2: .same(proto: "etag"),
    3: .same(proto: "id"),
    4: .standard(proto: "self_link"),
    5: .standard(proto: "user_email"),
    6: .same(proto: "configuration"),
    7: .standard(proto: "job_reference"),
    8: .same(proto: "statistics"),
    9: .same(proto: "status"),
    13: .standard(proto: "principal_subject"),
    14: .standard(proto: "job_creation_reason"),
  ]

  fileprivate class _StorageClass {
    var _kind: String = String()
    var _etag: String = String()
    var _id: String = String()
    var _selfLink: String = String()
    var _userEmail: String = String()
    var _configuration: Google_Cloud_Bigquery_V2_JobConfiguration? = nil
    var _jobReference: Google_Cloud_Bigquery_V2_JobReference? = nil
    var _statistics: Google_Cloud_Bigquery_V2_JobStatistics? = nil
    var _status: Google_Cloud_Bigquery_V2_JobStatus? = nil
    var _principalSubject: String = String()
    var _jobCreationReason: Google_Cloud_Bigquery_V2_JobCreationReason? = nil

    #if swift(>=5.10)
      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()
    #else
      static let defaultInstance = _StorageClass()
    #endif

    private init() {}

    init(copying source: _StorageClass) {
      _kind = source._kind
      _etag = source._etag
      _id = source._id
      _selfLink = source._selfLink
      _userEmail = source._userEmail
      _configuration = source._configuration
      _jobReference = source._jobReference
      _statistics = source._statistics
      _status = source._status
      _principalSubject = source._principalSubject
      _jobCreationReason = source._jobCreationReason
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._kind) }()
        case 2: try { try decoder.decodeSingularStringField(value: &_storage._etag) }()
        case 3: try { try decoder.decodeSingularStringField(value: &_storage._id) }()
        case 4: try { try decoder.decodeSingularStringField(value: &_storage._selfLink) }()
        case 5: try { try decoder.decodeSingularStringField(value: &_storage._userEmail) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._configuration) }()
        case 7: try { try decoder.decodeSingularMessageField(value: &_storage._jobReference) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._statistics) }()
        case 9: try { try decoder.decodeSingularMessageField(value: &_storage._status) }()
        case 13: try { try decoder.decodeSingularStringField(value: &_storage._principalSubject) }()
        case 14: try { try decoder.decodeSingularMessageField(value: &_storage._jobCreationReason) }()
        default: break
        }
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if !_storage._kind.isEmpty {
        try visitor.visitSingularStringField(value: _storage._kind, fieldNumber: 1)
      }
      if !_storage._etag.isEmpty {
        try visitor.visitSingularStringField(value: _storage._etag, fieldNumber: 2)
      }
      if !_storage._id.isEmpty {
        try visitor.visitSingularStringField(value: _storage._id, fieldNumber: 3)
      }
      if !_storage._selfLink.isEmpty {
        try visitor.visitSingularStringField(value: _storage._selfLink, fieldNumber: 4)
      }
      if !_storage._userEmail.isEmpty {
        try visitor.visitSingularStringField(value: _storage._userEmail, fieldNumber: 5)
      }
      try { if let v = _storage._configuration {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      } }()
      try { if let v = _storage._jobReference {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      } }()
      try { if let v = _storage._statistics {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      } }()
      try { if let v = _storage._status {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      } }()
      if !_storage._principalSubject.isEmpty {
        try visitor.visitSingularStringField(value: _storage._principalSubject, fieldNumber: 13)
      }
      try { if let v = _storage._jobCreationReason {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 14)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Job, rhs: Google_Cloud_Bigquery_V2_Job) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._kind != rhs_storage._kind {return false}
        if _storage._etag != rhs_storage._etag {return false}
        if _storage._id != rhs_storage._id {return false}
        if _storage._selfLink != rhs_storage._selfLink {return false}
        if _storage._userEmail != rhs_storage._userEmail {return false}
        if _storage._configuration != rhs_storage._configuration {return false}
        if _storage._jobReference != rhs_storage._jobReference {return false}
        if _storage._statistics != rhs_storage._statistics {return false}
        if _storage._status != rhs_storage._status {return false}
        if _storage._principalSubject != rhs_storage._principalSubject {return false}
        if _storage._jobCreationReason != rhs_storage._jobCreationReason {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_CancelJobRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".CancelJobRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "job_id"),
    3: .same(proto: "location"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.jobID) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.location) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.jobID.isEmpty {
      try visitor.visitSingularStringField(value: self.jobID, fieldNumber: 2)
    }
    if !self.location.isEmpty {
      try visitor.visitSingularStringField(value: self.location, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_CancelJobRequest, rhs: Google_Cloud_Bigquery_V2_CancelJobRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.jobID != rhs.jobID {return false}
    if lhs.location != rhs.location {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_JobCancelResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".JobCancelResponse"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "kind"),
    2: .same(proto: "job"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.kind) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._job) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.kind.isEmpty {
      try visitor.visitSingularStringField(value: self.kind, fieldNumber: 1)
    }
    try { if let v = self._job {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_JobCancelResponse, rhs: Google_Cloud_Bigquery_V2_JobCancelResponse) -> Bool {
    if lhs.kind != rhs.kind {return false}
    if lhs._job != rhs._job {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_GetJobRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".GetJobRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "job_id"),
    3: .same(proto: "location"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.jobID) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.location) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.jobID.isEmpty {
      try visitor.visitSingularStringField(value: self.jobID, fieldNumber: 2)
    }
    if !self.location.isEmpty {
      try visitor.visitSingularStringField(value: self.location, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_GetJobRequest, rhs: Google_Cloud_Bigquery_V2_GetJobRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.jobID != rhs.jobID {return false}
    if lhs.location != rhs.location {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_InsertJobRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".InsertJobRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    3: .same(proto: "job"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._job) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    try { if let v = self._job {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_InsertJobRequest, rhs: Google_Cloud_Bigquery_V2_InsertJobRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs._job != rhs._job {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_DeleteJobRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".DeleteJobRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "job_id"),
    3: .same(proto: "location"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.jobID) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.location) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.jobID.isEmpty {
      try visitor.visitSingularStringField(value: self.jobID, fieldNumber: 2)
    }
    if !self.location.isEmpty {
      try visitor.visitSingularStringField(value: self.location, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_DeleteJobRequest, rhs: Google_Cloud_Bigquery_V2_DeleteJobRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.jobID != rhs.jobID {return false}
    if lhs.location != rhs.location {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_ListJobsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".ListJobsRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "all_users"),
    3: .standard(proto: "max_results"),
    4: .standard(proto: "min_creation_time"),
    5: .standard(proto: "max_creation_time"),
    6: .standard(proto: "page_token"),
    7: .same(proto: "projection"),
    8: .standard(proto: "state_filter"),
    9: .standard(proto: "parent_job_id"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.allUsers) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._maxResults) }()
      case 4: try { try decoder.decodeSingularUInt64Field(value: &self.minCreationTime) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._maxCreationTime) }()
      case 6: try { try decoder.decodeSingularStringField(value: &self.pageToken) }()
      case 7: try { try decoder.decodeSingularEnumField(value: &self.projection) }()
      case 8: try { try decoder.decodeRepeatedEnumField(value: &self.stateFilter) }()
      case 9: try { try decoder.decodeSingularStringField(value: &self.parentJobID) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if self.allUsers != false {
      try visitor.visitSingularBoolField(value: self.allUsers, fieldNumber: 2)
    }
    try { if let v = self._maxResults {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    if self.minCreationTime != 0 {
      try visitor.visitSingularUInt64Field(value: self.minCreationTime, fieldNumber: 4)
    }
    try { if let v = self._maxCreationTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    if !self.pageToken.isEmpty {
      try visitor.visitSingularStringField(value: self.pageToken, fieldNumber: 6)
    }
    if self.projection != .minimal {
      try visitor.visitSingularEnumField(value: self.projection, fieldNumber: 7)
    }
    if !self.stateFilter.isEmpty {
      try visitor.visitPackedEnumField(value: self.stateFilter, fieldNumber: 8)
    }
    if !self.parentJobID.isEmpty {
      try visitor.visitSingularStringField(value: self.parentJobID, fieldNumber: 9)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_ListJobsRequest, rhs: Google_Cloud_Bigquery_V2_ListJobsRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.allUsers != rhs.allUsers {return false}
    if lhs._maxResults != rhs._maxResults {return false}
    if lhs.minCreationTime != rhs.minCreationTime {return false}
    if lhs._maxCreationTime != rhs._maxCreationTime {return false}
    if lhs.pageToken != rhs.pageToken {return false}
    if lhs.projection != rhs.projection {return false}
    if lhs.stateFilter != rhs.stateFilter {return false}
    if lhs.parentJobID != rhs.parentJobID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_ListJobsRequest.Projection: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .aliased(proto: "minimal", aliases: ["MINIMAL"]),
    1: .aliased(proto: "full", aliases: ["FULL"]),
  ]
}

extension Google_Cloud_Bigquery_V2_ListJobsRequest.StateFilter: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .aliased(proto: "done", aliases: ["DONE"]),
    1: .aliased(proto: "pending", aliases: ["PENDING"]),
    2: .aliased(proto: "running", aliases: ["RUNNING"]),
  ]
}

extension Google_Cloud_Bigquery_V2_ListFormatJob: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".ListFormatJob"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "id"),
    2: .same(proto: "kind"),
    3: .standard(proto: "job_reference"),
    4: .same(proto: "state"),
    5: .standard(proto: "error_result"),
    6: .same(proto: "statistics"),
    7: .same(proto: "configuration"),
    8: .same(proto: "status"),
    9: .standard(proto: "user_email"),
    10: .standard(proto: "principal_subject"),
  ]

  fileprivate class _StorageClass {
    var _id: String = String()
    var _kind: String = String()
    var _jobReference: Google_Cloud_Bigquery_V2_JobReference? = nil
    var _state: String = String()
    var _errorResult: Google_Cloud_Bigquery_V2_ErrorProto? = nil
    var _statistics: Google_Cloud_Bigquery_V2_JobStatistics? = nil
    var _configuration: Google_Cloud_Bigquery_V2_JobConfiguration? = nil
    var _status: Google_Cloud_Bigquery_V2_JobStatus? = nil
    var _userEmail: String = String()
    var _principalSubject: String = String()

    #if swift(>=5.10)
      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()
    #else
      static let defaultInstance = _StorageClass()
    #endif

    private init() {}

    init(copying source: _StorageClass) {
      _id = source._id
      _kind = source._kind
      _jobReference = source._jobReference
      _state = source._state
      _errorResult = source._errorResult
      _statistics = source._statistics
      _configuration = source._configuration
      _status = source._status
      _userEmail = source._userEmail
      _principalSubject = source._principalSubject
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._id) }()
        case 2: try { try decoder.decodeSingularStringField(value: &_storage._kind) }()
        case 3: try { try decoder.decodeSingularMessageField(value: &_storage._jobReference) }()
        case 4: try { try decoder.decodeSingularStringField(value: &_storage._state) }()
        case 5: try { try decoder.decodeSingularMessageField(value: &_storage._errorResult) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._statistics) }()
        case 7: try { try decoder.decodeSingularMessageField(value: &_storage._configuration) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._status) }()
        case 9: try { try decoder.decodeSingularStringField(value: &_storage._userEmail) }()
        case 10: try { try decoder.decodeSingularStringField(value: &_storage._principalSubject) }()
        default: break
        }
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if !_storage._id.isEmpty {
        try visitor.visitSingularStringField(value: _storage._id, fieldNumber: 1)
      }
      if !_storage._kind.isEmpty {
        try visitor.visitSingularStringField(value: _storage._kind, fieldNumber: 2)
      }
      try { if let v = _storage._jobReference {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      } }()
      if !_storage._state.isEmpty {
        try visitor.visitSingularStringField(value: _storage._state, fieldNumber: 4)
      }
      try { if let v = _storage._errorResult {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
      } }()
      try { if let v = _storage._statistics {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      } }()
      try { if let v = _storage._configuration {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      } }()
      try { if let v = _storage._status {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      } }()
      if !_storage._userEmail.isEmpty {
        try visitor.visitSingularStringField(value: _storage._userEmail, fieldNumber: 9)
      }
      if !_storage._principalSubject.isEmpty {
        try visitor.visitSingularStringField(value: _storage._principalSubject, fieldNumber: 10)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_ListFormatJob, rhs: Google_Cloud_Bigquery_V2_ListFormatJob) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._id != rhs_storage._id {return false}
        if _storage._kind != rhs_storage._kind {return false}
        if _storage._jobReference != rhs_storage._jobReference {return false}
        if _storage._state != rhs_storage._state {return false}
        if _storage._errorResult != rhs_storage._errorResult {return false}
        if _storage._statistics != rhs_storage._statistics {return false}
        if _storage._configuration != rhs_storage._configuration {return false}
        if _storage._status != rhs_storage._status {return false}
        if _storage._userEmail != rhs_storage._userEmail {return false}
        if _storage._principalSubject != rhs_storage._principalSubject {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_JobList: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".JobList"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "etag"),
    2: .same(proto: "kind"),
    3: .standard(proto: "next_page_token"),
    4: .same(proto: "jobs"),
    5: .same(proto: "unreachable"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.etag) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.kind) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.nextPageToken) }()
      case 4: try { try decoder.decodeRepeatedMessageField(value: &self.jobs) }()
      case 5: try { try decoder.decodeRepeatedStringField(value: &self.unreachable) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.etag.isEmpty {
      try visitor.visitSingularStringField(value: self.etag, fieldNumber: 1)
    }
    if !self.kind.isEmpty {
      try visitor.visitSingularStringField(value: self.kind, fieldNumber: 2)
    }
    if !self.nextPageToken.isEmpty {
      try visitor.visitSingularStringField(value: self.nextPageToken, fieldNumber: 3)
    }
    if !self.jobs.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.jobs, fieldNumber: 4)
    }
    if !self.unreachable.isEmpty {
      try visitor.visitRepeatedStringField(value: self.unreachable, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_JobList, rhs: Google_Cloud_Bigquery_V2_JobList) -> Bool {
    if lhs.etag != rhs.etag {return false}
    if lhs.kind != rhs.kind {return false}
    if lhs.nextPageToken != rhs.nextPageToken {return false}
    if lhs.jobs != rhs.jobs {return false}
    if lhs.unreachable != rhs.unreachable {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_GetQueryResultsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".GetQueryResultsRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "job_id"),
    3: .standard(proto: "start_index"),
    4: .standard(proto: "page_token"),
    5: .standard(proto: "max_results"),
    6: .standard(proto: "timeout_ms"),
    7: .same(proto: "location"),
    8: .standard(proto: "format_options"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.jobID) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._startIndex) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.pageToken) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._maxResults) }()
      case 6: try { try decoder.decodeSingularMessageField(value: &self._timeoutMs) }()
      case 7: try { try decoder.decodeSingularStringField(value: &self.location) }()
      case 8: try { try decoder.decodeSingularMessageField(value: &self._formatOptions) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.jobID.isEmpty {
      try visitor.visitSingularStringField(value: self.jobID, fieldNumber: 2)
    }
    try { if let v = self._startIndex {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    if !self.pageToken.isEmpty {
      try visitor.visitSingularStringField(value: self.pageToken, fieldNumber: 4)
    }
    try { if let v = self._maxResults {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    try { if let v = self._timeoutMs {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    } }()
    if !self.location.isEmpty {
      try visitor.visitSingularStringField(value: self.location, fieldNumber: 7)
    }
    try { if let v = self._formatOptions {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_GetQueryResultsRequest, rhs: Google_Cloud_Bigquery_V2_GetQueryResultsRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.jobID != rhs.jobID {return false}
    if lhs._startIndex != rhs._startIndex {return false}
    if lhs.pageToken != rhs.pageToken {return false}
    if lhs._maxResults != rhs._maxResults {return false}
    if lhs._timeoutMs != rhs._timeoutMs {return false}
    if lhs.location != rhs.location {return false}
    if lhs._formatOptions != rhs._formatOptions {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_GetQueryResultsResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".GetQueryResultsResponse"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "kind"),
    2: .same(proto: "etag"),
    3: .same(proto: "schema"),
    4: .standard(proto: "job_reference"),
    5: .standard(proto: "total_rows"),
    6: .standard(proto: "page_token"),
    7: .same(proto: "rows"),
    8: .standard(proto: "total_bytes_processed"),
    9: .standard(proto: "job_complete"),
    10: .same(proto: "errors"),
    11: .standard(proto: "cache_hit"),
    12: .standard(proto: "num_dml_affected_rows"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.kind) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.etag) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._schema) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._jobReference) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._totalRows) }()
      case 6: try { try decoder.decodeSingularStringField(value: &self.pageToken) }()
      case 7: try { try decoder.decodeRepeatedMessageField(value: &self.rows) }()
      case 8: try { try decoder.decodeSingularMessageField(value: &self._totalBytesProcessed) }()
      case 9: try { try decoder.decodeSingularMessageField(value: &self._jobComplete) }()
      case 10: try { try decoder.decodeRepeatedMessageField(value: &self.errors) }()
      case 11: try { try decoder.decodeSingularMessageField(value: &self._cacheHit) }()
      case 12: try { try decoder.decodeSingularMessageField(value: &self._numDmlAffectedRows) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.kind.isEmpty {
      try visitor.visitSingularStringField(value: self.kind, fieldNumber: 1)
    }
    if !self.etag.isEmpty {
      try visitor.visitSingularStringField(value: self.etag, fieldNumber: 2)
    }
    try { if let v = self._schema {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._jobReference {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try { if let v = self._totalRows {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    if !self.pageToken.isEmpty {
      try visitor.visitSingularStringField(value: self.pageToken, fieldNumber: 6)
    }
    if !self.rows.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.rows, fieldNumber: 7)
    }
    try { if let v = self._totalBytesProcessed {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
    } }()
    try { if let v = self._jobComplete {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
    } }()
    if !self.errors.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.errors, fieldNumber: 10)
    }
    try { if let v = self._cacheHit {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
    } }()
    try { if let v = self._numDmlAffectedRows {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 12)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_GetQueryResultsResponse, rhs: Google_Cloud_Bigquery_V2_GetQueryResultsResponse) -> Bool {
    if lhs.kind != rhs.kind {return false}
    if lhs.etag != rhs.etag {return false}
    if lhs._schema != rhs._schema {return false}
    if lhs._jobReference != rhs._jobReference {return false}
    if lhs._totalRows != rhs._totalRows {return false}
    if lhs.pageToken != rhs.pageToken {return false}
    if lhs.rows != rhs.rows {return false}
    if lhs._totalBytesProcessed != rhs._totalBytesProcessed {return false}
    if lhs._jobComplete != rhs._jobComplete {return false}
    if lhs.errors != rhs.errors {return false}
    if lhs._cacheHit != rhs._cacheHit {return false}
    if lhs._numDmlAffectedRows != rhs._numDmlAffectedRows {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_PostQueryRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".PostQueryRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "query_request"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._queryRequest) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    try { if let v = self._queryRequest {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_PostQueryRequest, rhs: Google_Cloud_Bigquery_V2_PostQueryRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs._queryRequest != rhs._queryRequest {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_QueryRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".QueryRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    2: .same(proto: "kind"),
    3: .same(proto: "query"),
    4: .standard(proto: "max_results"),
    5: .standard(proto: "default_dataset"),
    6: .standard(proto: "timeout_ms"),
    7: .standard(proto: "dry_run"),
    9: .standard(proto: "use_query_cache"),
    10: .standard(proto: "use_legacy_sql"),
    11: .standard(proto: "parameter_mode"),
    12: .standard(proto: "query_parameters"),
    13: .same(proto: "location"),
    15: .standard(proto: "format_options"),
    16: .standard(proto: "connection_properties"),
    17: .same(proto: "labels"),
    18: .standard(proto: "maximum_bytes_billed"),
    19: .standard(proto: "request_id"),
    20: .standard(proto: "create_session"),
    22: .standard(proto: "job_creation_mode"),
  ]

  fileprivate class _StorageClass {
    var _kind: String = String()
    var _query: String = String()
    var _maxResults: SwiftProtobuf.Google_Protobuf_UInt32Value? = nil
    var _defaultDataset: Google_Cloud_Bigquery_V2_DatasetReference? = nil
    var _timeoutMs: SwiftProtobuf.Google_Protobuf_UInt32Value? = nil
    var _dryRun: Bool = false
    var _useQueryCache: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _useLegacySql: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _parameterMode: String = String()
    var _queryParameters: [Google_Cloud_Bigquery_V2_QueryParameter] = []
    var _location: String = String()
    var _formatOptions: Google_Cloud_Bigquery_V2_DataFormatOptions? = nil
    var _connectionProperties: [Google_Cloud_Bigquery_V2_ConnectionProperty] = []
    var _labels: Dictionary<String,String> = [:]
    var _maximumBytesBilled: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _requestID: String = String()
    var _createSession: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _jobCreationMode: Google_Cloud_Bigquery_V2_QueryRequest.JobCreationMode = .unspecified

    #if swift(>=5.10)
      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()
    #else
      static let defaultInstance = _StorageClass()
    #endif

    private init() {}

    init(copying source: _StorageClass) {
      _kind = source._kind
      _query = source._query
      _maxResults = source._maxResults
      _defaultDataset = source._defaultDataset
      _timeoutMs = source._timeoutMs
      _dryRun = source._dryRun
      _useQueryCache = source._useQueryCache
      _useLegacySql = source._useLegacySql
      _parameterMode = source._parameterMode
      _queryParameters = source._queryParameters
      _location = source._location
      _formatOptions = source._formatOptions
      _connectionProperties = source._connectionProperties
      _labels = source._labels
      _maximumBytesBilled = source._maximumBytesBilled
      _requestID = source._requestID
      _createSession = source._createSession
      _jobCreationMode = source._jobCreationMode
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 2: try { try decoder.decodeSingularStringField(value: &_storage._kind) }()
        case 3: try { try decoder.decodeSingularStringField(value: &_storage._query) }()
        case 4: try { try decoder.decodeSingularMessageField(value: &_storage._maxResults) }()
        case 5: try { try decoder.decodeSingularMessageField(value: &_storage._defaultDataset) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._timeoutMs) }()
        case 7: try { try decoder.decodeSingularBoolField(value: &_storage._dryRun) }()
        case 9: try { try decoder.decodeSingularMessageField(value: &_storage._useQueryCache) }()
        case 10: try { try decoder.decodeSingularMessageField(value: &_storage._useLegacySql) }()
        case 11: try { try decoder.decodeSingularStringField(value: &_storage._parameterMode) }()
        case 12: try { try decoder.decodeRepeatedMessageField(value: &_storage._queryParameters) }()
        case 13: try { try decoder.decodeSingularStringField(value: &_storage._location) }()
        case 15: try { try decoder.decodeSingularMessageField(value: &_storage._formatOptions) }()
        case 16: try { try decoder.decodeRepeatedMessageField(value: &_storage._connectionProperties) }()
        case 17: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &_storage._labels) }()
        case 18: try { try decoder.decodeSingularMessageField(value: &_storage._maximumBytesBilled) }()
        case 19: try { try decoder.decodeSingularStringField(value: &_storage._requestID) }()
        case 20: try { try decoder.decodeSingularMessageField(value: &_storage._createSession) }()
        case 22: try { try decoder.decodeSingularEnumField(value: &_storage._jobCreationMode) }()
        default: break
        }
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if !_storage._kind.isEmpty {
        try visitor.visitSingularStringField(value: _storage._kind, fieldNumber: 2)
      }
      if !_storage._query.isEmpty {
        try visitor.visitSingularStringField(value: _storage._query, fieldNumber: 3)
      }
      try { if let v = _storage._maxResults {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      } }()
      try { if let v = _storage._defaultDataset {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
      } }()
      try { if let v = _storage._timeoutMs {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      } }()
      if _storage._dryRun != false {
        try visitor.visitSingularBoolField(value: _storage._dryRun, fieldNumber: 7)
      }
      try { if let v = _storage._useQueryCache {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      } }()
      try { if let v = _storage._useLegacySql {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
      } }()
      if !_storage._parameterMode.isEmpty {
        try visitor.visitSingularStringField(value: _storage._parameterMode, fieldNumber: 11)
      }
      if !_storage._queryParameters.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._queryParameters, fieldNumber: 12)
      }
      if !_storage._location.isEmpty {
        try visitor.visitSingularStringField(value: _storage._location, fieldNumber: 13)
      }
      try { if let v = _storage._formatOptions {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 15)
      } }()
      if !_storage._connectionProperties.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._connectionProperties, fieldNumber: 16)
      }
      if !_storage._labels.isEmpty {
        try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: _storage._labels, fieldNumber: 17)
      }
      try { if let v = _storage._maximumBytesBilled {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 18)
      } }()
      if !_storage._requestID.isEmpty {
        try visitor.visitSingularStringField(value: _storage._requestID, fieldNumber: 19)
      }
      try { if let v = _storage._createSession {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 20)
      } }()
      if _storage._jobCreationMode != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._jobCreationMode, fieldNumber: 22)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_QueryRequest, rhs: Google_Cloud_Bigquery_V2_QueryRequest) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._kind != rhs_storage._kind {return false}
        if _storage._query != rhs_storage._query {return false}
        if _storage._maxResults != rhs_storage._maxResults {return false}
        if _storage._defaultDataset != rhs_storage._defaultDataset {return false}
        if _storage._timeoutMs != rhs_storage._timeoutMs {return false}
        if _storage._dryRun != rhs_storage._dryRun {return false}
        if _storage._useQueryCache != rhs_storage._useQueryCache {return false}
        if _storage._useLegacySql != rhs_storage._useLegacySql {return false}
        if _storage._parameterMode != rhs_storage._parameterMode {return false}
        if _storage._queryParameters != rhs_storage._queryParameters {return false}
        if _storage._location != rhs_storage._location {return false}
        if _storage._formatOptions != rhs_storage._formatOptions {return false}
        if _storage._connectionProperties != rhs_storage._connectionProperties {return false}
        if _storage._labels != rhs_storage._labels {return false}
        if _storage._maximumBytesBilled != rhs_storage._maximumBytesBilled {return false}
        if _storage._requestID != rhs_storage._requestID {return false}
        if _storage._createSession != rhs_storage._createSession {return false}
        if _storage._jobCreationMode != rhs_storage._jobCreationMode {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_QueryRequest.JobCreationMode: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "JOB_CREATION_MODE_UNSPECIFIED"),
    1: .same(proto: "JOB_CREATION_REQUIRED"),
    2: .same(proto: "JOB_CREATION_OPTIONAL"),
  ]
}

extension Google_Cloud_Bigquery_V2_QueryResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".QueryResponse"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "kind"),
    2: .same(proto: "schema"),
    3: .standard(proto: "job_reference"),
    15: .standard(proto: "job_creation_reason"),
    14: .standard(proto: "query_id"),
    4: .standard(proto: "total_rows"),
    5: .standard(proto: "page_token"),
    6: .same(proto: "rows"),
    7: .standard(proto: "total_bytes_processed"),
    8: .standard(proto: "job_complete"),
    9: .same(proto: "errors"),
    10: .standard(proto: "cache_hit"),
    11: .standard(proto: "num_dml_affected_rows"),
    12: .standard(proto: "session_info"),
    13: .standard(proto: "dml_stats"),
  ]

  fileprivate class _StorageClass {
    var _kind: String = String()
    var _schema: Google_Cloud_Bigquery_V2_TableSchema? = nil
    var _jobReference: Google_Cloud_Bigquery_V2_JobReference? = nil
    var _jobCreationReason: Google_Cloud_Bigquery_V2_JobCreationReason? = nil
    var _queryID: String = String()
    var _totalRows: SwiftProtobuf.Google_Protobuf_UInt64Value? = nil
    var _pageToken: String = String()
    var _rows: [SwiftProtobuf.Google_Protobuf_Struct] = []
    var _totalBytesProcessed: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _jobComplete: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _errors: [Google_Cloud_Bigquery_V2_ErrorProto] = []
    var _cacheHit: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _numDmlAffectedRows: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _sessionInfo: Google_Cloud_Bigquery_V2_SessionInfo? = nil
    var _dmlStats: Google_Cloud_Bigquery_V2_DmlStats? = nil

    #if swift(>=5.10)
      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()
    #else
      static let defaultInstance = _StorageClass()
    #endif

    private init() {}

    init(copying source: _StorageClass) {
      _kind = source._kind
      _schema = source._schema
      _jobReference = source._jobReference
      _jobCreationReason = source._jobCreationReason
      _queryID = source._queryID
      _totalRows = source._totalRows
      _pageToken = source._pageToken
      _rows = source._rows
      _totalBytesProcessed = source._totalBytesProcessed
      _jobComplete = source._jobComplete
      _errors = source._errors
      _cacheHit = source._cacheHit
      _numDmlAffectedRows = source._numDmlAffectedRows
      _sessionInfo = source._sessionInfo
      _dmlStats = source._dmlStats
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._kind) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._schema) }()
        case 3: try { try decoder.decodeSingularMessageField(value: &_storage._jobReference) }()
        case 4: try { try decoder.decodeSingularMessageField(value: &_storage._totalRows) }()
        case 5: try { try decoder.decodeSingularStringField(value: &_storage._pageToken) }()
        case 6: try { try decoder.decodeRepeatedMessageField(value: &_storage._rows) }()
        case 7: try { try decoder.decodeSingularMessageField(value: &_storage._totalBytesProcessed) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._jobComplete) }()
        case 9: try { try decoder.decodeRepeatedMessageField(value: &_storage._errors) }()
        case 10: try { try decoder.decodeSingularMessageField(value: &_storage._cacheHit) }()
        case 11: try { try decoder.decodeSingularMessageField(value: &_storage._numDmlAffectedRows) }()
        case 12: try { try decoder.decodeSingularMessageField(value: &_storage._sessionInfo) }()
        case 13: try { try decoder.decodeSingularMessageField(value: &_storage._dmlStats) }()
        case 14: try { try decoder.decodeSingularStringField(value: &_storage._queryID) }()
        case 15: try { try decoder.decodeSingularMessageField(value: &_storage._jobCreationReason) }()
        default: break
        }
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if !_storage._kind.isEmpty {
        try visitor.visitSingularStringField(value: _storage._kind, fieldNumber: 1)
      }
      try { if let v = _storage._schema {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      } }()
      try { if let v = _storage._jobReference {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      } }()
      try { if let v = _storage._totalRows {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      } }()
      if !_storage._pageToken.isEmpty {
        try visitor.visitSingularStringField(value: _storage._pageToken, fieldNumber: 5)
      }
      if !_storage._rows.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._rows, fieldNumber: 6)
      }
      try { if let v = _storage._totalBytesProcessed {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      } }()
      try { if let v = _storage._jobComplete {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      } }()
      if !_storage._errors.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._errors, fieldNumber: 9)
      }
      try { if let v = _storage._cacheHit {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
      } }()
      try { if let v = _storage._numDmlAffectedRows {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
      } }()
      try { if let v = _storage._sessionInfo {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 12)
      } }()
      try { if let v = _storage._dmlStats {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 13)
      } }()
      if !_storage._queryID.isEmpty {
        try visitor.visitSingularStringField(value: _storage._queryID, fieldNumber: 14)
      }
      try { if let v = _storage._jobCreationReason {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 15)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_QueryResponse, rhs: Google_Cloud_Bigquery_V2_QueryResponse) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._kind != rhs_storage._kind {return false}
        if _storage._schema != rhs_storage._schema {return false}
        if _storage._jobReference != rhs_storage._jobReference {return false}
        if _storage._jobCreationReason != rhs_storage._jobCreationReason {return false}
        if _storage._queryID != rhs_storage._queryID {return false}
        if _storage._totalRows != rhs_storage._totalRows {return false}
        if _storage._pageToken != rhs_storage._pageToken {return false}
        if _storage._rows != rhs_storage._rows {return false}
        if _storage._totalBytesProcessed != rhs_storage._totalBytesProcessed {return false}
        if _storage._jobComplete != rhs_storage._jobComplete {return false}
        if _storage._errors != rhs_storage._errors {return false}
        if _storage._cacheHit != rhs_storage._cacheHit {return false}
        if _storage._numDmlAffectedRows != rhs_storage._numDmlAffectedRows {return false}
        if _storage._sessionInfo != rhs_storage._sessionInfo {return false}
        if _storage._dmlStats != rhs_storage._dmlStats {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
