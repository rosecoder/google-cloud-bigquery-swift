// DO NOT EDIT.
// swift-format-ignore-file
// swiftlint:disable all
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/bigquery/v2/dataset.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Grants all resources of particular types in a particular dataset read access
/// to the current dataset.
///
/// Similar to how individually authorized views work, updates to any resource
/// granted through its dataset (including creation of new resources) requires
/// read permission to referenced resources, plus write permission to the
/// authorizing dataset.
package struct Google_Cloud_Bigquery_V2_DatasetAccessEntry: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The dataset this entry applies to
  package var dataset: Google_Cloud_Bigquery_V2_DatasetReference {
    get {return _dataset ?? Google_Cloud_Bigquery_V2_DatasetReference()}
    set {_dataset = newValue}
  }
  /// Returns true if `dataset` has been explicitly set.
  package var hasDataset: Bool {return self._dataset != nil}
  /// Clears the value of `dataset`. Subsequent reads from it will return its default value.
  package mutating func clearDataset() {self._dataset = nil}

  /// Which resources in the dataset this entry applies to. Currently, only
  /// views are supported, but additional target types may be added in the
  /// future.
  package var targetTypes: [Google_Cloud_Bigquery_V2_DatasetAccessEntry.TargetType] = []

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Indicates the type of resources in a dataset that the entry applies to.
  package enum TargetType: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Do not use. You must set a target type explicitly.
    case unspecified // = 0

    /// This entry applies to views in the dataset.
    case views // = 1

    /// This entry applies to routines in the dataset.
    case routines // = 2
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .views
      case 2: self = .routines
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .views: return 1
      case .routines: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_DatasetAccessEntry.TargetType] = [
      .unspecified,
      .views,
      .routines,
    ]

  }

  package init() {}

  fileprivate var _dataset: Google_Cloud_Bigquery_V2_DatasetReference? = nil
}

/// An object that defines dataset access for an entity.
package struct Google_Cloud_Bigquery_V2_Access: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// An IAM role ID that should be granted to the user, group,
  /// or domain specified in this access entry.
  /// The following legacy mappings will be applied:
  ///
  /// * `OWNER`: `roles/bigquery.dataOwner`
  /// * `WRITER`: `roles/bigquery.dataEditor`
  /// * `READER`: `roles/bigquery.dataViewer`
  ///
  /// This field will accept any of the above formats, but will return only
  /// the legacy format. For example, if you set this field to
  /// "roles/bigquery.dataOwner", it will be returned back as "OWNER".
  package var role: String {
    get {return _storage._role}
    set {_uniqueStorage()._role = newValue}
  }

  /// [Pick one] An email address of a user to grant access to. For example:
  /// fred@example.com. Maps to IAM policy member "user:EMAIL" or
  /// "serviceAccount:EMAIL".
  package var userByEmail: String {
    get {return _storage._userByEmail}
    set {_uniqueStorage()._userByEmail = newValue}
  }

  /// [Pick one] An email address of a Google Group to grant access to.
  /// Maps to IAM policy member "group:GROUP".
  package var groupByEmail: String {
    get {return _storage._groupByEmail}
    set {_uniqueStorage()._groupByEmail = newValue}
  }

  /// [Pick one] A domain to grant access to. Any users signed in with the domain
  /// specified will be granted the specified access. Example: "example.com".
  /// Maps to IAM policy member "domain:DOMAIN".
  package var domain: String {
    get {return _storage._domain}
    set {_uniqueStorage()._domain = newValue}
  }

  /// [Pick one] A special group to grant access to. Possible values include:
  ///
  ///   * projectOwners: Owners of the enclosing project.
  ///   * projectReaders: Readers of the enclosing project.
  ///   * projectWriters: Writers of the enclosing project.
  ///   * allAuthenticatedUsers: All authenticated BigQuery users.
  ///
  /// Maps to similarly-named IAM members.
  package var specialGroup: String {
    get {return _storage._specialGroup}
    set {_uniqueStorage()._specialGroup = newValue}
  }

  /// [Pick one] Some other type of member that appears in the IAM Policy but
  /// isn't a user, group, domain, or special group.
  package var iamMember: String {
    get {return _storage._iamMember}
    set {_uniqueStorage()._iamMember = newValue}
  }

  /// [Pick one] A view from a different dataset to grant access to. Queries
  /// executed against that view will have read access to views/tables/routines
  /// in this dataset.
  /// The role field is not required when this field is set. If that view is
  /// updated by any user, access to the view needs to be granted again via an
  /// update operation.
  package var view: Google_Cloud_Bigquery_V2_TableReference {
    get {return _storage._view ?? Google_Cloud_Bigquery_V2_TableReference()}
    set {_uniqueStorage()._view = newValue}
  }
  /// Returns true if `view` has been explicitly set.
  package var hasView: Bool {return _storage._view != nil}
  /// Clears the value of `view`. Subsequent reads from it will return its default value.
  package mutating func clearView() {_uniqueStorage()._view = nil}

  /// [Pick one] A routine from a different dataset to grant access to. Queries
  /// executed against that routine will have read access to
  /// views/tables/routines in this dataset. Only UDF is supported for now.
  /// The role field is not required when this field is set. If that routine is
  /// updated by any user, access to the routine needs to be granted again via
  /// an update operation.
  package var routine: Google_Cloud_Bigquery_V2_RoutineReference {
    get {return _storage._routine ?? Google_Cloud_Bigquery_V2_RoutineReference()}
    set {_uniqueStorage()._routine = newValue}
  }
  /// Returns true if `routine` has been explicitly set.
  package var hasRoutine: Bool {return _storage._routine != nil}
  /// Clears the value of `routine`. Subsequent reads from it will return its default value.
  package mutating func clearRoutine() {_uniqueStorage()._routine = nil}

  /// [Pick one] A grant authorizing all resources of a particular type in a
  /// particular dataset access to this dataset. Only views are supported for
  /// now. The role field is not required when this field is set. If that dataset
  /// is deleted and re-created, its access needs to be granted again via an
  /// update operation.
  package var dataset: Google_Cloud_Bigquery_V2_DatasetAccessEntry {
    get {return _storage._dataset ?? Google_Cloud_Bigquery_V2_DatasetAccessEntry()}
    set {_uniqueStorage()._dataset = newValue}
  }
  /// Returns true if `dataset` has been explicitly set.
  package var hasDataset: Bool {return _storage._dataset != nil}
  /// Clears the value of `dataset`. Subsequent reads from it will return its default value.
  package mutating func clearDataset() {_uniqueStorage()._dataset = nil}

  /// Optional. condition for the binding. If CEL expression in this field is
  /// true, this access binding will be considered
  package var condition: Google_Type_Expr {
    get {return _storage._condition ?? Google_Type_Expr()}
    set {_uniqueStorage()._condition = newValue}
  }
  /// Returns true if `condition` has been explicitly set.
  package var hasCondition: Bool {return _storage._condition != nil}
  /// Clears the value of `condition`. Subsequent reads from it will return its default value.
  package mutating func clearCondition() {_uniqueStorage()._condition = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Represents a BigQuery dataset.
package struct Google_Cloud_Bigquery_V2_Dataset: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. The resource type.
  package var kind: String {
    get {return _storage._kind}
    set {_uniqueStorage()._kind = newValue}
  }

  /// Output only. A hash of the resource.
  package var etag: String {
    get {return _storage._etag}
    set {_uniqueStorage()._etag = newValue}
  }

  /// Output only. The fully-qualified unique name of the dataset in the format
  /// projectId:datasetId. The dataset name without the project name is given in
  /// the datasetId field. When creating a new dataset, leave this field blank,
  /// and instead specify the datasetId field.
  package var id: String {
    get {return _storage._id}
    set {_uniqueStorage()._id = newValue}
  }

  /// Output only. A URL that can be used to access the resource again. You can
  /// use this URL in Get or Update requests to the resource.
  package var selfLink: String {
    get {return _storage._selfLink}
    set {_uniqueStorage()._selfLink = newValue}
  }

  /// Required. A reference that identifies the dataset.
  package var datasetReference: Google_Cloud_Bigquery_V2_DatasetReference {
    get {return _storage._datasetReference ?? Google_Cloud_Bigquery_V2_DatasetReference()}
    set {_uniqueStorage()._datasetReference = newValue}
  }
  /// Returns true if `datasetReference` has been explicitly set.
  package var hasDatasetReference: Bool {return _storage._datasetReference != nil}
  /// Clears the value of `datasetReference`. Subsequent reads from it will return its default value.
  package mutating func clearDatasetReference() {_uniqueStorage()._datasetReference = nil}

  /// Optional. A descriptive name for the dataset.
  package var friendlyName: SwiftProtobuf.Google_Protobuf_StringValue {
    get {return _storage._friendlyName ?? SwiftProtobuf.Google_Protobuf_StringValue()}
    set {_uniqueStorage()._friendlyName = newValue}
  }
  /// Returns true if `friendlyName` has been explicitly set.
  package var hasFriendlyName: Bool {return _storage._friendlyName != nil}
  /// Clears the value of `friendlyName`. Subsequent reads from it will return its default value.
  package mutating func clearFriendlyName() {_uniqueStorage()._friendlyName = nil}

  /// Optional. A user-friendly description of the dataset.
  package var description_p: SwiftProtobuf.Google_Protobuf_StringValue {
    get {return _storage._description_p ?? SwiftProtobuf.Google_Protobuf_StringValue()}
    set {_uniqueStorage()._description_p = newValue}
  }
  /// Returns true if `description_p` has been explicitly set.
  package var hasDescription_p: Bool {return _storage._description_p != nil}
  /// Clears the value of `description_p`. Subsequent reads from it will return its default value.
  package mutating func clearDescription_p() {_uniqueStorage()._description_p = nil}

  /// Optional. The default lifetime of all tables in the dataset, in
  /// milliseconds. The minimum lifetime value is 3600000 milliseconds (one
  /// hour). To clear an existing default expiration with a PATCH request, set to
  /// 0. Once this property is set, all newly-created tables in the dataset will
  /// have an expirationTime property set to the creation time plus the value in
  /// this property, and changing the value will only affect new tables, not
  /// existing ones. When the expirationTime for a given table is reached, that
  /// table will be deleted automatically.
  /// If a table's expirationTime is modified or removed before the table
  /// expires, or if you provide an explicit expirationTime when creating a
  /// table, that value takes precedence over the default expiration time
  /// indicated by this property.
  package var defaultTableExpirationMs: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._defaultTableExpirationMs ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._defaultTableExpirationMs = newValue}
  }
  /// Returns true if `defaultTableExpirationMs` has been explicitly set.
  package var hasDefaultTableExpirationMs: Bool {return _storage._defaultTableExpirationMs != nil}
  /// Clears the value of `defaultTableExpirationMs`. Subsequent reads from it will return its default value.
  package mutating func clearDefaultTableExpirationMs() {_uniqueStorage()._defaultTableExpirationMs = nil}

  /// This default partition expiration, expressed in milliseconds.
  ///
  /// When new time-partitioned tables are created in a dataset where this
  /// property is set, the table will inherit this value, propagated as the
  /// `TimePartitioning.expirationMs` property on the new table.  If you set
  /// `TimePartitioning.expirationMs` explicitly when creating a table,
  /// the `defaultPartitionExpirationMs` of the containing dataset is ignored.
  ///
  /// When creating a partitioned table, if `defaultPartitionExpirationMs`
  /// is set, the `defaultTableExpirationMs` value is ignored and the table
  /// will not be inherit a table expiration deadline.
  package var defaultPartitionExpirationMs: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._defaultPartitionExpirationMs ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._defaultPartitionExpirationMs = newValue}
  }
  /// Returns true if `defaultPartitionExpirationMs` has been explicitly set.
  package var hasDefaultPartitionExpirationMs: Bool {return _storage._defaultPartitionExpirationMs != nil}
  /// Clears the value of `defaultPartitionExpirationMs`. Subsequent reads from it will return its default value.
  package mutating func clearDefaultPartitionExpirationMs() {_uniqueStorage()._defaultPartitionExpirationMs = nil}

  /// The labels associated with this dataset. You can use these
  /// to organize and group your datasets.
  /// You can set this property when inserting or updating a dataset.
  /// See [Creating and Updating Dataset
  /// Labels](https://cloud.google.com/bigquery/docs/creating-managing-labels#creating_and_updating_dataset_labels)
  /// for more information.
  package var labels: Dictionary<String,String> {
    get {return _storage._labels}
    set {_uniqueStorage()._labels = newValue}
  }

  /// Optional. An array of objects that define dataset access for one or more
  /// entities. You can set this property when inserting or updating a dataset in
  /// order to control who is allowed to access the data. If unspecified at
  /// dataset creation time, BigQuery adds default dataset access for the
  /// following entities: access.specialGroup: projectReaders; access.role:
  /// READER; access.specialGroup: projectWriters; access.role: WRITER;
  /// access.specialGroup: projectOwners; access.role: OWNER;
  /// access.userByEmail: [dataset creator email]; access.role: OWNER;
  /// If you patch a dataset, then this field is overwritten by the patched
  /// dataset's access field. To add entities, you must supply the entire
  /// existing access array in addition to any new entities that you want to add.
  package var access: [Google_Cloud_Bigquery_V2_Access] {
    get {return _storage._access}
    set {_uniqueStorage()._access = newValue}
  }

  /// Output only. The time when this dataset was created, in milliseconds since
  /// the epoch.
  package var creationTime: Int64 {
    get {return _storage._creationTime}
    set {_uniqueStorage()._creationTime = newValue}
  }

  /// Output only. The date when this dataset was last modified, in milliseconds
  /// since the epoch.
  package var lastModifiedTime: Int64 {
    get {return _storage._lastModifiedTime}
    set {_uniqueStorage()._lastModifiedTime = newValue}
  }

  /// The geographic location where the dataset should reside. See
  /// https://cloud.google.com/bigquery/docs/locations for supported
  /// locations.
  package var location: String {
    get {return _storage._location}
    set {_uniqueStorage()._location = newValue}
  }

  /// The default encryption key for all tables in the dataset.
  /// After this property is set, the encryption key of all newly-created tables
  /// in the dataset is set to this value unless the table creation request or
  /// query explicitly overrides the key.
  package var defaultEncryptionConfiguration: Google_Cloud_Bigquery_V2_EncryptionConfiguration {
    get {return _storage._defaultEncryptionConfiguration ?? Google_Cloud_Bigquery_V2_EncryptionConfiguration()}
    set {_uniqueStorage()._defaultEncryptionConfiguration = newValue}
  }
  /// Returns true if `defaultEncryptionConfiguration` has been explicitly set.
  package var hasDefaultEncryptionConfiguration: Bool {return _storage._defaultEncryptionConfiguration != nil}
  /// Clears the value of `defaultEncryptionConfiguration`. Subsequent reads from it will return its default value.
  package mutating func clearDefaultEncryptionConfiguration() {_uniqueStorage()._defaultEncryptionConfiguration = nil}

  /// Output only. Reserved for future use.
  package var satisfiesPzs: SwiftProtobuf.Google_Protobuf_BoolValue {
    get {return _storage._satisfiesPzs ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
    set {_uniqueStorage()._satisfiesPzs = newValue}
  }
  /// Returns true if `satisfiesPzs` has been explicitly set.
  package var hasSatisfiesPzs: Bool {return _storage._satisfiesPzs != nil}
  /// Clears the value of `satisfiesPzs`. Subsequent reads from it will return its default value.
  package mutating func clearSatisfiesPzs() {_uniqueStorage()._satisfiesPzs = nil}

  /// Output only. Reserved for future use.
  package var satisfiesPzi: SwiftProtobuf.Google_Protobuf_BoolValue {
    get {return _storage._satisfiesPzi ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
    set {_uniqueStorage()._satisfiesPzi = newValue}
  }
  /// Returns true if `satisfiesPzi` has been explicitly set.
  package var hasSatisfiesPzi: Bool {return _storage._satisfiesPzi != nil}
  /// Clears the value of `satisfiesPzi`. Subsequent reads from it will return its default value.
  package mutating func clearSatisfiesPzi() {_uniqueStorage()._satisfiesPzi = nil}

  /// Output only. Same as `type` in `ListFormatDataset`.
  /// The type of the dataset, one of:
  ///
  /// * DEFAULT - only accessible by owner and authorized accounts,
  /// * PUBLIC - accessible by everyone,
  /// * LINKED - linked dataset,
  /// * EXTERNAL - dataset with definition in external metadata catalog.
  package var type: String {
    get {return _storage._type}
    set {_uniqueStorage()._type = newValue}
  }

  /// Optional. The source dataset reference when the dataset is of type LINKED.
  /// For all other dataset types it is not set. This field cannot be updated
  /// once it is set. Any attempt to update this field using Update and Patch API
  /// Operations will be ignored.
  package var linkedDatasetSource: Google_Cloud_Bigquery_V2_LinkedDatasetSource {
    get {return _storage._linkedDatasetSource ?? Google_Cloud_Bigquery_V2_LinkedDatasetSource()}
    set {_uniqueStorage()._linkedDatasetSource = newValue}
  }
  /// Returns true if `linkedDatasetSource` has been explicitly set.
  package var hasLinkedDatasetSource: Bool {return _storage._linkedDatasetSource != nil}
  /// Clears the value of `linkedDatasetSource`. Subsequent reads from it will return its default value.
  package mutating func clearLinkedDatasetSource() {_uniqueStorage()._linkedDatasetSource = nil}

  /// Output only. Metadata about the LinkedDataset. Filled out when the dataset
  /// type is LINKED.
  package var linkedDatasetMetadata: Google_Cloud_Bigquery_V2_LinkedDatasetMetadata {
    get {return _storage._linkedDatasetMetadata ?? Google_Cloud_Bigquery_V2_LinkedDatasetMetadata()}
    set {_uniqueStorage()._linkedDatasetMetadata = newValue}
  }
  /// Returns true if `linkedDatasetMetadata` has been explicitly set.
  package var hasLinkedDatasetMetadata: Bool {return _storage._linkedDatasetMetadata != nil}
  /// Clears the value of `linkedDatasetMetadata`. Subsequent reads from it will return its default value.
  package mutating func clearLinkedDatasetMetadata() {_uniqueStorage()._linkedDatasetMetadata = nil}

  /// Optional. Reference to a read-only external dataset defined in data
  /// catalogs outside of BigQuery. Filled out when the dataset type is EXTERNAL.
  package var externalDatasetReference: Google_Cloud_Bigquery_V2_ExternalDatasetReference {
    get {return _storage._externalDatasetReference ?? Google_Cloud_Bigquery_V2_ExternalDatasetReference()}
    set {_uniqueStorage()._externalDatasetReference = newValue}
  }
  /// Returns true if `externalDatasetReference` has been explicitly set.
  package var hasExternalDatasetReference: Bool {return _storage._externalDatasetReference != nil}
  /// Clears the value of `externalDatasetReference`. Subsequent reads from it will return its default value.
  package mutating func clearExternalDatasetReference() {_uniqueStorage()._externalDatasetReference = nil}

  /// Optional. Options defining open source compatible datasets living in the
  /// BigQuery catalog. Contains metadata of open source database, schema or
  /// namespace represented by the current dataset.
  package var externalCatalogDatasetOptions: Google_Cloud_Bigquery_V2_ExternalCatalogDatasetOptions {
    get {return _storage._externalCatalogDatasetOptions ?? Google_Cloud_Bigquery_V2_ExternalCatalogDatasetOptions()}
    set {_uniqueStorage()._externalCatalogDatasetOptions = newValue}
  }
  /// Returns true if `externalCatalogDatasetOptions` has been explicitly set.
  package var hasExternalCatalogDatasetOptions: Bool {return _storage._externalCatalogDatasetOptions != nil}
  /// Clears the value of `externalCatalogDatasetOptions`. Subsequent reads from it will return its default value.
  package mutating func clearExternalCatalogDatasetOptions() {_uniqueStorage()._externalCatalogDatasetOptions = nil}

  /// Optional. TRUE if the dataset and its table names are case-insensitive,
  /// otherwise FALSE. By default, this is FALSE, which means the dataset and its
  /// table names are case-sensitive. This field does not affect routine
  /// references.
  package var isCaseInsensitive: SwiftProtobuf.Google_Protobuf_BoolValue {
    get {return _storage._isCaseInsensitive ?? SwiftProtobuf.Google_Protobuf_BoolValue()}
    set {_uniqueStorage()._isCaseInsensitive = newValue}
  }
  /// Returns true if `isCaseInsensitive` has been explicitly set.
  package var hasIsCaseInsensitive: Bool {return _storage._isCaseInsensitive != nil}
  /// Clears the value of `isCaseInsensitive`. Subsequent reads from it will return its default value.
  package mutating func clearIsCaseInsensitive() {_uniqueStorage()._isCaseInsensitive = nil}

  /// Optional. Defines the default collation specification of future tables
  /// created in the dataset. If a table is created in this dataset without
  /// table-level default collation, then the table inherits the dataset default
  /// collation, which is applied to the string fields that do not have explicit
  /// collation specified. A change to this field affects only tables created
  /// afterwards, and does not alter the existing tables.
  /// The following values are supported:
  ///
  /// * 'und:ci': undetermined locale, case insensitive.
  /// * '': empty string. Default to case-sensitive behavior.
  package var defaultCollation: SwiftProtobuf.Google_Protobuf_StringValue {
    get {return _storage._defaultCollation ?? SwiftProtobuf.Google_Protobuf_StringValue()}
    set {_uniqueStorage()._defaultCollation = newValue}
  }
  /// Returns true if `defaultCollation` has been explicitly set.
  package var hasDefaultCollation: Bool {return _storage._defaultCollation != nil}
  /// Clears the value of `defaultCollation`. Subsequent reads from it will return its default value.
  package mutating func clearDefaultCollation() {_uniqueStorage()._defaultCollation = nil}

  /// Optional. Defines the default rounding mode specification of new tables
  /// created within this dataset. During table creation, if this field is
  /// specified, the table within this dataset will inherit the default rounding
  /// mode of the dataset. Setting the default rounding mode on a table overrides
  /// this option. Existing tables in the dataset are unaffected.
  /// If columns are defined during that table creation,
  /// they will immediately inherit the table's default rounding mode,
  /// unless otherwise specified.
  package var defaultRoundingMode: Google_Cloud_Bigquery_V2_TableFieldSchema.RoundingMode {
    get {return _storage._defaultRoundingMode}
    set {_uniqueStorage()._defaultRoundingMode = newValue}
  }

  /// Optional. Defines the time travel window in hours. The value can be from 48
  /// to 168 hours (2 to 7 days). The default value is 168 hours if this is not
  /// set.
  package var maxTimeTravelHours: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._maxTimeTravelHours ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._maxTimeTravelHours = newValue}
  }
  /// Returns true if `maxTimeTravelHours` has been explicitly set.
  package var hasMaxTimeTravelHours: Bool {return _storage._maxTimeTravelHours != nil}
  /// Clears the value of `maxTimeTravelHours`. Subsequent reads from it will return its default value.
  package mutating func clearMaxTimeTravelHours() {_uniqueStorage()._maxTimeTravelHours = nil}

  /// Output only. Tags for the dataset. To provide tags as inputs, use the
  /// `resourceTags` field.
  ///
  /// NOTE: This field was marked as deprecated in the .proto file.
  package var tags: [Google_Cloud_Bigquery_V2_GcpTag] {
    get {return _storage._tags}
    set {_uniqueStorage()._tags = newValue}
  }

  /// Optional. Updates storage_billing_model for the dataset.
  package var storageBillingModel: Google_Cloud_Bigquery_V2_Dataset.StorageBillingModel {
    get {return _storage._storageBillingModel}
    set {_uniqueStorage()._storageBillingModel = newValue}
  }

  /// Optional. Output only. Restriction config for all tables and dataset. If
  /// set, restrict certain accesses on the dataset and all its tables based on
  /// the config. See [Data
  /// egress](https://cloud.google.com/bigquery/docs/analytics-hub-introduction#data_egress)
  /// for more details.
  package var restrictions: Google_Cloud_Bigquery_V2_RestrictionConfig {
    get {return _storage._restrictions ?? Google_Cloud_Bigquery_V2_RestrictionConfig()}
    set {_uniqueStorage()._restrictions = newValue}
  }
  /// Returns true if `restrictions` has been explicitly set.
  package var hasRestrictions: Bool {return _storage._restrictions != nil}
  /// Clears the value of `restrictions`. Subsequent reads from it will return its default value.
  package mutating func clearRestrictions() {_uniqueStorage()._restrictions = nil}

  /// Optional. The [tags](https://cloud.google.com/bigquery/docs/tags) attached
  /// to this dataset. Tag keys are globally unique. Tag key is expected to be in
  /// the namespaced format, for example "123456789012/environment" where
  /// 123456789012 is the ID of the parent organization or project resource for
  /// this tag key. Tag value is expected to be the short name, for example
  /// "Production". See [Tag
  /// definitions](https://cloud.google.com/iam/docs/tags-access-control#definitions)
  /// for more details.
  package var resourceTags: Dictionary<String,String> {
    get {return _storage._resourceTags}
    set {_uniqueStorage()._resourceTags = newValue}
  }

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Indicates the billing model that will be applied to the dataset.
  package enum StorageBillingModel: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// Value not set.
    case unspecified // = 0

    /// Billing for logical bytes.
    case logical // = 1

    /// Billing for physical bytes.
    case physical // = 2
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .logical
      case 2: self = .physical
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .logical: return 1
      case .physical: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_Dataset.StorageBillingModel] = [
      .unspecified,
      .logical,
      .physical,
    ]

  }

  package init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// A global tag managed by Resource Manager.
/// https://cloud.google.com/iam/docs/tags-access-control#definitions
package struct Google_Cloud_Bigquery_V2_GcpTag: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The namespaced friendly name of the tag key, e.g.
  /// "12345/environment" where 12345 is org id.
  package var tagKey: String = String()

  /// Required. The friendly short name of the tag value, e.g. "production".
  package var tagValue: String = String()

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

/// A dataset source type which refers to another BigQuery dataset.
package struct Google_Cloud_Bigquery_V2_LinkedDatasetSource: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The source dataset reference contains project numbers and not project ids.
  package var sourceDataset: Google_Cloud_Bigquery_V2_DatasetReference {
    get {return _sourceDataset ?? Google_Cloud_Bigquery_V2_DatasetReference()}
    set {_sourceDataset = newValue}
  }
  /// Returns true if `sourceDataset` has been explicitly set.
  package var hasSourceDataset: Bool {return self._sourceDataset != nil}
  /// Clears the value of `sourceDataset`. Subsequent reads from it will return its default value.
  package mutating func clearSourceDataset() {self._sourceDataset = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _sourceDataset: Google_Cloud_Bigquery_V2_DatasetReference? = nil
}

/// Metadata about the Linked Dataset.
package struct Google_Cloud_Bigquery_V2_LinkedDatasetMetadata: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Specifies whether Linked Dataset is currently in a linked
  /// state or not.
  package var linkState: Google_Cloud_Bigquery_V2_LinkedDatasetMetadata.LinkState = .unspecified

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Specifies whether Linked Dataset is currently in a linked state or not.
  package enum LinkState: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// The default value.
    /// Default to the LINKED state.
    case unspecified // = 0

    /// Normal Linked Dataset state. Data is queryable via the Linked Dataset.
    case linked // = 1

    /// Data publisher or owner has unlinked this Linked Dataset. It means you
    /// can no longer query or see the data in the Linked Dataset.
    case unlinked // = 2
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .linked
      case 2: self = .unlinked
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .linked: return 1
      case .unlinked: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_LinkedDatasetMetadata.LinkState] = [
      .unspecified,
      .linked,
      .unlinked,
    ]

  }

  package init() {}
}

/// Request format for getting information about a dataset.
package struct Google_Cloud_Bigquery_V2_GetDatasetRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the requested dataset
  package var projectID: String = String()

  /// Required. Dataset ID of the requested dataset
  package var datasetID: String = String()

  /// Optional. Specifies the view that determines which dataset information is
  /// returned. By default, metadata and ACL information are returned.
  package var datasetView: Google_Cloud_Bigquery_V2_GetDatasetRequest.DatasetView = .unspecified

  /// Optional. The version of the access policy schema to fetch.
  /// Valid values are 0, 1, and 3. Requests specifying an invalid value will be
  /// rejected.
  ///
  /// Requests for conditional access policy binding in datasets must specify
  /// version 3. Dataset with no conditional role bindings in access policy may
  /// specify any valid value or leave the field unset.
  ///
  /// This field will be maped to [IAM Policy version]
  /// (https://cloud.google.com/iam/docs/policies#versions) and will be used to
  /// fetch policy from IAM.
  ///
  /// If unset or if 0 or 1 value is used for dataset with conditional bindings,
  /// access entry with condition will have role string appended by
  /// 'withcond' string followed by a hash value. For example :
  /// {
  ///   "access": [
  ///      {
  ///         "role":
  ///         "roles/bigquery.dataViewer_with_conditionalbinding_7a34awqsda",
  ///         "userByEmail": "user@example.com",
  ///      }
  ///   ]
  /// }
  /// Please refer https://cloud.google.com/iam/docs/troubleshooting-withcond for
  /// more details.
  package var accessPolicyVersion: Int32 = 0

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  /// DatasetView specifies which dataset information is returned.
  package enum DatasetView: SwiftProtobuf.Enum, Swift.CaseIterable {
    package typealias RawValue = Int

    /// The default value.
    /// Default to the FULL view.
    case unspecified // = 0

    /// Includes metadata information for the dataset, such as location,
    /// etag, lastModifiedTime, etc.
    case metadata // = 1

    /// Includes ACL information for the dataset, which defines dataset access
    /// for one or more entities.
    case acl // = 2

    /// Includes both dataset metadata and ACL information.
    case full // = 3
    case UNRECOGNIZED(Int)

    package init() {
      self = .unspecified
    }

    package init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .metadata
      case 2: self = .acl
      case 3: self = .full
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    package var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .metadata: return 1
      case .acl: return 2
      case .full: return 3
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    package static let allCases: [Google_Cloud_Bigquery_V2_GetDatasetRequest.DatasetView] = [
      .unspecified,
      .metadata,
      .acl,
      .full,
    ]

  }

  package init() {}
}

/// Request format for inserting a dataset.
package struct Google_Cloud_Bigquery_V2_InsertDatasetRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the new dataset
  package var projectID: String = String()

  /// Required. Datasets resource to use for the new dataset
  package var dataset: Google_Cloud_Bigquery_V2_Dataset {
    get {return _dataset ?? Google_Cloud_Bigquery_V2_Dataset()}
    set {_dataset = newValue}
  }
  /// Returns true if `dataset` has been explicitly set.
  package var hasDataset: Bool {return self._dataset != nil}
  /// Clears the value of `dataset`. Subsequent reads from it will return its default value.
  package mutating func clearDataset() {self._dataset = nil}

  /// Optional. The version of the provided access policy schema.
  /// Valid values are 0, 1, and 3. Requests specifying an invalid value will be
  /// rejected.
  ///
  /// This version refers to the schema version of the access policy and not the
  /// version of access policy. This field's value can be equal or more
  /// than the access policy schema provided in the request.
  /// For example,
  ///   * Requests with conditional access policy binding in datasets must
  ///   specify
  ///     version 3.
  ///   * But dataset with no conditional role bindings in access policy
  ///     may specify any valid value or leave the field unset.
  /// If unset or if 0 or 1 value is used for dataset with conditional
  /// bindings, request will be rejected.
  ///
  /// This field will be maped to IAM Policy version
  /// (https://cloud.google.com/iam/docs/policies#versions) and will be used to
  /// set policy in IAM.
  package var accessPolicyVersion: Int32 = 0

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _dataset: Google_Cloud_Bigquery_V2_Dataset? = nil
}

/// Message for updating or patching a dataset.
package struct Google_Cloud_Bigquery_V2_UpdateOrPatchDatasetRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the dataset being updated
  package var projectID: String = String()

  /// Required. Dataset ID of the dataset being updated
  package var datasetID: String = String()

  /// Required. Datasets resource which will replace or patch the specified
  /// dataset.
  package var dataset: Google_Cloud_Bigquery_V2_Dataset {
    get {return _dataset ?? Google_Cloud_Bigquery_V2_Dataset()}
    set {_dataset = newValue}
  }
  /// Returns true if `dataset` has been explicitly set.
  package var hasDataset: Bool {return self._dataset != nil}
  /// Clears the value of `dataset`. Subsequent reads from it will return its default value.
  package mutating func clearDataset() {self._dataset = nil}

  /// Optional. The version of the provided access policy schema.
  /// Valid values are 0, 1, and 3. Requests specifying an invalid value will be
  /// rejected.
  ///
  /// This version refers to the schema version of the access policy and not the
  /// version of access policy. This field's value can be equal or more
  /// than the access policy schema provided in the request.
  /// For example,
  ///   * Operations updating conditional access policy binding in datasets must
  ///   specify
  ///     version 3. Some of the operations are :
  ///       -  Adding a new access policy entry with condition.
  ///       -  Removing an access policy entry with condition.
  ///       -  Updating an access policy entry with condition.
  ///   * But dataset with no conditional role bindings in access policy
  ///     may specify any valid value or leave the field unset.
  /// If unset or if 0 or 1 value is used for dataset with conditional
  /// bindings, request will be rejected.
  ///
  /// This field will be maped to IAM Policy version
  /// (https://cloud.google.com/iam/docs/policies#versions) and will be used to
  /// set policy in IAM.
  package var accessPolicyVersion: Int32 = 0

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _dataset: Google_Cloud_Bigquery_V2_Dataset? = nil
}

/// Request format for deleting a dataset.
package struct Google_Cloud_Bigquery_V2_DeleteDatasetRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the dataset being deleted
  package var projectID: String = String()

  /// Required. Dataset ID of dataset being deleted
  package var datasetID: String = String()

  /// If True, delete all the tables in the dataset.
  /// If False and the dataset contains tables, the request will fail.
  /// Default is False
  package var deleteContents: Bool = false

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

package struct Google_Cloud_Bigquery_V2_ListDatasetsRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the datasets to be listed
  package var projectID: String = String()

  /// The maximum number of results to return in a single response page.
  /// Leverage the page tokens to iterate through the entire collection.
  package var maxResults: SwiftProtobuf.Google_Protobuf_UInt32Value {
    get {return _maxResults ?? SwiftProtobuf.Google_Protobuf_UInt32Value()}
    set {_maxResults = newValue}
  }
  /// Returns true if `maxResults` has been explicitly set.
  package var hasMaxResults: Bool {return self._maxResults != nil}
  /// Clears the value of `maxResults`. Subsequent reads from it will return its default value.
  package mutating func clearMaxResults() {self._maxResults = nil}

  /// Page token, returned by a previous call, to request the next page of
  /// results
  package var pageToken: String = String()

  /// Whether to list all datasets, including hidden ones
  package var all: Bool = false

  /// An expression for filtering the results of the request by label.
  /// The syntax is `labels.<name>[:<value>]`.
  /// Multiple filters can be ANDed together by connecting with a space.
  /// Example: `labels.department:receiving labels.active`.
  /// See [Filtering datasets using
  /// labels](https://cloud.google.com/bigquery/docs/filtering-labels#filtering_datasets_using_labels)
  /// for details.
  package var filter: String = String()

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _maxResults: SwiftProtobuf.Google_Protobuf_UInt32Value? = nil
}

/// A dataset resource with only a subset of fields, to be returned in a list of
/// datasets.
package struct Google_Cloud_Bigquery_V2_ListFormatDataset: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The resource type.
  /// This property always returns the value "bigquery#dataset"
  package var kind: String = String()

  /// The fully-qualified, unique, opaque ID of the dataset.
  package var id: String = String()

  /// The dataset reference.
  /// Use this property to access specific parts of the dataset's ID, such as
  /// project ID or dataset ID.
  package var datasetReference: Google_Cloud_Bigquery_V2_DatasetReference {
    get {return _datasetReference ?? Google_Cloud_Bigquery_V2_DatasetReference()}
    set {_datasetReference = newValue}
  }
  /// Returns true if `datasetReference` has been explicitly set.
  package var hasDatasetReference: Bool {return self._datasetReference != nil}
  /// Clears the value of `datasetReference`. Subsequent reads from it will return its default value.
  package mutating func clearDatasetReference() {self._datasetReference = nil}

  /// The labels associated with this dataset.
  /// You can use these to organize and group your datasets.
  package var labels: Dictionary<String,String> = [:]

  /// An alternate name for the dataset.  The friendly name is purely
  /// decorative in nature.
  package var friendlyName: SwiftProtobuf.Google_Protobuf_StringValue {
    get {return _friendlyName ?? SwiftProtobuf.Google_Protobuf_StringValue()}
    set {_friendlyName = newValue}
  }
  /// Returns true if `friendlyName` has been explicitly set.
  package var hasFriendlyName: Bool {return self._friendlyName != nil}
  /// Clears the value of `friendlyName`. Subsequent reads from it will return its default value.
  package mutating func clearFriendlyName() {self._friendlyName = nil}

  /// The geographic location where the dataset resides.
  package var location: String = String()

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _datasetReference: Google_Cloud_Bigquery_V2_DatasetReference? = nil
  fileprivate var _friendlyName: SwiftProtobuf.Google_Protobuf_StringValue? = nil
}

/// Response format for a page of results when listing datasets.
package struct Google_Cloud_Bigquery_V2_DatasetList: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. The resource type.
  /// This property always returns the value "bigquery#datasetList"
  package var kind: String = String()

  /// Output only. A hash value of the results page. You can use this property to
  /// determine if the page has changed since the last request.
  package var etag: String = String()

  /// A token that can be used to request the next results page. This property is
  /// omitted on the final results page.
  package var nextPageToken: String = String()

  /// An array of the dataset resources in the project.
  /// Each resource contains basic information.
  /// For full information about a particular dataset resource, use the Datasets:
  /// get method. This property is omitted when there are no datasets in the
  /// project.
  package var datasets: [Google_Cloud_Bigquery_V2_ListFormatDataset] = []

  /// A list of skipped locations that were unreachable. For more information
  /// about BigQuery locations, see:
  /// https://cloud.google.com/bigquery/docs/locations. Example: "europe-west5"
  package var unreachable: [String] = []

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}
}

/// Request format for undeleting a dataset.
package struct Google_Cloud_Bigquery_V2_UndeleteDatasetRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Project ID of the dataset to be undeleted
  package var projectID: String = String()

  /// Required. Dataset ID of dataset being deleted
  package var datasetID: String = String()

  /// Optional. The exact time when the dataset was deleted. If not specified,
  /// the most recently deleted version is undeleted. Undeleting a dataset
  /// using deletion time is not supported.
  package var deletionTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _deletionTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_deletionTime = newValue}
  }
  /// Returns true if `deletionTime` has been explicitly set.
  package var hasDeletionTime: Bool {return self._deletionTime != nil}
  /// Clears the value of `deletionTime`. Subsequent reads from it will return its default value.
  package mutating func clearDeletionTime() {self._deletionTime = nil}

  package var unknownFields = SwiftProtobuf.UnknownStorage()

  package init() {}

  fileprivate var _deletionTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.bigquery.v2"

extension Google_Cloud_Bigquery_V2_DatasetAccessEntry: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".DatasetAccessEntry"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "dataset"),
    2: .standard(proto: "target_types"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._dataset) }()
      case 2: try { try decoder.decodeRepeatedEnumField(value: &self.targetTypes) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._dataset {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if !self.targetTypes.isEmpty {
      try visitor.visitPackedEnumField(value: self.targetTypes, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_DatasetAccessEntry, rhs: Google_Cloud_Bigquery_V2_DatasetAccessEntry) -> Bool {
    if lhs._dataset != rhs._dataset {return false}
    if lhs.targetTypes != rhs.targetTypes {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_DatasetAccessEntry.TargetType: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "TARGET_TYPE_UNSPECIFIED"),
    1: .same(proto: "VIEWS"),
    2: .same(proto: "ROUTINES"),
  ]
}

extension Google_Cloud_Bigquery_V2_Access: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".Access"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "role"),
    2: .standard(proto: "user_by_email"),
    3: .standard(proto: "group_by_email"),
    4: .same(proto: "domain"),
    5: .standard(proto: "special_group"),
    7: .standard(proto: "iam_member"),
    6: .same(proto: "view"),
    8: .same(proto: "routine"),
    9: .same(proto: "dataset"),
    10: .same(proto: "condition"),
  ]

  fileprivate class _StorageClass {
    var _role: String = String()
    var _userByEmail: String = String()
    var _groupByEmail: String = String()
    var _domain: String = String()
    var _specialGroup: String = String()
    var _iamMember: String = String()
    var _view: Google_Cloud_Bigquery_V2_TableReference? = nil
    var _routine: Google_Cloud_Bigquery_V2_RoutineReference? = nil
    var _dataset: Google_Cloud_Bigquery_V2_DatasetAccessEntry? = nil
    var _condition: Google_Type_Expr? = nil

    #if swift(>=5.10)
      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()
    #else
      static let defaultInstance = _StorageClass()
    #endif

    private init() {}

    init(copying source: _StorageClass) {
      _role = source._role
      _userByEmail = source._userByEmail
      _groupByEmail = source._groupByEmail
      _domain = source._domain
      _specialGroup = source._specialGroup
      _iamMember = source._iamMember
      _view = source._view
      _routine = source._routine
      _dataset = source._dataset
      _condition = source._condition
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._role) }()
        case 2: try { try decoder.decodeSingularStringField(value: &_storage._userByEmail) }()
        case 3: try { try decoder.decodeSingularStringField(value: &_storage._groupByEmail) }()
        case 4: try { try decoder.decodeSingularStringField(value: &_storage._domain) }()
        case 5: try { try decoder.decodeSingularStringField(value: &_storage._specialGroup) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._view) }()
        case 7: try { try decoder.decodeSingularStringField(value: &_storage._iamMember) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._routine) }()
        case 9: try { try decoder.decodeSingularMessageField(value: &_storage._dataset) }()
        case 10: try { try decoder.decodeSingularMessageField(value: &_storage._condition) }()
        default: break
        }
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if !_storage._role.isEmpty {
        try visitor.visitSingularStringField(value: _storage._role, fieldNumber: 1)
      }
      if !_storage._userByEmail.isEmpty {
        try visitor.visitSingularStringField(value: _storage._userByEmail, fieldNumber: 2)
      }
      if !_storage._groupByEmail.isEmpty {
        try visitor.visitSingularStringField(value: _storage._groupByEmail, fieldNumber: 3)
      }
      if !_storage._domain.isEmpty {
        try visitor.visitSingularStringField(value: _storage._domain, fieldNumber: 4)
      }
      if !_storage._specialGroup.isEmpty {
        try visitor.visitSingularStringField(value: _storage._specialGroup, fieldNumber: 5)
      }
      try { if let v = _storage._view {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      } }()
      if !_storage._iamMember.isEmpty {
        try visitor.visitSingularStringField(value: _storage._iamMember, fieldNumber: 7)
      }
      try { if let v = _storage._routine {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      } }()
      try { if let v = _storage._dataset {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      } }()
      try { if let v = _storage._condition {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Access, rhs: Google_Cloud_Bigquery_V2_Access) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._role != rhs_storage._role {return false}
        if _storage._userByEmail != rhs_storage._userByEmail {return false}
        if _storage._groupByEmail != rhs_storage._groupByEmail {return false}
        if _storage._domain != rhs_storage._domain {return false}
        if _storage._specialGroup != rhs_storage._specialGroup {return false}
        if _storage._iamMember != rhs_storage._iamMember {return false}
        if _storage._view != rhs_storage._view {return false}
        if _storage._routine != rhs_storage._routine {return false}
        if _storage._dataset != rhs_storage._dataset {return false}
        if _storage._condition != rhs_storage._condition {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Dataset: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".Dataset"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "kind"),
    2: .same(proto: "etag"),
    3: .same(proto: "id"),
    4: .standard(proto: "self_link"),
    5: .standard(proto: "dataset_reference"),
    6: .standard(proto: "friendly_name"),
    7: .same(proto: "description"),
    8: .standard(proto: "default_table_expiration_ms"),
    14: .standard(proto: "default_partition_expiration_ms"),
    9: .same(proto: "labels"),
    10: .same(proto: "access"),
    11: .standard(proto: "creation_time"),
    12: .standard(proto: "last_modified_time"),
    13: .same(proto: "location"),
    16: .standard(proto: "default_encryption_configuration"),
    17: .standard(proto: "satisfies_pzs"),
    31: .standard(proto: "satisfies_pzi"),
    18: .same(proto: "type"),
    19: .standard(proto: "linked_dataset_source"),
    29: .standard(proto: "linked_dataset_metadata"),
    20: .standard(proto: "external_dataset_reference"),
    32: .standard(proto: "external_catalog_dataset_options"),
    21: .standard(proto: "is_case_insensitive"),
    22: .standard(proto: "default_collation"),
    26: .standard(proto: "default_rounding_mode"),
    23: .standard(proto: "max_time_travel_hours"),
    24: .same(proto: "tags"),
    25: .standard(proto: "storage_billing_model"),
    27: .same(proto: "restrictions"),
    30: .standard(proto: "resource_tags"),
  ]

  fileprivate class _StorageClass {
    var _kind: String = String()
    var _etag: String = String()
    var _id: String = String()
    var _selfLink: String = String()
    var _datasetReference: Google_Cloud_Bigquery_V2_DatasetReference? = nil
    var _friendlyName: SwiftProtobuf.Google_Protobuf_StringValue? = nil
    var _description_p: SwiftProtobuf.Google_Protobuf_StringValue? = nil
    var _defaultTableExpirationMs: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _defaultPartitionExpirationMs: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _labels: Dictionary<String,String> = [:]
    var _access: [Google_Cloud_Bigquery_V2_Access] = []
    var _creationTime: Int64 = 0
    var _lastModifiedTime: Int64 = 0
    var _location: String = String()
    var _defaultEncryptionConfiguration: Google_Cloud_Bigquery_V2_EncryptionConfiguration? = nil
    var _satisfiesPzs: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _satisfiesPzi: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _type: String = String()
    var _linkedDatasetSource: Google_Cloud_Bigquery_V2_LinkedDatasetSource? = nil
    var _linkedDatasetMetadata: Google_Cloud_Bigquery_V2_LinkedDatasetMetadata? = nil
    var _externalDatasetReference: Google_Cloud_Bigquery_V2_ExternalDatasetReference? = nil
    var _externalCatalogDatasetOptions: Google_Cloud_Bigquery_V2_ExternalCatalogDatasetOptions? = nil
    var _isCaseInsensitive: SwiftProtobuf.Google_Protobuf_BoolValue? = nil
    var _defaultCollation: SwiftProtobuf.Google_Protobuf_StringValue? = nil
    var _defaultRoundingMode: Google_Cloud_Bigquery_V2_TableFieldSchema.RoundingMode = .unspecified
    var _maxTimeTravelHours: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _tags: [Google_Cloud_Bigquery_V2_GcpTag] = []
    var _storageBillingModel: Google_Cloud_Bigquery_V2_Dataset.StorageBillingModel = .unspecified
    var _restrictions: Google_Cloud_Bigquery_V2_RestrictionConfig? = nil
    var _resourceTags: Dictionary<String,String> = [:]

    #if swift(>=5.10)
      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()
    #else
      static let defaultInstance = _StorageClass()
    #endif

    private init() {}

    init(copying source: _StorageClass) {
      _kind = source._kind
      _etag = source._etag
      _id = source._id
      _selfLink = source._selfLink
      _datasetReference = source._datasetReference
      _friendlyName = source._friendlyName
      _description_p = source._description_p
      _defaultTableExpirationMs = source._defaultTableExpirationMs
      _defaultPartitionExpirationMs = source._defaultPartitionExpirationMs
      _labels = source._labels
      _access = source._access
      _creationTime = source._creationTime
      _lastModifiedTime = source._lastModifiedTime
      _location = source._location
      _defaultEncryptionConfiguration = source._defaultEncryptionConfiguration
      _satisfiesPzs = source._satisfiesPzs
      _satisfiesPzi = source._satisfiesPzi
      _type = source._type
      _linkedDatasetSource = source._linkedDatasetSource
      _linkedDatasetMetadata = source._linkedDatasetMetadata
      _externalDatasetReference = source._externalDatasetReference
      _externalCatalogDatasetOptions = source._externalCatalogDatasetOptions
      _isCaseInsensitive = source._isCaseInsensitive
      _defaultCollation = source._defaultCollation
      _defaultRoundingMode = source._defaultRoundingMode
      _maxTimeTravelHours = source._maxTimeTravelHours
      _tags = source._tags
      _storageBillingModel = source._storageBillingModel
      _restrictions = source._restrictions
      _resourceTags = source._resourceTags
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._kind) }()
        case 2: try { try decoder.decodeSingularStringField(value: &_storage._etag) }()
        case 3: try { try decoder.decodeSingularStringField(value: &_storage._id) }()
        case 4: try { try decoder.decodeSingularStringField(value: &_storage._selfLink) }()
        case 5: try { try decoder.decodeSingularMessageField(value: &_storage._datasetReference) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._friendlyName) }()
        case 7: try { try decoder.decodeSingularMessageField(value: &_storage._description_p) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._defaultTableExpirationMs) }()
        case 9: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &_storage._labels) }()
        case 10: try { try decoder.decodeRepeatedMessageField(value: &_storage._access) }()
        case 11: try { try decoder.decodeSingularInt64Field(value: &_storage._creationTime) }()
        case 12: try { try decoder.decodeSingularInt64Field(value: &_storage._lastModifiedTime) }()
        case 13: try { try decoder.decodeSingularStringField(value: &_storage._location) }()
        case 14: try { try decoder.decodeSingularMessageField(value: &_storage._defaultPartitionExpirationMs) }()
        case 16: try { try decoder.decodeSingularMessageField(value: &_storage._defaultEncryptionConfiguration) }()
        case 17: try { try decoder.decodeSingularMessageField(value: &_storage._satisfiesPzs) }()
        case 18: try { try decoder.decodeSingularStringField(value: &_storage._type) }()
        case 19: try { try decoder.decodeSingularMessageField(value: &_storage._linkedDatasetSource) }()
        case 20: try { try decoder.decodeSingularMessageField(value: &_storage._externalDatasetReference) }()
        case 21: try { try decoder.decodeSingularMessageField(value: &_storage._isCaseInsensitive) }()
        case 22: try { try decoder.decodeSingularMessageField(value: &_storage._defaultCollation) }()
        case 23: try { try decoder.decodeSingularMessageField(value: &_storage._maxTimeTravelHours) }()
        case 24: try { try decoder.decodeRepeatedMessageField(value: &_storage._tags) }()
        case 25: try { try decoder.decodeSingularEnumField(value: &_storage._storageBillingModel) }()
        case 26: try { try decoder.decodeSingularEnumField(value: &_storage._defaultRoundingMode) }()
        case 27: try { try decoder.decodeSingularMessageField(value: &_storage._restrictions) }()
        case 29: try { try decoder.decodeSingularMessageField(value: &_storage._linkedDatasetMetadata) }()
        case 30: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &_storage._resourceTags) }()
        case 31: try { try decoder.decodeSingularMessageField(value: &_storage._satisfiesPzi) }()
        case 32: try { try decoder.decodeSingularMessageField(value: &_storage._externalCatalogDatasetOptions) }()
        default: break
        }
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if !_storage._kind.isEmpty {
        try visitor.visitSingularStringField(value: _storage._kind, fieldNumber: 1)
      }
      if !_storage._etag.isEmpty {
        try visitor.visitSingularStringField(value: _storage._etag, fieldNumber: 2)
      }
      if !_storage._id.isEmpty {
        try visitor.visitSingularStringField(value: _storage._id, fieldNumber: 3)
      }
      if !_storage._selfLink.isEmpty {
        try visitor.visitSingularStringField(value: _storage._selfLink, fieldNumber: 4)
      }
      try { if let v = _storage._datasetReference {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
      } }()
      try { if let v = _storage._friendlyName {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      } }()
      try { if let v = _storage._description_p {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      } }()
      try { if let v = _storage._defaultTableExpirationMs {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      } }()
      if !_storage._labels.isEmpty {
        try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: _storage._labels, fieldNumber: 9)
      }
      if !_storage._access.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._access, fieldNumber: 10)
      }
      if _storage._creationTime != 0 {
        try visitor.visitSingularInt64Field(value: _storage._creationTime, fieldNumber: 11)
      }
      if _storage._lastModifiedTime != 0 {
        try visitor.visitSingularInt64Field(value: _storage._lastModifiedTime, fieldNumber: 12)
      }
      if !_storage._location.isEmpty {
        try visitor.visitSingularStringField(value: _storage._location, fieldNumber: 13)
      }
      try { if let v = _storage._defaultPartitionExpirationMs {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 14)
      } }()
      try { if let v = _storage._defaultEncryptionConfiguration {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 16)
      } }()
      try { if let v = _storage._satisfiesPzs {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 17)
      } }()
      if !_storage._type.isEmpty {
        try visitor.visitSingularStringField(value: _storage._type, fieldNumber: 18)
      }
      try { if let v = _storage._linkedDatasetSource {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 19)
      } }()
      try { if let v = _storage._externalDatasetReference {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 20)
      } }()
      try { if let v = _storage._isCaseInsensitive {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 21)
      } }()
      try { if let v = _storage._defaultCollation {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 22)
      } }()
      try { if let v = _storage._maxTimeTravelHours {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 23)
      } }()
      if !_storage._tags.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._tags, fieldNumber: 24)
      }
      if _storage._storageBillingModel != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._storageBillingModel, fieldNumber: 25)
      }
      if _storage._defaultRoundingMode != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._defaultRoundingMode, fieldNumber: 26)
      }
      try { if let v = _storage._restrictions {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 27)
      } }()
      try { if let v = _storage._linkedDatasetMetadata {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 29)
      } }()
      if !_storage._resourceTags.isEmpty {
        try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: _storage._resourceTags, fieldNumber: 30)
      }
      try { if let v = _storage._satisfiesPzi {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 31)
      } }()
      try { if let v = _storage._externalCatalogDatasetOptions {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 32)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_Dataset, rhs: Google_Cloud_Bigquery_V2_Dataset) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._kind != rhs_storage._kind {return false}
        if _storage._etag != rhs_storage._etag {return false}
        if _storage._id != rhs_storage._id {return false}
        if _storage._selfLink != rhs_storage._selfLink {return false}
        if _storage._datasetReference != rhs_storage._datasetReference {return false}
        if _storage._friendlyName != rhs_storage._friendlyName {return false}
        if _storage._description_p != rhs_storage._description_p {return false}
        if _storage._defaultTableExpirationMs != rhs_storage._defaultTableExpirationMs {return false}
        if _storage._defaultPartitionExpirationMs != rhs_storage._defaultPartitionExpirationMs {return false}
        if _storage._labels != rhs_storage._labels {return false}
        if _storage._access != rhs_storage._access {return false}
        if _storage._creationTime != rhs_storage._creationTime {return false}
        if _storage._lastModifiedTime != rhs_storage._lastModifiedTime {return false}
        if _storage._location != rhs_storage._location {return false}
        if _storage._defaultEncryptionConfiguration != rhs_storage._defaultEncryptionConfiguration {return false}
        if _storage._satisfiesPzs != rhs_storage._satisfiesPzs {return false}
        if _storage._satisfiesPzi != rhs_storage._satisfiesPzi {return false}
        if _storage._type != rhs_storage._type {return false}
        if _storage._linkedDatasetSource != rhs_storage._linkedDatasetSource {return false}
        if _storage._linkedDatasetMetadata != rhs_storage._linkedDatasetMetadata {return false}
        if _storage._externalDatasetReference != rhs_storage._externalDatasetReference {return false}
        if _storage._externalCatalogDatasetOptions != rhs_storage._externalCatalogDatasetOptions {return false}
        if _storage._isCaseInsensitive != rhs_storage._isCaseInsensitive {return false}
        if _storage._defaultCollation != rhs_storage._defaultCollation {return false}
        if _storage._defaultRoundingMode != rhs_storage._defaultRoundingMode {return false}
        if _storage._maxTimeTravelHours != rhs_storage._maxTimeTravelHours {return false}
        if _storage._tags != rhs_storage._tags {return false}
        if _storage._storageBillingModel != rhs_storage._storageBillingModel {return false}
        if _storage._restrictions != rhs_storage._restrictions {return false}
        if _storage._resourceTags != rhs_storage._resourceTags {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_Dataset.StorageBillingModel: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "STORAGE_BILLING_MODEL_UNSPECIFIED"),
    1: .same(proto: "LOGICAL"),
    2: .same(proto: "PHYSICAL"),
  ]
}

extension Google_Cloud_Bigquery_V2_GcpTag: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".GcpTag"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "tag_key"),
    2: .standard(proto: "tag_value"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.tagKey) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.tagValue) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.tagKey.isEmpty {
      try visitor.visitSingularStringField(value: self.tagKey, fieldNumber: 1)
    }
    if !self.tagValue.isEmpty {
      try visitor.visitSingularStringField(value: self.tagValue, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_GcpTag, rhs: Google_Cloud_Bigquery_V2_GcpTag) -> Bool {
    if lhs.tagKey != rhs.tagKey {return false}
    if lhs.tagValue != rhs.tagValue {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_LinkedDatasetSource: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".LinkedDatasetSource"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "source_dataset"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._sourceDataset) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._sourceDataset {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_LinkedDatasetSource, rhs: Google_Cloud_Bigquery_V2_LinkedDatasetSource) -> Bool {
    if lhs._sourceDataset != rhs._sourceDataset {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_LinkedDatasetMetadata: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".LinkedDatasetMetadata"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "link_state"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.linkState) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.linkState != .unspecified {
      try visitor.visitSingularEnumField(value: self.linkState, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_LinkedDatasetMetadata, rhs: Google_Cloud_Bigquery_V2_LinkedDatasetMetadata) -> Bool {
    if lhs.linkState != rhs.linkState {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_LinkedDatasetMetadata.LinkState: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "LINK_STATE_UNSPECIFIED"),
    1: .same(proto: "LINKED"),
    2: .same(proto: "UNLINKED"),
  ]
}

extension Google_Cloud_Bigquery_V2_GetDatasetRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".GetDatasetRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "dataset_id"),
    3: .standard(proto: "dataset_view"),
    4: .standard(proto: "access_policy_version"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.datasetID) }()
      case 3: try { try decoder.decodeSingularEnumField(value: &self.datasetView) }()
      case 4: try { try decoder.decodeSingularInt32Field(value: &self.accessPolicyVersion) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.datasetID.isEmpty {
      try visitor.visitSingularStringField(value: self.datasetID, fieldNumber: 2)
    }
    if self.datasetView != .unspecified {
      try visitor.visitSingularEnumField(value: self.datasetView, fieldNumber: 3)
    }
    if self.accessPolicyVersion != 0 {
      try visitor.visitSingularInt32Field(value: self.accessPolicyVersion, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_GetDatasetRequest, rhs: Google_Cloud_Bigquery_V2_GetDatasetRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.datasetID != rhs.datasetID {return false}
    if lhs.datasetView != rhs.datasetView {return false}
    if lhs.accessPolicyVersion != rhs.accessPolicyVersion {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_GetDatasetRequest.DatasetView: SwiftProtobuf._ProtoNameProviding {
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "DATASET_VIEW_UNSPECIFIED"),
    1: .same(proto: "METADATA"),
    2: .same(proto: "ACL"),
    3: .same(proto: "FULL"),
  ]
}

extension Google_Cloud_Bigquery_V2_InsertDatasetRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".InsertDatasetRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .same(proto: "dataset"),
    4: .standard(proto: "access_policy_version"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._dataset) }()
      case 4: try { try decoder.decodeSingularInt32Field(value: &self.accessPolicyVersion) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    try { if let v = self._dataset {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if self.accessPolicyVersion != 0 {
      try visitor.visitSingularInt32Field(value: self.accessPolicyVersion, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_InsertDatasetRequest, rhs: Google_Cloud_Bigquery_V2_InsertDatasetRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs._dataset != rhs._dataset {return false}
    if lhs.accessPolicyVersion != rhs.accessPolicyVersion {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_UpdateOrPatchDatasetRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".UpdateOrPatchDatasetRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "dataset_id"),
    3: .same(proto: "dataset"),
    5: .standard(proto: "access_policy_version"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.datasetID) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._dataset) }()
      case 5: try { try decoder.decodeSingularInt32Field(value: &self.accessPolicyVersion) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.datasetID.isEmpty {
      try visitor.visitSingularStringField(value: self.datasetID, fieldNumber: 2)
    }
    try { if let v = self._dataset {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    if self.accessPolicyVersion != 0 {
      try visitor.visitSingularInt32Field(value: self.accessPolicyVersion, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_UpdateOrPatchDatasetRequest, rhs: Google_Cloud_Bigquery_V2_UpdateOrPatchDatasetRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.datasetID != rhs.datasetID {return false}
    if lhs._dataset != rhs._dataset {return false}
    if lhs.accessPolicyVersion != rhs.accessPolicyVersion {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_DeleteDatasetRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".DeleteDatasetRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "dataset_id"),
    3: .standard(proto: "delete_contents"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.datasetID) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self.deleteContents) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.datasetID.isEmpty {
      try visitor.visitSingularStringField(value: self.datasetID, fieldNumber: 2)
    }
    if self.deleteContents != false {
      try visitor.visitSingularBoolField(value: self.deleteContents, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_DeleteDatasetRequest, rhs: Google_Cloud_Bigquery_V2_DeleteDatasetRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.datasetID != rhs.datasetID {return false}
    if lhs.deleteContents != rhs.deleteContents {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_ListDatasetsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".ListDatasetsRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "max_results"),
    3: .standard(proto: "page_token"),
    4: .same(proto: "all"),
    5: .same(proto: "filter"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._maxResults) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.pageToken) }()
      case 4: try { try decoder.decodeSingularBoolField(value: &self.all) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self.filter) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    try { if let v = self._maxResults {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if !self.pageToken.isEmpty {
      try visitor.visitSingularStringField(value: self.pageToken, fieldNumber: 3)
    }
    if self.all != false {
      try visitor.visitSingularBoolField(value: self.all, fieldNumber: 4)
    }
    if !self.filter.isEmpty {
      try visitor.visitSingularStringField(value: self.filter, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_ListDatasetsRequest, rhs: Google_Cloud_Bigquery_V2_ListDatasetsRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs._maxResults != rhs._maxResults {return false}
    if lhs.pageToken != rhs.pageToken {return false}
    if lhs.all != rhs.all {return false}
    if lhs.filter != rhs.filter {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_ListFormatDataset: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".ListFormatDataset"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "kind"),
    2: .same(proto: "id"),
    3: .standard(proto: "dataset_reference"),
    4: .same(proto: "labels"),
    5: .standard(proto: "friendly_name"),
    6: .same(proto: "location"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.kind) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.id) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._datasetReference) }()
      case 4: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &self.labels) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._friendlyName) }()
      case 6: try { try decoder.decodeSingularStringField(value: &self.location) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.kind.isEmpty {
      try visitor.visitSingularStringField(value: self.kind, fieldNumber: 1)
    }
    if !self.id.isEmpty {
      try visitor.visitSingularStringField(value: self.id, fieldNumber: 2)
    }
    try { if let v = self._datasetReference {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    if !self.labels.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: self.labels, fieldNumber: 4)
    }
    try { if let v = self._friendlyName {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    if !self.location.isEmpty {
      try visitor.visitSingularStringField(value: self.location, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_ListFormatDataset, rhs: Google_Cloud_Bigquery_V2_ListFormatDataset) -> Bool {
    if lhs.kind != rhs.kind {return false}
    if lhs.id != rhs.id {return false}
    if lhs._datasetReference != rhs._datasetReference {return false}
    if lhs.labels != rhs.labels {return false}
    if lhs._friendlyName != rhs._friendlyName {return false}
    if lhs.location != rhs.location {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_DatasetList: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".DatasetList"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "kind"),
    2: .same(proto: "etag"),
    3: .standard(proto: "next_page_token"),
    4: .same(proto: "datasets"),
    5: .same(proto: "unreachable"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.kind) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.etag) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.nextPageToken) }()
      case 4: try { try decoder.decodeRepeatedMessageField(value: &self.datasets) }()
      case 5: try { try decoder.decodeRepeatedStringField(value: &self.unreachable) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.kind.isEmpty {
      try visitor.visitSingularStringField(value: self.kind, fieldNumber: 1)
    }
    if !self.etag.isEmpty {
      try visitor.visitSingularStringField(value: self.etag, fieldNumber: 2)
    }
    if !self.nextPageToken.isEmpty {
      try visitor.visitSingularStringField(value: self.nextPageToken, fieldNumber: 3)
    }
    if !self.datasets.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.datasets, fieldNumber: 4)
    }
    if !self.unreachable.isEmpty {
      try visitor.visitRepeatedStringField(value: self.unreachable, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_DatasetList, rhs: Google_Cloud_Bigquery_V2_DatasetList) -> Bool {
    if lhs.kind != rhs.kind {return false}
    if lhs.etag != rhs.etag {return false}
    if lhs.nextPageToken != rhs.nextPageToken {return false}
    if lhs.datasets != rhs.datasets {return false}
    if lhs.unreachable != rhs.unreachable {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_V2_UndeleteDatasetRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  package static let protoMessageName: String = _protobuf_package + ".UndeleteDatasetRequest"
  package static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "dataset_id"),
    3: .standard(proto: "deletion_time"),
  ]

  package mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.datasetID) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._deletionTime) }()
      default: break
      }
    }
  }

  package func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.datasetID.isEmpty {
      try visitor.visitSingularStringField(value: self.datasetID, fieldNumber: 2)
    }
    try { if let v = self._deletionTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  package static func ==(lhs: Google_Cloud_Bigquery_V2_UndeleteDatasetRequest, rhs: Google_Cloud_Bigquery_V2_UndeleteDatasetRequest) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.datasetID != rhs.datasetID {return false}
    if lhs._deletionTime != rhs._deletionTime {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
